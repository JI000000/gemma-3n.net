// æ”¯æŒçš„è¯­è¨€
export const languages = {
  en: 'English',
  zh: 'ä¸­æ–‡'
} as const;

export type Language = keyof typeof languages;

// é»˜è®¤è¯­è¨€
export const defaultLang: Language = 'en';

// è¯­è¨€é…ç½®
export const langConfig = {
  en: {
    name: 'English',
    dir: 'ltr',
    locale: 'en-US'
  },
  zh: {
    name: 'ä¸­æ–‡',
    dir: 'ltr', 
    locale: 'zh-CN'
  }
} as const;

// UIæ–‡æœ¬èµ„æº
export const ui = {
  en: {
    // Nav
    'nav.home': 'Home',
    'nav.about': 'About',
    'nav.benchmarks': 'Benchmarks',
    'nav.blog': 'Blog',
    'nav.toolkit': 'Toolkit',
    'nav.resources': 'Resources',
    'nav.faq': 'FAQ',
    'nav.demo': 'Demo',
    'nav.compare': 'Compare',
    'nav.leaderboard': 'Leaderboard',
    
    // Home
    'hero.title': 'Gemma-3n.net: The Ultimate Developer Guide',
    'hero.subtitle': 'Master Google\'s Gemma 3n AI models with comprehensive tutorials, benchmarks, and tools.',
    'hero.cta.primary': 'Get Started',
    'hero.cta.secondary': 'View Demos',
    
    // SEO
    'seo.home.title': 'Gemma-3n.net: The Ultimate Developer Guide for Googleâ€™s Gemma 3n',
    'seo.home.description': 'Master Googleâ€™s Gemma 3n AI model with comprehensive tutorials, benchmarks, and tools. Your essential resource for local and cloud deployment.',
    'seo.about.title': 'About Gemma-3n.net | Our Mission and Methodology',
    'seo.about.description': 'Learn about the mission of Gemma-3n.net: to provide the most accurate, independent, and up-to-date resources for the Gemma 3n developer community.',
    'seo.blog.title': 'Gemma 3n Blog | Tutorials, News, and In-Depth Analysis',
    'seo.blog.description': 'The official blog for Gemma-3n.net. Find the latest news, expert tutorials, and deep-dive articles on fine-tuning, deploying, and optimizing the Gemma 3n model.',
    'seo.toolkit.title': 'Gemma 3n Toolkit | Downloads, Guides, and Official Resources',
    'seo.toolkit.description': 'The complete developer toolkit for Gemma 3n. Access official model downloads, setup guides for Ollama and Hugging Face, iOS deployment docs, and more.',
    'seo.compare.title': 'Gemma 3n vs. Llama 3: In-Depth AI Model Comparison',
    'seo.compare.description': 'A head-to-head, data-driven comparison of Google\'s Gemma 3n and Meta\'s Llama 3. Analyze performance benchmarks, architecture, and real-world use cases.',
    'seo.leaderboard.title': 'AI Model Leaderboard | Compare Gemma 3n, Llama 3, and More',
    'seo.leaderboard.description': 'Live AI model leaderboard comparing the latest open-source and proprietary models on key industry benchmarks. See how Gemma 3n stacks up against the competition.',

    // Demo
    'demo.title': 'ğŸš€ Gemma 3n Interactive Demo',
    'demo.subtitle': 'Experience in-browser AI inference - fully local, no server required',
    'demo.loading.initializing': 'Initializing lightweight AI model...',
    'demo.loading.engine': 'Downloading lightweight inference engine...',
    'demo.loading.wasm': 'Initializing WebAssembly module...',
    'demo.loading.vocab': 'Loading vocabulary and configuration...',
    'demo.loading.weights': 'Optimizing model weights...',
    'demo.loading.ready': 'Model ready!',
    'demo.status.ready': 'âœ… Gemma 3n Lite is ready (Online Demo Version)',
    'demo.scenarios.label': 'Select a demo scenario',
    'demo.scenarios.code.title': 'Code Completion',
    'demo.scenarios.code.description': 'Intelligent code suggestions',
    'demo.scenarios.translate.title': 'Language Translation',
    'demo.scenarios.translate.description': 'Translate between languages',
    'demo.scenarios.chat.title': 'Assistant Chat',
    'demo.scenarios.chat.description': 'Conversational assistant',
    'demo.input.label': 'Input Text',
    'demo.input.placeholder': 'Enter your text...',
    'demo.parameters.label': 'Temperature (Creativity)',
    'demo.parameters.conservative': 'Conservative',
    'demo.parameters.creative': 'Creative',
    'demo.button.loading': 'Model loading...',
    'demo.button.generate': 'Generate AI Response',
    'demo.button.generating': 'Generating...',
    'demo.output.label': 'AI Output',
    'demo.output.placeholder': 'AI-generated content will appear here...',
    'demo.output.thinking': 'ğŸ¤– AI is thinking...',
    'demo.output.error': 'âŒ Generation failed:',
    'demo.alert.no_input': 'Please enter some text',
    'demo.metrics.tokensPerSecond': 'Tokens/sec',
    'demo.metrics.inferenceTime': 'Inference Time (ms)',
    'demo.metrics.memoryUsage': 'Memory Usage (MB)',
    'demo.metrics.modelSize': 'Model Size',
    'demo.placeholders.code': `function fibonacci(n) {
  // Calculate fibonacci sequence
  if (n <= 1) return n;
  return`,
    'demo.placeholders.translate': `Please translate the following text to English:
Artificial intelligence is changing our world.`,
    'demo.placeholders.chat': `Hello, I would like to know the features and advantages of the Gemma 3n model.`,
    'demo.simulations.code_response': ` fibonacci(n - 1) + fibonacci(n - 2);
}

// Optimized version: using dynamic programming
function fibonacciDP(n) {
  const dp = [0, 1];
  for (let i = 2; i <= n; i++) {
    dp[i] = dp[i-1] + dp[i-2];
  }
  return dp[n];
}`,
    'demo.simulations.translation_response': `**Translation Result:**
Artificial Intelligence is transforming our world.

*Detected Language: Chinese â†’ English*`,
    'demo.simulations.chat_response_1': `Hello! I'm happy to introduce Gemma 3n. It is the latest multimodal AI model released by Google, with the following features:

ğŸ¯ **On-device Optimization**: Designed for devices like mobile phones and laptops
âš¡ **Efficient Architecture**: "Nested" MatFormer Transformer structure
ğŸ¨ **Multimodal Capability**: Supports text, image, and audio processing
ğŸ”§ **Developer Friendly**: Compatible with the mainstream AI tool ecosystem

Which aspect would you like to know more about?`,
    'demo.simulations.chat_response_2': `The advantages of Gemma 3n compared to other models are:

1. **Smaller Memory Footprint**: The E2B version requires only 4GB of memory
2. **Faster Inference Speed**: Optimized for mobile devices
3. **Better Accuracy**: Achieves 79.8% on the MMLU benchmark
4. **Stronger Multimodality**: Natively supports vision and audio

This makes it particularly suitable for building privacy-first on-device AI applications.`,
    'demo.simulations.chat_response_3': `Regarding the technical implementation of Gemma 3n, I recommend that you:

ğŸ“š **Learning Path**: Start with our introductory tutorials
ğŸ’» **Practical Projects**: Try the iOS deployment or Ollama integration
ğŸ”§ **Advanced Skills**: Learn LoRA fine-tuning techniques
ğŸŒ **Community Involvement**: Follow the latest model updates and optimizations

Would you like me to recommend a specific tutorial?`,
    
    // Controls
    'controls.temperature': 'Temperature',
    'controls.temperature.desc': 'Controls randomness in output',
    'controls.maxTokens': 'Max Tokens',
    'controls.maxTokens.desc': 'Maximum length of generated text',
    'controls.topK': 'Top-K',
    'controls.topK.desc': 'Limits vocabulary for more focused output',
    
    // Metrics
    'metrics.inference': 'Inference Time',
    'metrics.memory': 'Memory Usage',
    'metrics.tokens': 'Tokens/sec',
    'metrics.local': 'Local Processing',
    'metrics.api': 'API Call',
    
    // Scenarios
    'scenarios.code': 'Code Generation',
    'scenarios.code.desc': 'Generate and complete code',
    'scenarios.text': 'Text Generation', 
    'scenarios.text.desc': 'Creative writing and content',
    'scenarios.chat': 'Q&A Chat',
    'scenarios.chat.desc': 'Interactive conversations',
    
    // Benchmarks
    'benchmarks.title': 'Performance Benchmarks',
    'benchmarks.subtitle': 'How does Gemma 3n compare to competitors? Here are the benchmarks.',
    'benchmarks.source': 'Data sourced from official Google AI publications and independent benchmarks.',
    'benchmarks.heading': 'Performance Benchmarks',
    'benchmarks.efficiency_champion_title': 'Efficiency Champion',
    'benchmarks.efficiency_champion': 'Gemma 3n E4B achieves 79.8% MMLU with only 4B parameters, outperforming Llama 3.1 8B (66.7%) while using half the memory.',
    'benchmarks.mobile_first_design_title': 'Mobile-First Design',
    'benchmarks.mobile_first_design': 'MatFormer architecture enables dynamic scaling, allowing the same model to run efficiently from smartphones to workstations.',
    'benchmarks.mmlu.title': 'MMLU',
    'benchmarks.mmlu.desc': 'Massive Multitask Language Understanding',
    'benchmarks.mmlu.note': 'Outperforms leading models in its class on this key knowledge and reasoning benchmark.',
    'benchmarks.lmarena.title': 'LMArena Score',
    'benchmarks.lmarena.desc': 'Human preference chatbot benchmark',
    'benchmarks.lmarena.max': 'of max observed',
    'benchmarks.lmarena.note': 'The first model under 10B parameters to break the 1300 barrier, showcasing strong conversational ability.',
    'benchmarks.vision.title': 'Vision Encoder Speed',
    'benchmarks.vision.desc': 'On-device performance (Pixel Edge TPU)',
    'benchmarks.vision.faster': 'Faster',
    'benchmarks.vision.compare': 'MobileNet-V5 vs SoViT',
    'benchmarks.vision.note': 'A massive speedup in vision processing with higher accuracy and a smaller memory footprint.',
    'benchmarks.table.title': 'Gemma 3n vs. Competition',
    'benchmarks.table.model': 'Model',
    'benchmarks.table.params': 'Parameters',
    'benchmarks.table.mmlu': 'MMLU',
    'benchmarks.table.gsm8k': 'GSM8K',
    'benchmarks.table.humaneval': 'HumanEval',
    'benchmarks.table.memory': 'Memory (GB)',
    'benchmarks.gemma_e4b': 'Gemma 3n E4B',
    'benchmarks.gemma_e2b': 'Gemma 3n E2B',
    'benchmarks.llama_3_8b': 'Llama 3.1 8B',
    'benchmarks.llama_3_3b': 'Llama 3.2 3B',
    'benchmarks.score': 'Score',
    'benchmarks.tag.superior': 'Superior performance',
    'benchmarks.tag.below': 'Below Gemma 3n E4B',
    'benchmarks.memory.note': 'Memory requirements are for full precision models.',

    // Toolkit
    'toolkit.title': 'Gemma 3n Toolkit - Complete Developer Resources',
    'toolkit.description': 'Comprehensive toolkit for Gemma 3n development. Includes Ollama setup, Hugging Face integration, iOS deployment guides, and model comparison tools.',
    'toolkit.h1': 'Gemma 3n Toolkit',
    'toolkit.subheading': 'Everything you need to get started with Gemma 3n development. From quick setup to advanced deployment strategies.',
    'toolkit.tag1': 'Ollama Ready',
    'toolkit.tag2': 'Hugging Face Compatible',
    'toolkit.tag3': 'iOS Optimized',
    'toolkit.resources.title': 'Official Resources',
    'toolkit.resources.description': 'Access the latest official documentation, research papers, and community discussions directly from Google and the open source community.',
    'toolkit.resources.google.title': 'Google Official',
    'toolkit.resources.google.deepmind_page': 'DeepMind Official Page',
    'toolkit.resources.google.deepmind_desc': 'Official model overview, architecture details, and performance benchmarks.',
    'toolkit.resources.google.ai_dev': 'AI for Developers',
    'toolkit.resources.google.ai_dev_desc': 'Technical documentation, API references, and integration guides.',
    'toolkit.resources.google.announcement': 'Official Announcement',
    'toolkit.resources.google.announcement_desc': 'Launch announcement, key features, and architectural innovations.',
    'toolkit.downloads.title': 'Download Models',
    'toolkit.downloads.huggingface': 'Hugging Face Hub',
    'toolkit.downloads.huggingface_desc': 'Official model repositories with multiple format options.',
    'toolkit.downloads.ollama': 'Ollama Library',
    'toolkit.downloads.ollama_desc': 'Easy one-command installation for local development.',
    'toolkit.downloads.ollama_link': 'View on Ollama',
    'toolkit.community.title': 'Community & Research',
    'toolkit.community.reddit': 'r/LocalLLaMA',
    'toolkit.community.reddit_desc': 'Active community discussions, benchmarks, and user experiences.',
    'toolkit.community.hackernews': 'Hacker News',
    'toolkit.community.hackernews_desc': 'Technical discussions and community feedback on Gemma 3n.',
    'toolkit.community.research': 'Research Projects',
    'toolkit.community.research_desc': 'Reverse engineering efforts and architectural analysis.',
    'toolkit.learning.title': 'Learning Resources',
    'toolkit.learning.unsloth': 'Unsloth Blog',
    'toolkit.learning.unsloth_desc': 'Fine-tuning guides and performance optimization techniques.',
    'toolkit.learning.hf_blog': 'Hugging Face Blog',
    'toolkit.learning.hf_blog_desc': 'Technical deep-dives and integration tutorials.',
    'cta.title': 'Ready to Build with Gemma 3n?',
    'cta.subtitle': 'Join thousands of developers already using Gemma 3n in production.',
    'cta.button1': 'Browse Tutorials',
    'cta.button2': 'Download Models',
    
    // Common
    'common.loading': 'Loading...',
    'common.error': 'Error',
    'common.retry': 'Try Again',
    'common.close': 'Close',
    'common.save': 'Save',
    'common.cancel': 'Cancel',
    'common.continue': 'Continue',
    'common.learn.more': 'Learn More',
    'common.get.started': 'Get Started',
    'common.view.all': 'View All',
    
    // PWA
    'pwa.install': 'Install App',
    'pwa.install.desc': 'Install Gemma-3n.net for offline access',
    'pwa.update': 'Update Available',
    'pwa.update.desc': 'A new version is available. Refresh to update.',
    'pwa.offline': 'You\'re offline',
    'pwa.offline.desc': 'Some features may be limited without internet connection.',
    
    // è¯­è¨€åˆ‡æ¢
    'lang.switch': 'Switch Language',
    'lang.current': 'English',

    // resources
    'resources.heading': 'Resources',
    'resources.subtitle': 'Essential links to get you started and building with Gemma 3n.',
    'resources.category.download': 'Download Models',
    'resources.category.api': 'Official APIs & Guides',
    'resources.download.hf.title': 'Hugging Face',
    'resources.download.hf.desc': 'Access all Gemma 3n models, GGUF versions, and community-tuned variants.',
    'resources.download.ollama.title': 'Ollama',
    'resources.download.ollama.desc': 'Pull and run Gemma 3n models with a single command on your local machine.',
    'resources.download.lmstudio.title': 'LM Studio',
    'resources.download.lmstudio.desc': 'Discover and run Gemma 3n through a user-friendly desktop application.',
    'resources.api.studio.title': 'Google AI Studio',
    'resources.api.studio.desc': 'Experiment with Gemma 3n models directly in your browser with Google\'s free tool.',
    'resources.api.keras.title': 'Keras',
    'resources.api.keras.desc': 'Utilize Gemma 3n with Keras, Google\'s high-level API for building and training models.',
    'resources.api.paper.title': 'Technical Report',
    'resources.api.paper.desc': 'Read the official paper from Google for a deep dive into Gemma 3n\'s architecture.',

    // Demo é¡µé¢ä¸»ç»“æ„
    'demo.page.title': 'AI Demo | Interactive Experience',
    'demo.page.description': 'Experience the power of Gemma 3n - run AI models directly in your browser, no installation required.',
    'demo.hero.title': 'Gemma 3n Interactive Experience',
    'demo.hero.subtitle': 'Experience powerful AI features directly in your browser. Code completion â€¢ Language translation â€¢ Intelligent Q&A',
    'demo.hero.feature1.title': 'Ultra-fast Response',
    'demo.hero.feature1.desc': 'Millisecond-level AI inference, real-time interaction',
    'demo.hero.feature2.title': 'Privacy First',
    'demo.hero.feature2.desc': 'All data processed locally, never uploaded to the cloud',
    'demo.hero.feature3.title': 'Multi-scenario Support',
    'demo.hero.feature3.desc': 'Coding, translation, chat â€” one model for all',
    'demo.hero.cta': 'Try Now â†’',
    'demo.section.title': 'Interactive AI Demo',
    'demo.section.desc': 'This is a simulated version showing how Gemma 3n works in real-world scenarios. For production, use ONNX.js or WebAssembly to run the real model.',
    'demo.info.title': 'About this Demo',
    'demo.info.current.title': 'Current Features',
    'demo.info.current.feature1': 'Simulates Gemma 3n inference process and response style',
    'demo.info.current.feature2': 'Realistic UI and interaction flow',
    'demo.info.current.feature3': 'Performance metrics based on real hardware data',
    'demo.info.current.feature4': 'Supports three core application scenarios',
    'demo.info.prod.title': 'Production Version',
    'demo.info.prod.feature1': 'Load real Gemma 3n model with ONNX.js',
    'demo.info.prod.feature2': 'Accelerated inference with WebAssembly',
    'demo.info.prod.feature3': 'Full tokenizer and post-processing pipeline',
    'demo.info.prod.feature4': 'Supports model quantization and optimization',
    'demo.tech.title': 'Technical Implementation Path',
    'demo.tech.desc': 'Upgrade the demo to a full-fledged AI application tech stack',
    'demo.tech.frontend.title': 'Frontend Architecture',
    'demo.tech.frontend.engine': 'Lightweight Inference Engine',
    'demo.tech.frontend.engine.code': "// ONNX.js integration\nimport * as ort from 'onnxruntime-web';\n\n// Load model\nconst session = await ort.InferenceSession\n  .create('/models/gemma-3n-e2b.onnx');\n\n// Inference\nconst results = await session.run(feeds);",
    'demo.tech.frontend.wasm': 'WebAssembly Optimization',
    'demo.tech.frontend.wasm.code': "// WebAssembly tokenizer\nimport init, { tokenize } from './pkg/tokenizer.js';\n\n// Initialize WASM module\nawait init();\n\n// High-performance tokenization\nconst tokens = tokenize(inputText);",
    'demo.tech.deploy.title': 'Model Deployment',
    'demo.tech.deploy.convert': 'Model Conversion',
    'demo.tech.deploy.convert1': 'Hugging Face â†’ ONNX',
    'demo.tech.deploy.convert2': 'Dynamic quantization (INT8)',
    'demo.tech.deploy.convert3': 'Graph optimization and constant folding',
    'demo.tech.deploy.convert4': 'WebGL backend adaptation',
    'demo.tech.deploy.cdn': 'CDN Distribution',
    'demo.tech.deploy.cdn1': 'Global acceleration with Cloudflare',
    'demo.tech.deploy.cdn2': 'Chunked download strategy',
    'demo.tech.deploy.cdn3': 'Browser cache optimization',
    'demo.tech.deploy.cdn4': 'Progressive loading',
    'demo.tech.deploy.optimize': 'Performance Optimization',
    'demo.tech.deploy.optimize1': 'Web Workers multithreading',
    'demo.tech.deploy.optimize2': 'SharedArrayBuffer',
    'demo.tech.deploy.optimize3': 'WebGPU acceleration (future)',
    'demo.tech.deploy.optimize4': 'Memory pool management',
    'demo.tech.cost.title': 'Zero-cost Solution Advantages',
    'demo.tech.cost.cloud': 'Traditional Cloud AI Cost',
    'demo.tech.cost.cloud1': 'ğŸ”´ OpenAI API: $0.002/1K tokens',
    'demo.tech.cost.cloud2': 'ğŸ”´ Azure OpenAI: $0.0015/1K tokens',
    'demo.tech.cost.cloud3': 'ğŸ”´ Google Cloud AI: $0.001/1K tokens',
    'demo.tech.cost.cloud4': 'ğŸ”´ Monthly: $200-2000 (medium traffic)',
    'demo.tech.cost.device': 'Gemma 3n On-device Solution',
    'demo.tech.cost.device1': 'âœ… Inference cost: $0',
    'demo.tech.cost.device2': 'âœ… CDN: $0 (Cloudflare free tier)',
    'demo.tech.cost.device3': 'âœ… Storage: $0 (static hosting)',
    'demo.tech.cost.device4': 'âœ… Monthly: $0 + $12/year domain',
    'demo.cta.title': 'Ready to build your AI app?',
    'demo.cta.desc': 'Start with tutorials and master the power of Gemma 3n step by step.',
    'demo.cta.learn': 'Start Learning',
    'demo.cta.toolkit': 'Toolkit',
    'demo.cta.download': 'Download Model',

    // FAQåŒºå—
    'faq.heading': 'Frequently Asked Questions',
    'faq.subtitle': "Got questions? We've got answers. Here are some of the most common things developers ask about Gemma 3n.",
    'faq.q1': 'Is Gemma 3n free to use?',
    'faq.a1': 'Yes, Gemma 3n models are released under a license that permits free access for commercial and research use. Always check the official license terms for details.',
    'faq.q2': "What does 'multimodal' actually mean for Gemma 3n?",
    'faq.a2': 'It means the model can natively understand and process more than just text. It can analyze images and listen to audio, making it suitable for a wider range of applications like describing photos or transcribing speech.',
    'faq.q3': 'How is Gemma 3n different from the regular Gemma 2 or Gemma family?',
    'faq.a3': 'Gemma 3n is specifically optimized for on-device performance. It uses the novel MatFormer architecture to be more efficient in terms of memory and computation, making it ideal for running on phones and laptops.',
    'faq.q4': 'Can I fine-tune Gemma 3n on my own data?',
    'faq.a4': 'Absolutely. The models are designed to be fine-tuned. Google provides recipes and support through frameworks like Keras, PyTorch, and JAX to facilitate this process.',
    'faq.q5': 'How do I run Gemma 3n with Ollama?',
    'faq.a5': "Running Gemma 3n with Ollama is straightforward. Simply install Ollama and run 'ollama run gemma-3n:e4b' for the 4B model or 'ollama run gemma-3n:e2b' for the 2B model. The model will be downloaded automatically.",
    'faq.q6': "What's the difference between Gemma 3n E2B and E4B models?",
    'faq.a6': 'E2B (2B parameters) is smaller and faster, ideal for mobile devices and quick inference. E4B (4B parameters) offers better performance and accuracy but requires more computational resources. Both use the same MatFormer architecture.',
    'faq.q7': 'Can I use Gemma 3n models from Hugging Face?',
    'faq.a7': 'Yes, all Gemma 3n models are available on Hugging Face Hub. You can use them with the transformers library: from transformers import AutoModelForCausalLM, AutoTokenizer. Both 16-bit and quantized versions are available.',
    'faq.q8': 'Is Gemma 3n better than Llama 3 for local AI setups?',
    'faq.a8': "Gemma 3n E4B often outperforms Llama 3 8B in many benchmarks while being smaller and more efficient. For on-device applications, Gemma 3n's MatFormer architecture provides better memory efficiency and faster inference.",
    'faq.q9': 'Can I run Gemma 3n on iOS devices?',
    'faq.a9': 'Yes, Gemma 3n models can run on iOS devices. The E2B model is particularly well-suited for mobile deployment. You can use frameworks like CoreML or run quantized versions for optimal performance on Apple devices.',
    'faq.q10': 'What hardware requirements does Gemma 3n have?',
    'faq.a10': 'Gemma 3n E2B can run on devices with as little as 4GB RAM. E4B typically requires 8GB+ RAM for comfortable operation. Both models can run on CPU-only setups, though GPU acceleration significantly improves inference speed.',
    
    // newsletter
    'newsletter.heading': 'Stay Updated',
    'newsletter.desc': 'Get the latest tutorials and news about Gemma 3n delivered to your inbox. No spam, ever.',
    'newsletter.placeholder': 'Enter your email',
    'newsletter.subscribe': 'Subscribe',

    'footer.independent': 'An independent, community-driven guide to Googleâ€™s Gemma 3n.',
    'footer.rights': 'All rights reserved.',
    'footer.stay_updated': 'Stay Updated',
    'footer.subscribe_desc': 'Get the latest Gemma 3n news, tutorials, and benchmarks delivered to your inbox.',
    'footer.subscribe_button': 'Subscribe',
    'footer.privacy': 'Privacy Policy',
    'footer.terms': 'Terms of Service',

    // Blog
    'blog.title': 'Gemma 3n Developer Blog',
    'blog.description': 'News, tutorials, and in-depth articles on the Gemma 3n AI model.',
    'blog.read_more': 'Read More',
    'blog.giscus.comments': 'Comments',
    'blog.table_of_contents': 'Table of Contents',
    'blog.last_updated': 'Last Updated',
    'blog.share': 'Share This Post',
    'blog.share.twitter': 'Share on Twitter',
    'blog.share.linkedin': 'Share on LinkedIn',
    'blog.share.facebook': 'Share on Facebook',
    'blog.share.copy': 'Copy Link',
    'blog.share.copied': 'Copied!',

    // å¯¹æ¯”é¡µé¢
    'compare.title': "Gemma 3n vs. Llama 3: ç»ˆæå¯¹å†³",
    'compare.description': "æ·±åº¦æ•°æ®é©±åŠ¨å¯¹æ¯” Google Gemma 3n ä¸ Meta Llama 3ã€‚æˆ‘ä»¬åˆ†æåŸºå‡†æµ‹è¯•ã€ç¡¬ä»¶éœ€æ±‚å’Œä½¿ç”¨åœºæ™¯ï¼ŒåŠ©ä½ é€‰æ‹©æœ€é€‚åˆä½ é¡¹ç›®çš„æ¨¡å‹ã€‚",
    'compare.h1': "Gemma 3n <span class='text-blue-600'>å¯¹å†³</span> Llama 3",
    'compare.subheading': "æ•ˆç‡ä¸æ€§èƒ½çš„ç¢°æ’ã€‚æˆ‘ä»¬æ·±å…¥å‰–æä¸¤å¤§é¢†å…ˆå¼€æºæ¨¡å‹ï¼ŒåŠ©ä½ æ ¹æ®å…·ä½“éœ€æ±‚åšå‡ºæœ€ç»ˆå†³ç­–ã€‚",
    'compare.showdown_badge': "æ¨¡å‹å¯¹å†³",
    'compare.glance.title': "é€Ÿè§ˆï¼šæ ¸å¿ƒå·®å¼‚",
    'compare.glance.feature': "ç‰¹æ€§",
    'compare.glance.gemma': "Gemma 3n (E4B)",
    'compare.glance.llama': "Llama 3 (8B)",
    'compare.glance.architecture': "æ¶æ„",
    'compare.glance.architecture.gemma': "MatFormer (åŠ¨æ€ç¼©æ”¾)",
    'compare.glance.architecture.llama': "æ ‡å‡† Transformer",
    'compare.glance.params': "æœ‰æ•ˆå‚æ•°",
    'compare.glance.params.gemma': "~40äº¿",
    'compare.glance.params.llama': "80äº¿",
    'compare.glance.strength': "æ ¸å¿ƒä¼˜åŠ¿",
    'compare.glance.strength.gemma': "ç«¯ä¾§æ€§èƒ½, é«˜æ•ˆç‡",
    'compare.glance.strength.llama': "åŸå§‹æ¨ç† & ç¼–ç¨‹èƒ½åŠ›",
    'compare.glance.hardware': "ç¡¬ä»¶éœ€æ±‚",
    'compare.glance.hardware.gemma': "<span class='font-semibold text-green-600 dark:text-green-400'>ä½</span> (ç°ä»£ç¬”è®°æœ¬)",
    'compare.glance.hardware.llama': "<span class='font-semibold text-orange-500'>ä¸­</span> (éœ€è¦è‰¯å¥½GPU)",
    'compare.glance.multimodality': "å¤šæ¨¡æ€èƒ½åŠ›",
    'compare.glance.multimodality.gemma': "åŸç”Ÿæ”¯æŒæ–‡æœ¬ã€éŸ³é¢‘ã€å›¾åƒ",
    'compare.glance.multimodality.llama': "ä»…æ–‡æœ¬",
    'compare.benchmarks.title': "æ€§èƒ½åŸºå‡†æµ‹è¯•",
    'compare.benchmarks.note': "*åŸºå‡†åˆ†æ•°æ˜¯åŸºäºå…¬å¼€èšåˆæ•°æ®çš„è¯´æ˜æ€§å±•ç¤ºã€‚",
    'compare.deepdive.title': "æ·±åº¦åˆ†æ",
    'compare.deepdive.gemma.title': "ğŸ† Gemma 3n çš„èƒœå‡ºä¹‹å¤„",
    'compare.deepdive.gemma.1.title': "æ•ˆç‡ä¸å¯åŠæ€§",
    'compare.deepdive.gemma.1.desc': "åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ï¼ˆç¬”è®°æœ¬ã€æ‰‹æœºï¼‰ä¸Šæµç•…è¿è¡Œï¼ŒRAMå ç”¨æ˜¾è‘—å‡å°‘ï¼Œæ˜¯ç«¯ä¾§åº”ç”¨çš„å®Œç¾é€‰æ‹©ã€‚",
    'compare.deepdive.gemma.2.title': "åŸç”Ÿå¤šæ¨¡æ€",
    'compare.deepdive.gemma.2.desc': "ä»åº•å±‚è®¾è®¡å°±æ”¯æŒåœ¨å•ä¸€æ¨¡å‹ä¸­ç†è§£æ–‡æœ¬ã€éŸ³é¢‘å’Œå›¾åƒï¼Œè§£é”äº†Llamaæ— æ³•å•ç‹¬å¤„ç†çš„æ–°å‹åº”ç”¨ã€‚",
    'compare.deepdive.gemma.3.title': "åŠ¨æ€æ¶æ„",
    'compare.deepdive.gemma.3.desc': "MatFormeræ¶æ„ä½¿å…¶èƒ½åŠ¨æ€è°ƒæ•´è®¡ç®—é‡ï¼Œæ— éœ€å·¨å¤§çš„é™æ€å‚æ•°å³å¯æä¾›å‡è¡¡çš„æ€§èƒ½ã€‚",
    'compare.deepdive.llama.title': "ğŸ† Llama 3 çš„èƒœå‡ºä¹‹å¤„",
    'compare.deepdive.llama.1.title': "åŸå§‹æ¨ç†ä¸ç¼–ç¨‹èƒ½åŠ›",
    'compare.deepdive.llama.1.desc': "å‡­å€Ÿæ›´å¤šä¸“ç”¨å‚æ•°ï¼ŒLlama 3åœ¨å¤æ‚é€»è¾‘æ¨ç†ã€æ•°å­¦é—®é¢˜å’Œä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œçº¯æ–‡æœ¬åŸºå‡†æµ‹è¯•é€šå¸¸ä¼˜äºGemmaã€‚",
    'compare.deepdive.llama.2.title': "æˆç†Ÿçš„å¾®è°ƒç”Ÿæ€",
    'compare.deepdive.llama.2.desc': "ä½œä¸ºä¸€ä¸ªæ›´æˆç†Ÿçš„æ¶æ„ï¼Œç¤¾åŒºä¸ºLlama 3è´¡çŒ®äº†å¤§é‡é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒç‰ˆæœ¬ã€‚",
    'compare.deepdive.llama.3.title': "å¯é¢„æµ‹çš„æ€§èƒ½",
    'compare.deepdive.llama.3.desc': "å…¶æ ‡å‡†Transformeræ¶æ„æ„å‘³ç€æ€§èƒ½éå¸¸å¯é¢„æµ‹ï¼Œå¹¶ä¸”èƒ½éšæ›´å¼ºå¤§çš„ç¡¬ä»¶å¾ˆå¥½åœ°æ‰©å±•ã€‚",
    'compare.verdict.title': "æœ€ç»ˆè£å†³ï¼šå“ªæ¬¾é€‚åˆä½ ï¼Ÿ",
    'compare.verdict.subtitle': "ä½ çš„é€‰æ‹©å®Œå…¨å–å†³äºé¡¹ç›®çš„æ ¸å¿ƒç›®æ ‡ã€‚",
    'compare.verdict.gemma.title': "é€‰æ‹© Gemma 3n å¦‚æœ...",
    'compare.verdict.gemma.bullet1': "ä½ æ­£åœ¨ä¸º**ç§»åŠ¨æˆ–è¾¹ç¼˜è®¾å¤‡**æ„å»ºåº”ç”¨ã€‚",
    'compare.verdict.gemma.bullet2': "ä½ çš„åº”ç”¨éœ€è¦**å¤šæ¨¡æ€èƒ½åŠ›**ï¼ˆéŸ³é¢‘/è§†è§‰ï¼‰ã€‚",
    'compare.verdict.gemma.bullet3': "**èµ„æºæ•ˆç‡**å’Œä½RAMå ç”¨è‡³å…³é‡è¦ã€‚",
    'compare.verdict.gemma.bullet4': "ä½ éœ€è¦ä¸€ä¸ªç”¨äºé€šç”¨ä»»åŠ¡çš„ã€å‡è¡¡çš„å…¨é¢æ¨¡å‹ã€‚",
    'compare.verdict.llama.title': "é€‰æ‹© Llama 3 å¦‚æœ...",
    'compare.verdict.llama.bullet1': "ä½ çš„ä¸»è¦ç”¨ä¾‹æ˜¯**å¤æ‚çš„ç¼–ç¨‹æˆ–æ¨ç†**ã€‚",
    'compare.verdict.llama.bullet2': "ä½ æ‹¥æœ‰**å¼ºå¤§çš„GPU**ã€‚",
    'compare.verdict.llama.bullet3': "ä½ éœ€è¦åœ¨**çº¯æ–‡æœ¬ä»»åŠ¡**ä¸Šè·å¾—ç»å¯¹æœ€ä½³æ€§èƒ½ã€‚",
    'compare.verdict.llama.bullet4': "ä½ æƒ³åˆ©ç”¨åºå¤§çš„ç¤¾åŒºå¾®è°ƒæ¨¡å‹åº“ã€‚",
    'compare.cta.title': "å‡†å¤‡å¥½æ·±å…¥æ¢ç´¢äº†å—ï¼Ÿ",
    'compare.cta.subtitle': "æµè§ˆæˆ‘ä»¬çš„å®æˆ˜æ•™ç¨‹ï¼ŒæŒæ¡è¿™ä¸¤æ¬¾æ¨¡å‹ã€‚",
    'compare.cta.button1': "æµè§ˆå…¨éƒ¨æ•™ç¨‹",
    'compare.cta.button2': "è·å–å·¥å…·ç®±",

    // Leaderboard Page
    'leaderboard.title': "AI Model Leaderboard: The Best Open Source Models",
    'leaderboard.description': "A data-driven, sortable leaderboard comparing the top open-source AI models like Gemma 3n, Llama 3, Phi-3, and Qwen 2. Filter by benchmarks like MMLU, GSM8K, and HumanEval.",
    'leaderboard.h1': "Open Model Leaderboard",
    'leaderboard.subheading': "The definitive, data-driven ranking of today's top open-source AI models. Sort, compare, and find the best model for your needs.",
    'leaderboard.badge': "Community Benchmark",
    'leaderboard.table.rank': "Rank",
    'leaderboard.table.model': "Model",
    'leaderboard.table.params': "Params (B)",
    'leaderboard.table.mmlu': "MMLU",
    'leaderboard.table.gsm8k': "GSM8K",
    'leaderboard.table.humaneval': "HumanEval",
    'leaderboard.table.tags': "Tags",
    'leaderboard.notes.definitions': "* MMLU: Massive Multitask Language Understanding. GSM8K: Grade School Math. HumanEval: Code Generation.",
    'leaderboard.notes.disclaimer': "* Performance data is based on publicly available information and may vary based on quantization and implementation.",
    'leaderboard.tags.reasoning': "Reasoning Power",
    'leaderboard.tags.efficiency': "Efficiency King",
    'leaderboard.tags.multimodal': "Multimodal",
    'leaderboard.tags.coder': "Strong Coder",
    'leaderboard.tags.on_device': "On-Device",
    'leaderboard.tags.fast': "Fast",

    // Privacy and Terms
    'privacy.title': "Privacy Policy",
    'privacy.h1': "Privacy Policy for Gemma-3n.net",
    'privacy.effective_date': "Effective Date: July 1, 2025",
    'privacy.p1': "Welcome to Gemma-3n.net. We are committed to protecting your privacy. This Privacy Policy explains how we collect, use, disclose, and safeguard your information when you visit our website. Please read this privacy policy carefully. If you do not agree with the terms of this privacy policy, please do not access the site.",
    'privacy.h2_info': "Collection of Your Information",
    'privacy.p2': "We may collect information about you in a variety of ways. The information we may collect on the Site includes:",
    'privacy.h3_personal': "Personal Data",
    'privacy.p3': "Personally identifiable information, such as your email address, that you voluntarily give to us when you subscribe to our newsletter.",
    'privacy.h3_analytics': "Derivative Data",
    'privacy.p4': "Information our servers automatically collect when you access the Site, such as your IP address, your browser type, your operating system, your access times, and the pages you have viewed directly before and after accessing the Site. We use a privacy-focused analytics service and do not use Google Analytics.",
    'privacy.h2_use': "Use of Your Information",
    'privacy.p5': "Having accurate information about you permits us to provide you with a smooth, efficient, and customized experience. Specifically, we may use information collected about you via the Site to: email you regarding your account or order, respond to customer service requests, and send you a newsletter.",
    'privacy.h2_security': "Security of Your Information",
    'privacy.p6': "We use administrative, technical, and physical security measures to help protect your personal information. While we have taken reasonable steps to secure the personal information you provide to us, please be aware that despite our efforts, no security measures are perfect or impenetrable, and no method of data transmission can be guaranteed against any interception or other type of misuse.",
    'privacy.h2_contact': "Contact Us",
    'privacy.p7': "If you have questions or comments about this Privacy Policy, please contact us at: legal@gemma-3n.net",

    'terms.title': "Terms of Service",
    'terms.h1': "Terms of Service for Gemma-3n.net",
    'terms.effective_date': "Effective Date: July 1, 2025",
    'terms.p1': "By using the website located at Gemma-3n.net (the \"Site\"), you agree to be bound by these Terms of Service (this \"Agreement\"), whether or not you register as a member. If you do not agree with these terms, you should not use the Site.",
    'terms.h2_use': "Use of the Site",
    'terms.p2': "You may use the Site for your personal, non-commercial use only. You agree not to use the Site for any purpose that is unlawful or prohibited by this Agreement. You may not use the Site in any manner that could damage, disable, overburden, or impair the Site.",
    'terms.h2_disclaimer': "Disclaimer",
    'terms.p3': "The information provided on the Site is for general informational purposes only. All information on the Site is provided in good faith, however we make no representation or warranty of any kind, express or implied, regarding the accuracy, adequacy, validity, reliability, availability or completeness of any information on the Site.",
    'terms.h2_liability': "Limitation of Liability",
    'terms.p4': "IN NO EVENT WILL WE OR OUR DIRECTORS, EMPLOYEES, OR AGENTS BE LIABLE TO YOU OR ANY THIRD PARTY FOR ANY DIRECT, INDIRECT, CONSEQUENTIAL, EXEMPLARY, INCIDENTAL, SPECIAL, OR PUNITIVE DAMAGES, INCLUDING LOST PROFIT, LOST REVENUE, LOSS OF DATA, OR OTHER DAMAGES ARISING FROM YOUR USE OF THE SITE, EVEN IF WE HAVE BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.",
    'terms.h2_governing': "Governing Law",
    'terms.p5': "This Agreement shall be governed by and construed in accordance with the laws of the State of California, without regard to its conflict of law principles.",
    'terms.h2_contact': "Contact Us",
    'terms.p6': "If you have questions or comments about these Terms of Service, please contact us at: legal@gemma-3n.net",
  },
  zh: {
    // å¯¼èˆª
    'nav.home': 'é¦–é¡µ',
    'nav.about': 'å…³äº',
    'nav.benchmarks': 'æ€§èƒ½æµ‹è¯•',
    'nav.blog': 'åšå®¢',
    'nav.toolkit': 'å·¥å…·ç®±',
    'nav.resources': 'èµ„æº',
    'nav.faq': 'å¸¸è§é—®é¢˜',
    'nav.demo': 'æ¼”ç¤º',
    'nav.compare': 'å¯¹æ¯”',
    'nav.leaderboard': 'æ’è¡Œæ¦œ',
    
    // é¦–é¡µ
    'hero.title': 'Gemma-3n.net: ç»ˆæå¼€å‘è€…æŒ‡å—',
    'hero.subtitle': 'é€šè¿‡å…¨é¢çš„æ•™ç¨‹ã€åŸºå‡†æµ‹è¯•å’Œå·¥å…·ï¼ŒæŒæ¡Googleçš„Gemma 3n AIæ¨¡å‹ã€‚',
    'hero.cta.primary': 'å¼€å§‹ä½¿ç”¨',
    'hero.cta.secondary': 'æŸ¥çœ‹æ¼”ç¤º',
    
    // SEO
    'seo.home.title': 'Gemma-3n.net: Google Gemma 3n ç»ˆæå¼€å‘è€…æŒ‡å—',
    'seo.home.description': 'é€šè¿‡å…¨é¢çš„æ•™ç¨‹ã€åŸºå‡†æµ‹è¯•å’Œå·¥å…·ï¼ŒæŒæ¡Googleçš„Gemma 3n AIæ¨¡å‹ã€‚æ‚¨è¿›è¡Œæœ¬åœ°å’Œäº‘ç«¯éƒ¨ç½²çš„é‡è¦èµ„æºã€‚',
    'seo.about.title': 'å…³äº Gemma-3n.net | æˆ‘ä»¬çš„ä½¿å‘½ä¸æ–¹æ³•è®º',
    'seo.about.description': 'äº†è§£ Gemma-3n.net çš„ä½¿å‘½ï¼šä¸ºGemma 3nå¼€å‘è€…ç¤¾åŒºæä¾›æœ€å‡†ç¡®ã€ç‹¬ç«‹å’Œæœ€æ–°çš„èµ„æºã€‚',
    'seo.blog.title': 'Gemma 3n åšå®¢ | æ•™ç¨‹ã€æ–°é—»ä¸æ·±åº¦åˆ†æ',
    'seo.blog.description': 'Gemma-3n.net çš„å®˜æ–¹åšå®¢ã€‚æŸ¥æ‰¾å…³äºå¾®è°ƒã€éƒ¨ç½²å’Œä¼˜åŒ–Gemma 3næ¨¡å‹çš„æœ€æ–°æ¶ˆæ¯ã€ä¸“å®¶æ•™ç¨‹å’Œæ·±åº¦æ–‡ç« ã€‚',
    'seo.toolkit.title': 'Gemma 3n å·¥å…·ç®± | ä¸‹è½½ã€æŒ‡å—å’Œå®˜æ–¹èµ„æº',
    'seo.toolkit.description': 'Gemma 3n çš„å®Œæ•´å¼€å‘è€…å·¥å…·ç®±ã€‚è·å–å®˜æ–¹æ¨¡å‹ä¸‹è½½ã€Ollamaå’ŒHugging Faceçš„è®¾ç½®æŒ‡å—ã€iOSéƒ¨ç½²æ–‡æ¡£ç­‰ã€‚',
    'seo.compare.title': 'Gemma 3n vs. Llama 3: AIæ¨¡å‹æ·±åº¦å¯¹æ¯”',
    'seo.compare.description': 'Googleçš„Gemma 3nä¸Metaçš„Llama 3çš„æ­£é¢æ•°æ®é©±åŠ¨å¯¹æ¯”ã€‚åˆ†ææ€§èƒ½åŸºå‡†ã€æ¶æ„å’ŒçœŸå®ä¸–ç•Œç”¨ä¾‹ã€‚',
    'seo.leaderboard.title': 'AIæ¨¡å‹æ’è¡Œæ¦œ | å¯¹æ¯”Gemma 3nã€Llama 3ç­‰',
    'seo.leaderboard.description': 'å®æ—¶çš„AIæ¨¡å‹æ’è¡Œæ¦œï¼Œæ¯”è¾ƒæœ€æ–°çš„å¼€æºå’Œä¸“æœ‰æ¨¡å‹åœ¨å…³é”®è¡Œä¸šåŸºå‡†ä¸Šçš„è¡¨ç°ã€‚æŸ¥çœ‹Gemma 3nä¸ç«äº‰å¯¹æ‰‹çš„è¾ƒé‡ã€‚',

    // Demo
    'demo.title': 'ğŸš€ Gemma 3n äº¤äº’å¼Demo',
    'demo.subtitle': 'ä½“éªŒæµè§ˆå™¨å†…AIæ¨ç† - å®Œå…¨æœ¬åœ°åŒ–ï¼Œæ— éœ€æœåŠ¡å™¨',
    'demo.loading.initializing': 'æ­£åœ¨åˆå§‹åŒ–è½»é‡çº§AIæ¨¡å‹...',
    'demo.loading.engine': 'ä¸‹è½½è½»é‡çº§æ¨ç†å¼•æ“...',
    'demo.loading.wasm': 'åˆå§‹åŒ–WebAssemblyæ¨¡å—...',
    'demo.loading.vocab': 'åŠ è½½è¯æ±‡è¡¨å’Œé…ç½®...',
    'demo.loading.weights': 'ä¼˜åŒ–æ¨¡å‹æƒé‡...',
    'demo.loading.ready': 'æ¨¡å‹å°±ç»ªï¼',
    'demo.status.ready': 'âœ… Gemma 3n Lite å·²å°±ç»ª (åœ¨çº¿Demoç‰ˆæœ¬)',
    'demo.scenarios.label': 'é€‰æ‹©æ¼”ç¤ºåœºæ™¯',
    'demo.scenarios.code.title': 'ä»£ç è¡¥å…¨',
    'demo.scenarios.code.description': 'æ™ºèƒ½ä»£ç å»ºè®®',
    'demo.scenarios.translate.title': 'è¯­è¨€ç¿»è¯‘',
    'demo.scenarios.translate.description': 'å¤šè¯­è¨€äº’è¯‘',
    'demo.scenarios.chat.title': 'æ™ºèƒ½é—®ç­”',
    'demo.scenarios.chat.description': 'å¯¹è¯åŠ©æ‰‹',
    'demo.input.label': 'è¾“å…¥æ–‡æœ¬',
    'demo.input.placeholder': 'è¾“å…¥æ‚¨çš„æ–‡æœ¬...',
    'demo.parameters.label': 'æ¸©åº¦è®¾ç½® (åˆ›é€ æ€§)',
    'demo.parameters.conservative': 'ä¿å®ˆ',
    'demo.parameters.creative': 'åˆ›æ–°',
    'demo.button.loading': 'æ¨¡å‹åŠ è½½ä¸­...',
    'demo.button.generate': 'ç”ŸæˆAIå›å¤',
    'demo.button.generating': 'ç”Ÿæˆä¸­...',
    'demo.output.label': 'AIè¾“å‡ºç»“æœ',
    'demo.output.placeholder': 'AIç”Ÿæˆçš„å†…å®¹å°†åœ¨è¿™é‡Œæ˜¾ç¤º...',
    'demo.output.thinking': 'ğŸ¤– AIæ­£åœ¨æ€è€ƒ...',
    'demo.output.error': 'âŒ ç”Ÿæˆå¤±è´¥:',
    'demo.alert.no_input': 'è¯·è¾“å…¥ä¸€äº›æ–‡æœ¬',
    'demo.metrics.tokensPerSecond': 'Tokens/ç§’',
    'demo.metrics.inferenceTime': 'æ¨ç†æ—¶é—´(ms)',
    'demo.metrics.memoryUsage': 'å†…å­˜ä½¿ç”¨(MB)',
    'demo.metrics.modelSize': 'æ¨¡å‹å¤§å°',
    'demo.placeholders.code': `function fibonacci(n) {
  // è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—
  if (n <= 1) return n;
  return`,
    'demo.placeholders.translate': `è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š
äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ä¸–ç•Œã€‚`,
    'demo.placeholders.chat': `ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£Gemma 3næ¨¡å‹çš„ç‰¹ç‚¹å’Œä¼˜åŠ¿ã€‚`,
    'demo.simulations.code_response': ` fibonacci(n - 1) + fibonacci(n - 2);
}

// ä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨åŠ¨æ€è§„åˆ’
function fibonacciDP(n) {
  const dp = [0, 1];
  for (let i = 2; i <= n; i++) {
    dp[i] = dp[i-1] + dp[i-2];
  }
  return dp[n];
}`,
    'demo.simulations.translation_response': `**ç¿»è¯‘ç»“æœ:**
äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ä¸–ç•Œã€‚

*æ£€æµ‹åˆ°çš„è¯­è¨€: ä¸­æ–‡ â†’ è‹±æ–‡*`,
    'demo.simulations.chat_response_1': `æ‚¨å¥½ï¼æˆ‘å¾ˆé«˜å…´ä¸ºæ‚¨ä»‹ç»Gemma 3nã€‚è¿™æ˜¯Googleæœ€æ–°å‘å¸ƒçš„å¤šæ¨¡æ€AIæ¨¡å‹ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

ğŸ¯ **è®¾å¤‡ç«¯ä¼˜åŒ–**: ä¸“ä¸ºæ‰‹æœºã€ç¬”è®°æœ¬ç­‰è®¾å¤‡è®¾è®¡
âš¡ **é«˜æ•ˆæ¶æ„**: MatFormer"åµŒå¥—"Transformerç»“æ„
ğŸ¨ **å¤šæ¨¡æ€èƒ½åŠ›**: æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å¤„ç†
ğŸ”§ **å¼€å‘è€…å‹å¥½**: ä¸ä¸»æµAIå·¥å…·ç”Ÿæ€å…¼å®¹

æ‚¨è¿˜æƒ³äº†è§£å“ªä¸ªæ–¹é¢çš„è¯¦ç»†ä¿¡æ¯ï¼Ÿ`,
    'demo.simulations.chat_response_2': `Gemma 3nç›¸æ¯”å…¶ä»–æ¨¡å‹çš„ä¼˜åŠ¿åœ¨äºï¼š

1. **æ›´å°çš„å†…å­˜å ç”¨**: E2Bç‰ˆæœ¬ä»…éœ€4GBå†…å­˜
2. **æ›´å¿«çš„æ¨ç†é€Ÿåº¦**: é’ˆå¯¹ç§»åŠ¨è®¾å¤‡ä¼˜åŒ–
3. **æ›´å¥½çš„å‡†ç¡®æ€§**: MMLUåŸºå‡†æµ‹è¯•è¾¾åˆ°79.8%
4. **æ›´å¼ºçš„å¤šæ¨¡æ€**: åŸç”Ÿæ”¯æŒè§†è§‰å’ŒéŸ³é¢‘

è¿™ä½¿å¾—å®ƒç‰¹åˆ«é€‚åˆæ„å»ºéšç§ä¼˜å…ˆçš„è®¾å¤‡ç«¯AIåº”ç”¨ã€‚`,
    'demo.simulations.chat_response_3': `å…³äºGemma 3nçš„æŠ€æœ¯å®ç°ï¼Œæˆ‘å»ºè®®æ‚¨ï¼š

ğŸ“š **å­¦ä¹ è·¯å¾„**: ä»æˆ‘ä»¬çš„å…¥é—¨æ•™ç¨‹å¼€å§‹
ğŸ’» **å®è·µé¡¹ç›®**: å°è¯•iOSéƒ¨ç½²æˆ–Ollamaé›†æˆ
ğŸ”§ **è¿›é˜¶æŠ€èƒ½**: å­¦ä¹ LoRAå¾®è°ƒæŠ€æœ¯
ğŸŒ **ç¤¾åŒºå‚ä¸**: å…³æ³¨æœ€æ–°çš„æ¨¡å‹æ›´æ–°å’Œä¼˜åŒ–

éœ€è¦æˆ‘ä¸ºæ‚¨æ¨èå…·ä½“çš„æ•™ç¨‹å—ï¼Ÿ`,
    
    // å‚æ•°æ§åˆ¶
    'controls.temperature': 'æ¸©åº¦å€¼',
    'controls.temperature.desc': 'æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§',
    'controls.maxTokens': 'æœ€å¤§é•¿åº¦',
    'controls.maxTokens.desc': 'ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦',
    'controls.topK': 'Top-K',
    'controls.topK.desc': 'é™åˆ¶è¯æ±‡è¡¨ä»¥è·å¾—æ›´é›†ä¸­çš„è¾“å‡º',
    
    // æ€§èƒ½ç›‘æ§
    'metrics.inference': 'æ¨ç†æ—¶é—´',
    'metrics.memory': 'å†…å­˜ä½¿ç”¨',
    'metrics.tokens': 'ä»¤ç‰Œ/ç§’',
    'metrics.local': 'æœ¬åœ°å¤„ç†',
    'metrics.api': 'APIè°ƒç”¨',
    
    // é¢„è®¾åœºæ™¯
    'scenarios.code': 'ä»£ç ç”Ÿæˆ',
    'scenarios.code.desc': 'ç”Ÿæˆå’Œè¡¥å…¨ä»£ç ',
    'scenarios.text': 'æ–‡æœ¬ç”Ÿæˆ',
    'scenarios.text.desc': 'åˆ›æ„å†™ä½œå’Œå†…å®¹åˆ›ä½œ',
    'scenarios.chat': 'é—®ç­”å¯¹è¯',
    'scenarios.chat.desc': 'äº¤äº’å¼å¯¹è¯',
    
    // å·¥å…·ç®±
    'toolkit.title': 'Gemma 3n å·¥å…·ç®± - å®Œæ•´çš„å¼€å‘è€…èµ„æº',
    'toolkit.description': 'Gemma 3n å¼€å‘çš„ç»¼åˆå·¥å…·ç®±ã€‚åŒ…æ‹¬ Ollama è®¾ç½®ã€Hugging Face é›†æˆã€iOS éƒ¨ç½²æŒ‡å—å’Œæ¨¡å‹æ¯”è¾ƒå·¥å…·ã€‚',
    'toolkit.h1': 'Gemma 3n Toolkit',
    'toolkit.subheading': 'æ‚¨å¼€å§‹ Gemma 3n å¼€å‘æ‰€éœ€çš„ä¸€åˆ‡ã€‚ä»å¿«é€Ÿè®¾ç½®åˆ°é«˜çº§éƒ¨ç½²ç­–ç•¥ã€‚',
    'toolkit.tag1': 'Ollama å°±ç»ª',
    'toolkit.tag2': 'Hugging Face å…¼å®¹',
    'toolkit.tag3': 'iOS ä¼˜åŒ–',
    'toolkit.resources.title': 'å®˜æ–¹èµ„æº',
    'toolkit.resources.description': 'ç›´æ¥ä»è°·æ­Œå’Œå¼€æºç¤¾åŒºè®¿é—®æœ€æ–°çš„å®˜æ–¹æ–‡æ¡£ã€ç ”ç©¶è®ºæ–‡å’Œç¤¾åŒºè®¨è®ºã€‚',
    'toolkit.resources.google.title': 'Google Official',
    'toolkit.resources.google.deepmind_page': 'DeepMind Official Page',
    'toolkit.resources.google.deepmind_desc': 'Official model overview, architecture details, and performance benchmarks.',
    'toolkit.resources.google.ai_dev': 'AI for Developers',
    'toolkit.resources.google.ai_dev_desc': 'Technical documentation, API references, and integration guides.',
    'toolkit.resources.google.announcement': 'Official Announcement',
    'toolkit.resources.google.announcement_desc': 'Launch announcement, key features, and architectural innovations.',
    'toolkit.downloads.title': 'Download Models',
    'toolkit.downloads.huggingface': 'Hugging Face Hub',
    'toolkit.downloads.huggingface_desc': 'Official model repositories with multiple format options.',
    'toolkit.downloads.ollama': 'Ollama Library',
    'toolkit.downloads.ollama_desc': 'Easy one-command installation for local development.',
    'toolkit.downloads.ollama_link': 'View on Ollama',
    'toolkit.community.title': 'Community & Research',
    'toolkit.community.reddit': 'r/LocalLLaMA',
    'toolkit.community.reddit_desc': 'Active community discussions, benchmarks, and user experiences.',
    'toolkit.community.hackernews': 'Hacker News',
    'toolkit.community.hackernews_desc': 'Technical discussions and community feedback on Gemma 3n.',
    'toolkit.community.research': 'Research Projects',
    'toolkit.community.research_desc': 'Reverse engineering efforts and architectural analysis.',
    'toolkit.learning.title': 'Learning Resources',
    'toolkit.learning.unsloth': 'Unsloth Blog',
    'toolkit.learning.unsloth_desc': 'Fine-tuning guides and performance optimization techniques.',
    'toolkit.learning.hf_blog': 'Hugging Face Blog',
    'toolkit.learning.hf_blog_desc': 'Technical deep-dives and integration tutorials.',
    'cta.title': 'Ready to Build with Gemma 3n?',
    'cta.subtitle': 'Join thousands of developers already using Gemma 3n in production.',
    'cta.button1': 'Browse Tutorials',
    'cta.button2': 'Download Models',
    
    // é€šç”¨
    'common.loading': 'åŠ è½½ä¸­...',
    'common.error': 'é”™è¯¯',
    'common.retry': 'é‡è¯•',
    'common.close': 'å…³é—­',
    'common.save': 'ä¿å­˜',
    'common.cancel': 'å–æ¶ˆ',
    'common.continue': 'ç»§ç»­',
    'common.learn.more': 'äº†è§£æ›´å¤š',
    'common.get.started': 'å¼€å§‹ä½¿ç”¨',
    'common.view.all': 'æŸ¥çœ‹å…¨éƒ¨',
    
    // PWA
    'pwa.install': 'å®‰è£…åº”ç”¨',
    'pwa.install.desc': 'å®‰è£… Gemma-3n.net ä»¥ä¾¿ç¦»çº¿è®¿é—®',
    'pwa.update': 'æœ‰å¯ç”¨æ›´æ–°',
    'pwa.update.desc': 'æ–°ç‰ˆæœ¬å¯ç”¨ï¼Œåˆ·æ–°é¡µé¢ä»¥æ›´æ–°ã€‚',
    'pwa.offline': 'æ‚¨å½“å‰ç¦»çº¿',
    'pwa.offline.desc': 'æ²¡æœ‰ç½‘ç»œè¿æ¥æ—¶æŸäº›åŠŸèƒ½å¯èƒ½å—é™ã€‚',

    // è¯­è¨€åˆ‡æ¢
    'lang.switch': 'åˆ‡æ¢è¯­è¨€',
    'lang.current': 'ä¸­æ–‡',

    // åŸºå‡†æµ‹è¯•
    'benchmarks.title': 'æ€§èƒ½åŸºå‡†',
    'benchmarks.subtitle': 'Gemma 3n ä¸ç«äº‰å¯¹æ‰‹ç›¸æ¯”è¡¨ç°å¦‚ä½•ï¼Ÿè¿™é‡Œæ˜¯æ•°æ®å¯¹æ¯”ã€‚',
    'benchmarks.source': 'æ•°æ®æ¥æºäºGoogle AIå®˜æ–¹å‘å¸ƒå’Œç‹¬ç«‹åŸºå‡†æµ‹è¯•ã€‚',
    'benchmarks.heading': 'æ€§èƒ½åŸºå‡†',
    'benchmarks.mmlu.title': 'MMLU',
    'benchmarks.mmlu.desc': 'å¤šä»»åŠ¡è¯­è¨€ç†è§£èƒ½åŠ›',
    'benchmarks.mmlu.note': 'åœ¨è¯¥å…³é”®çŸ¥è¯†ä¸æ¨ç†åŸºå‡†ä¸Šè¶…è¶ŠåŒçº§ä¸»æµæ¨¡å‹',
    'benchmarks.lmarena.title': 'LMArena å¾—åˆ†',
    'benchmarks.lmarena.desc': 'äººç±»åå¥½å¯¹è¯åŸºå‡†',
    'benchmarks.lmarena.max': 'æœ€å¤§åˆ†æ•°å æ¯”',
    'benchmarks.lmarena.note': 'é¦–ä¸ªçªç ´1300åˆ†çš„10Bä»¥ä¸‹æ¨¡å‹ï¼Œå±•ç°å¼ºå¤§å¯¹è¯èƒ½åŠ›',
    'benchmarks.vision.title': 'è§†è§‰ç¼–ç é€Ÿåº¦',
    'benchmarks.vision.desc': 'è®¾å¤‡ç«¯è§†è§‰æ¨ç†æ€§èƒ½ï¼ˆPixel Edge TPUï¼‰',
    'benchmarks.vision.faster': 'åŠ é€Ÿ',
    'benchmarks.vision.compare': 'MobileNet-V5 vs SoViT',
    'benchmarks.vision.note': 'è§†è§‰å¤„ç†é€Ÿåº¦å¤§å¹…æå‡ï¼Œç²¾åº¦æ›´é«˜ï¼Œå†…å­˜å ç”¨æ›´ä½',
    'benchmarks.table.title': 'Gemma 3n ä¸ç«å“å¯¹æ¯”',
    'benchmarks.table.model': 'æ¨¡å‹',
    'benchmarks.table.params': 'å‚æ•°é‡',
    'benchmarks.table.mmlu': 'MMLU',
    'benchmarks.table.gsm8k': 'GSM8K',
    'benchmarks.table.humaneval': 'HumanEval',
    'benchmarks.table.memory': 'å†…å­˜(GB)',
    'benchmarks.gemma_e4b': 'Gemma 3n E4B',
    'benchmarks.gemma_e2b': 'Gemma 3n E2B',
    'benchmarks.llama_3_8b': 'Llama 3.1 8B',
    'benchmarks.llama_3_3b': 'Llama 3.2 3B',
    'benchmarks.score': 'åˆ†æ•°',
    'benchmarks.tag.superior': 'æ€§èƒ½é¢†å…ˆ',
    'benchmarks.tag.below': 'ä½äº Gemma 3n E4B',
    'benchmarks.memory.note': 'å†…å­˜éœ€æ±‚ä¸ºå…¨ç²¾åº¦æ¨¡å‹é…ç½®ã€‚',
    'benchmarks.efficiency_champion_title': 'æ•ˆç‡ä¹‹ç‹',
    'benchmarks.efficiency_champion': 'Gemma 3n E4B ä»…ç”¨ 4B å‚æ•°å³è¾¾ 79.8% MMLUï¼Œæ€§èƒ½è¶…è¶Š Llama 3.1 8Bï¼ˆ66.7%ï¼‰ï¼Œå†…å­˜å ç”¨ä»…ä¸ºå…¶ä¸€åŠã€‚',
    'benchmarks.mobile_first_design_title': 'ç§»åŠ¨ä¼˜å…ˆè®¾è®¡',
    'benchmarks.mobile_first_design': 'MatFormer æ¶æ„æ”¯æŒåŠ¨æ€æ‰©å±•ï¼ŒåŒä¸€æ¨¡å‹å¯é«˜æ•ˆè¿è¡Œäºæ‰‹æœºåˆ°å·¥ä½œç«™ç­‰å¤šç§è®¾å¤‡ã€‚',

    // èµ„æºåŒºå—
    'resources.heading': 'èµ„æº',
    'resources.subtitle': 'å¼€å§‹ä½¿ç”¨ Gemma 3n çš„é‡è¦é“¾æ¥ã€‚',
    'resources.category.download': 'ä¸‹è½½æ¨¡å‹',
    'resources.category.api': 'å®˜æ–¹APIä¸æŒ‡å—',
    'resources.download.hf.title': 'Hugging Face',
    'resources.download.hf.desc': 'è·å–å…¨éƒ¨ Gemma 3n æ¨¡å‹ã€GGUF ç‰ˆæœ¬åŠç¤¾åŒºå¾®è°ƒæ¨¡å‹ã€‚',
    'resources.download.ollama.title': 'Ollama',
    'resources.download.ollama.desc': 'ä¸€è¡Œå‘½ä»¤æœ¬åœ°æ‹‰å–å¹¶è¿è¡Œ Gemma 3n æ¨¡å‹ã€‚',
    'resources.download.lmstudio.title': 'LM Studio',
    'resources.download.lmstudio.desc': 'æ¡Œé¢ç«¯å¯è§†åŒ–åº”ç”¨ï¼Œè½»æ¾ä½“éªŒå’Œè¿è¡Œ Gemma 3nã€‚',
    'resources.api.studio.title': 'Google AI Studio',
    'resources.api.studio.desc': 'æ— éœ€å®‰è£…ï¼Œç›´æ¥åœ¨æµè§ˆå™¨ä½“éªŒ Gemma 3nã€‚',
    'resources.api.keras.title': 'Keras',
    'resources.api.keras.desc': 'ç”¨ Keras é«˜æ•ˆæ„å»ºå’Œè®­ç»ƒ Gemma 3n æ¨¡å‹ã€‚',
    'resources.api.paper.title': 'æŠ€æœ¯æŠ¥å‘Š',
    'resources.api.paper.desc': 'é˜…è¯» Google å®˜æ–¹è®ºæ–‡ï¼Œæ·±å…¥äº†è§£ Gemma 3n æ¶æ„ã€‚',

    // Demo é¡µé¢ä¸»ç»“æ„
    'demo.page.title': 'AI Demo | Interactive Experience',
    'demo.page.description': 'Experience the power of Gemma 3n - run AI models directly in your browser, no installation required.',
    'demo.hero.title': 'Gemma 3n Interactive Experience',
    'demo.hero.subtitle': 'Experience powerful AI features directly in your browser. Code completion â€¢ Language translation â€¢ Intelligent Q&A',
    'demo.hero.feature1.title': 'Ultra-fast Response',
    'demo.hero.feature1.desc': 'Millisecond-level AI inference, real-time interaction',
    'demo.hero.feature2.title': 'Privacy First',
    'demo.hero.feature2.desc': 'All data processed locally, never uploaded to the cloud',
    'demo.hero.feature3.title': 'Multi-scenario Support',
    'demo.hero.feature3.desc': 'Coding, translation, chat â€” one model for all',
    'demo.hero.cta': 'Try Now â†’',
    'demo.section.title': 'Interactive AI Demo',
    'demo.section.desc': 'This is a simulated version showing how Gemma 3n works in real-world scenarios. For production, use ONNX.js or WebAssembly to run the real model.',
    'demo.info.title': 'About this Demo',
    'demo.info.current.title': 'Current Features',
    'demo.info.current.feature1': 'Simulates Gemma 3n inference process and response style',
    'demo.info.current.feature2': 'Realistic UI and interaction flow',
    'demo.info.current.feature3': 'Performance metrics based on real hardware data',
    'demo.info.current.feature4': 'Supports three core application scenarios',
    'demo.info.prod.title': 'Production Version',
    'demo.info.prod.feature1': 'Load real Gemma 3n model with ONNX.js',
    'demo.info.prod.feature2': 'Accelerated inference with WebAssembly',
    'demo.info.prod.feature3': 'Full tokenizer and post-processing pipeline',
    'demo.info.prod.feature4': 'Supports model quantization and optimization',
    'demo.tech.title': 'Technical Implementation Path',
    'demo.tech.desc': 'Upgrade the demo to a full-fledged AI application tech stack',
    'demo.tech.frontend.title': 'Frontend Architecture',
    'demo.tech.frontend.engine': 'Lightweight Inference Engine',
    'demo.tech.frontend.engine.code': "// ONNX.js integration\nimport * as ort from 'onnxruntime-web';\n\n// Load model\nconst session = await ort.InferenceSession\n  .create('/models/gemma-3n-e2b.onnx');\n\n// Inference\nconst results = await session.run(feeds);",
    'demo.tech.frontend.wasm': 'WebAssembly Optimization',
    'demo.tech.frontend.wasm.code': "// WebAssembly tokenizer\nimport init, { tokenize } from './pkg/tokenizer.js';\n\n// Initialize WASM module\nawait init();\n\n// High-performance tokenization\nconst tokens = tokenize(inputText);",
    'demo.tech.deploy.title': 'Model Deployment',
    'demo.tech.deploy.convert': 'Model Conversion',
    'demo.tech.deploy.convert1': 'Hugging Face â†’ ONNX',
    'demo.tech.deploy.convert2': 'Dynamic quantization (INT8)',
    'demo.tech.deploy.convert3': 'Graph optimization and constant folding',
    'demo.tech.deploy.convert4': 'WebGL backend adaptation',
    'demo.tech.deploy.cdn': 'CDN Distribution',
    'demo.tech.deploy.cdn1': 'Global acceleration with Cloudflare',
    'demo.tech.deploy.cdn2': 'Chunked download strategy',
    'demo.tech.deploy.cdn3': 'Browser cache optimization',
    'demo.tech.deploy.cdn4': 'Progressive loading',
    'demo.tech.deploy.optimize': 'Performance Optimization',
    'demo.tech.deploy.optimize1': 'Web Workers multithreading',
    'demo.tech.deploy.optimize2': 'SharedArrayBuffer',
    'demo.tech.deploy.optimize3': 'WebGPU acceleration (future)',
    'demo.tech.deploy.optimize4': 'Memory pool management',
    'demo.tech.cost.title': 'Zero-cost Solution Advantages',
    'demo.tech.cost.cloud': 'Traditional Cloud AI Cost',
    'demo.tech.cost.cloud1': 'ğŸ”´ OpenAI API: $0.002/1K tokens',
    'demo.tech.cost.cloud2': 'ğŸ”´ Azure OpenAI: $0.0015/1K tokens',
    'demo.tech.cost.cloud3': 'ğŸ”´ Google Cloud AI: $0.001/1K tokens',
    'demo.tech.cost.cloud4': 'ğŸ”´ Monthly: $200-2000 (medium traffic)',
    'demo.tech.cost.device': 'Gemma 3n On-device Solution',
    'demo.tech.cost.device1': 'âœ… Inference cost: $0',
    'demo.tech.cost.device2': 'âœ… CDN: $0 (Cloudflare free tier)',
    'demo.tech.cost.device3': 'âœ… Storage: $0 (static hosting)',
    'demo.tech.cost.device4': 'âœ… Monthly: $0 + $12/year domain',
    'demo.cta.title': 'Ready to build your AI app?',
    'demo.cta.desc': 'Start with tutorials and master the power of Gemma 3n step by step.',
    'demo.cta.learn': 'Start Learning',
    'demo.cta.toolkit': 'Toolkit',
    'demo.cta.download': 'Download Model',

    // FAQåŒºå—
    'faq.heading': 'å¸¸è§é—®é¢˜',
    'faq.subtitle': 'æœ‰ç–‘é—®ï¼Ÿæˆ‘ä»¬æ¥è§£ç­”ã€‚ä»¥ä¸‹æ˜¯å¼€å‘è€…æœ€å¸¸é—®çš„ä¸€äº›é—®é¢˜ã€‚',
    'faq.q1': 'Gemma 3n å¯ä»¥å…è´¹å•†ç”¨å—ï¼Ÿ',
    'faq.a1': 'å¯ä»¥ã€‚Gemma 3n æ¨¡å‹é‡‡ç”¨å®½æ¾è®¸å¯åè®®ï¼Œå…è®¸å…è´¹å•†ç”¨å’Œç§‘ç ”ä½¿ç”¨ã€‚è¯·åŠ¡å¿…æŸ¥é˜…å®˜æ–¹è®¸å¯æ¡æ¬¾ã€‚',
    'faq.q2': 'Gemma 3n çš„"å¤šæ¨¡æ€"å…·ä½“æŒ‡ä»€ä¹ˆï¼Ÿ',
    'faq.a2': 'å¤šæ¨¡æ€æ„å‘³ç€æ¨¡å‹ä¸ä»…èƒ½ç†è§£æ–‡æœ¬ï¼Œè¿˜èƒ½åˆ†æå›¾ç‰‡å’ŒéŸ³é¢‘ï¼Œé€‚ç”¨äºæè¿°ç…§ç‰‡ã€è¯­éŸ³è½¬å½•ç­‰å¤šåœºæ™¯ã€‚',
    'faq.q3': 'Gemma 3n å’Œ Gemma 2 æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ',
    'faq.a3': 'Gemma 3n é’ˆå¯¹è®¾å¤‡ç«¯ä¼˜åŒ–ï¼Œé‡‡ç”¨ MatFormer æ¶æ„ï¼Œå†…å­˜å’Œç®—åŠ›æ•ˆç‡æ›´é«˜ï¼Œéå¸¸é€‚åˆæ‰‹æœºã€ç¬”è®°æœ¬ç­‰æœ¬åœ°éƒ¨ç½²ã€‚',
    'faq.q4': 'å¯ä»¥ç”¨è‡ªå·±çš„æ•°æ®å¾®è°ƒ Gemma 3n å—ï¼Ÿ',
    'faq.a4': 'å½“ç„¶å¯ä»¥ã€‚Google æä¾›äº† Kerasã€PyTorchã€JAX ç­‰ä¸»æµæ¡†æ¶çš„å¾®è°ƒæ–¹æ¡ˆå’Œå·¥å…·ã€‚',
    'faq.q5': 'å¦‚ä½•ç”¨ Ollama è¿è¡Œ Gemma 3nï¼Ÿ',
    'faq.a5': 'å®‰è£… Ollama åï¼Œè¿è¡Œ "ollama run gemma-3n:e4b" æˆ– "ollama run gemma-3n:e2b" å³å¯è‡ªåŠ¨ä¸‹è½½å¹¶è¿è¡Œå¯¹åº”æ¨¡å‹ã€‚',
    'faq.q6': 'E2B å’Œ E4B æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ',
    'faq.a6': 'E2Bï¼ˆ2Bå‚æ•°ï¼‰æ›´å°æ›´å¿«ï¼Œé€‚åˆç§»åŠ¨ç«¯å’Œå¿«é€Ÿæ¨ç†ï¼›E4Bï¼ˆ4Bå‚æ•°ï¼‰ç²¾åº¦æ›´é«˜ä½†èµ„æºéœ€æ±‚æ›´å¤§ã€‚ä¸¤è€…å‡é‡‡ç”¨ MatFormer æ¶æ„ã€‚',
    'faq.q7': 'å¯ä»¥åœ¨ Hugging Face ä¸Šç”¨ Gemma 3n å—ï¼Ÿ',
    'faq.a7': 'å¯ä»¥ï¼Œæ‰€æœ‰ Gemma 3n æ¨¡å‹å‡å·²ä¸Šæ¶ Hugging Face Hubï¼Œæ”¯æŒ transformers åº“ç›´æ¥è°ƒç”¨ã€‚',
    'faq.q8': 'Gemma 3n æ¯” Llama 3 æ›´é€‚åˆæœ¬åœ°éƒ¨ç½²å—ï¼Ÿ',
    'faq.a8': 'Gemma 3n E4B åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­ä¼˜äº Llama 3 8Bï¼Œä¸”ä½“ç§¯æ›´å°ã€æ¨ç†æ›´å¿«ï¼Œéå¸¸é€‚åˆæœ¬åœ°å’Œéšç§åœºæ™¯ã€‚',
    'faq.q9': 'Gemma 3n èƒ½åœ¨ iOS è®¾å¤‡ä¸Šè¿è¡Œå—ï¼Ÿ',
    'faq.a9': 'å¯ä»¥ï¼ŒE2B ç‰ˆæœ¬ç‰¹åˆ«é€‚åˆç§»åŠ¨ç«¯ã€‚å¯ç”¨ CoreML æˆ–é‡åŒ–æ¨¡å‹åœ¨è‹¹æœè®¾å¤‡é«˜æ•ˆè¿è¡Œã€‚',
    'faq.q10': 'Gemma 3n å¯¹ç¡¬ä»¶æœ‰ä½•è¦æ±‚ï¼Ÿ',
    'faq.a10': 'E2B åªéœ€ 4GB å†…å­˜å³å¯è¿è¡Œï¼ŒE4B æ¨è 8GB ä»¥ä¸Šã€‚CPU ä¹Ÿå¯è¿è¡Œï¼Œè‹¥æœ‰ GPU æ¨ç†é€Ÿåº¦æ›´å¿«ã€‚',

    // newsletter
    'newsletter.heading': 'è·å–æœ€æ–°èµ„è®¯',
    'newsletter.desc': 'è®¢é˜…åå¯ç¬¬ä¸€æ—¶é—´è·å– Gemma 3n çš„æœ€æ–°æ•™ç¨‹ä¸æ–°é—»ã€‚ç»æ— åƒåœ¾é‚®ä»¶ã€‚',
    'newsletter.placeholder': 'è¯·è¾“å…¥æ‚¨çš„é‚®ç®±',
    'newsletter.subscribe': 'è®¢é˜…',

    // é¡µè„š
    'footer.independent': 'ä¸€ä¸ªç”±ç¤¾åŒºé©±åŠ¨çš„ã€ç‹¬ç«‹çš„Gemma 3nå¼€å‘è€…æŒ‡å—ã€‚',
    'footer.rights': 'ç‰ˆæƒæ‰€æœ‰ã€‚',
    'footer.stay_updated': 'ä¿æŒæ›´æ–°',
    'footer.subscribe_desc': 'è®¢é˜…æˆ‘ä»¬çš„æ–°é—»é€šè®¯ï¼Œè·å–æœ€æ–°çš„Gemma 3næ–°é—»ã€æ•™ç¨‹å’ŒåŸºå‡†æµ‹è¯•ã€‚',
    'footer.subscribe_button': 'è®¢é˜…',
    'footer.privacy': 'éšç§æ”¿ç­–',
    'footer.terms': 'æœåŠ¡æ¡æ¬¾',

    // åšå®¢
    'blog.title': 'Gemma 3n å¼€å‘è€…åšå®¢',
    'blog.description': 'å…³äºGemma 3n AIæ¨¡å‹çš„æ–°é—»ã€æ•™ç¨‹å’Œæ·±åº¦æ–‡ç« ã€‚',
    'blog.read_more': 'é˜…è¯»æ›´å¤š',
    'blog.giscus.comments': 'è¯„è®º',
    'blog.table_of_contents': 'ç›®å½•',
    'blog.last_updated': 'æœ€åæ›´æ–°äº',
    'blog.share': 'åˆ†äº«è¿™ç¯‡æ–‡ç« ',
    'blog.share.twitter': 'åˆ†äº«åˆ°æ¨ç‰¹',
    'blog.share.linkedin': 'åˆ†äº«åˆ°é¢†è‹±',
    'blog.share.facebook': 'åˆ†äº«åˆ°è„¸ä¹¦',
    'blog.share.copy': 'å¤åˆ¶é“¾æ¥',
    'blog.share.copied': 'å·²å¤åˆ¶ï¼',

    // å¯¹æ¯”é¡µé¢
    'compare.title': "Gemma 3n vs. Llama 3: ç»ˆæå¯¹å†³",
    'compare.description': "æ·±åº¦æ•°æ®é©±åŠ¨å¯¹æ¯” Google Gemma 3n ä¸ Meta Llama 3ã€‚æˆ‘ä»¬åˆ†æåŸºå‡†æµ‹è¯•ã€ç¡¬ä»¶éœ€æ±‚å’Œä½¿ç”¨åœºæ™¯ï¼ŒåŠ©ä½ é€‰æ‹©æœ€é€‚åˆä½ é¡¹ç›®çš„æ¨¡å‹ã€‚",
    'compare.h1': "Gemma 3n <span class='text-blue-600'>å¯¹å†³</span> Llama 3",
    'compare.subheading': "æ•ˆç‡ä¸æ€§èƒ½çš„ç¢°æ’ã€‚æˆ‘ä»¬æ·±å…¥å‰–æä¸¤å¤§é¢†å…ˆå¼€æºæ¨¡å‹ï¼ŒåŠ©ä½ æ ¹æ®å…·ä½“éœ€æ±‚åšå‡ºæœ€ç»ˆå†³ç­–ã€‚",
    'compare.showdown_badge': "æ¨¡å‹å¯¹å†³",
    'compare.glance.title': "é€Ÿè§ˆï¼šæ ¸å¿ƒå·®å¼‚",
    'compare.glance.feature': "ç‰¹æ€§",
    'compare.glance.gemma': "Gemma 3n (E4B)",
    'compare.glance.llama': "Llama 3 (8B)",
    'compare.glance.architecture': "æ¶æ„",
    'compare.glance.architecture.gemma': "MatFormer (åŠ¨æ€ç¼©æ”¾)",
    'compare.glance.architecture.llama': "æ ‡å‡† Transformer",
    'compare.glance.params': "æœ‰æ•ˆå‚æ•°",
    'compare.glance.params.gemma': "~40äº¿",
    'compare.glance.params.llama': "80äº¿",
    'compare.glance.strength': "æ ¸å¿ƒä¼˜åŠ¿",
    'compare.glance.strength.gemma': "ç«¯ä¾§æ€§èƒ½, é«˜æ•ˆç‡",
    'compare.glance.strength.llama': "åŸå§‹æ¨ç† & ç¼–ç¨‹èƒ½åŠ›",
    'compare.glance.hardware': "ç¡¬ä»¶éœ€æ±‚",
    'compare.glance.hardware.gemma': "<span class='font-semibold text-green-600 dark:text-green-400'>ä½</span> (ç°ä»£ç¬”è®°æœ¬)",
    'compare.glance.hardware.llama': "<span class='font-semibold text-orange-500'>ä¸­</span> (éœ€è¦è‰¯å¥½GPU)",
    'compare.glance.multimodality': "å¤šæ¨¡æ€èƒ½åŠ›",
    'compare.glance.multimodality.gemma': "åŸç”Ÿæ”¯æŒæ–‡æœ¬ã€éŸ³é¢‘ã€å›¾åƒ",
    'compare.glance.multimodality.llama': "ä»…æ–‡æœ¬",
    'compare.benchmarks.title': "æ€§èƒ½åŸºå‡†æµ‹è¯•",
    'compare.benchmarks.note': "*åŸºå‡†åˆ†æ•°æ˜¯åŸºäºå…¬å¼€èšåˆæ•°æ®çš„è¯´æ˜æ€§å±•ç¤ºã€‚",
    'compare.deepdive.title': "æ·±åº¦åˆ†æ",
    'compare.deepdive.gemma.title': "ğŸ† Gemma 3n çš„èƒœå‡ºä¹‹å¤„",
    'compare.deepdive.gemma.1.title': "æ•ˆç‡ä¸å¯åŠæ€§",
    'compare.deepdive.gemma.1.desc': "åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ï¼ˆç¬”è®°æœ¬ã€æ‰‹æœºï¼‰ä¸Šæµç•…è¿è¡Œï¼ŒRAMå ç”¨æ˜¾è‘—å‡å°‘ï¼Œæ˜¯ç«¯ä¾§åº”ç”¨çš„å®Œç¾é€‰æ‹©ã€‚",
    'compare.deepdive.gemma.2.title': "åŸç”Ÿå¤šæ¨¡æ€",
    'compare.deepdive.gemma.2.desc': "ä»åº•å±‚è®¾è®¡å°±æ”¯æŒåœ¨å•ä¸€æ¨¡å‹ä¸­ç†è§£æ–‡æœ¬ã€éŸ³é¢‘å’Œå›¾åƒï¼Œè§£é”äº†Llamaæ— æ³•å•ç‹¬å¤„ç†çš„æ–°å‹åº”ç”¨ã€‚",
    'compare.deepdive.gemma.3.title': "åŠ¨æ€æ¶æ„",
    'compare.deepdive.gemma.3.desc': "MatFormeræ¶æ„ä½¿å…¶èƒ½åŠ¨æ€è°ƒæ•´è®¡ç®—é‡ï¼Œæ— éœ€å·¨å¤§çš„é™æ€å‚æ•°å³å¯æä¾›å‡è¡¡çš„æ€§èƒ½ã€‚",
    'compare.deepdive.llama.title': "ğŸ† Llama 3 çš„èƒœå‡ºä¹‹å¤„",
    'compare.deepdive.llama.1.title': "åŸå§‹æ¨ç†ä¸ç¼–ç¨‹èƒ½åŠ›",
    'compare.deepdive.llama.1.desc': "å‡­å€Ÿæ›´å¤šä¸“ç”¨å‚æ•°ï¼ŒLlama 3åœ¨å¤æ‚é€»è¾‘æ¨ç†ã€æ•°å­¦é—®é¢˜å’Œä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œçº¯æ–‡æœ¬åŸºå‡†æµ‹è¯•é€šå¸¸ä¼˜äºGemmaã€‚",
    'compare.deepdive.llama.2.title': "æˆç†Ÿçš„å¾®è°ƒç”Ÿæ€",
    'compare.deepdive.llama.2.desc': "ä½œä¸ºä¸€ä¸ªæ›´æˆç†Ÿçš„æ¶æ„ï¼Œç¤¾åŒºä¸ºLlama 3è´¡çŒ®äº†å¤§é‡é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒç‰ˆæœ¬ã€‚",
    'compare.deepdive.llama.3.title': "å¯é¢„æµ‹çš„æ€§èƒ½",
    'compare.deepdive.llama.3.desc': "å…¶æ ‡å‡†Transformeræ¶æ„æ„å‘³ç€æ€§èƒ½éå¸¸å¯é¢„æµ‹ï¼Œå¹¶ä¸”èƒ½éšæ›´å¼ºå¤§çš„ç¡¬ä»¶å¾ˆå¥½åœ°æ‰©å±•ã€‚",
    'compare.verdict.title': "æœ€ç»ˆè£å†³ï¼šå“ªæ¬¾é€‚åˆä½ ï¼Ÿ",
    'compare.verdict.subtitle': "ä½ çš„é€‰æ‹©å®Œå…¨å–å†³äºé¡¹ç›®çš„æ ¸å¿ƒç›®æ ‡ã€‚",
    'compare.verdict.gemma.title': "é€‰æ‹© Gemma 3n å¦‚æœ...",
    'compare.verdict.gemma.bullet1': "ä½ æ­£åœ¨ä¸º**ç§»åŠ¨æˆ–è¾¹ç¼˜è®¾å¤‡**æ„å»ºåº”ç”¨ã€‚",
    'compare.verdict.gemma.bullet2': "ä½ çš„åº”ç”¨éœ€è¦**å¤šæ¨¡æ€èƒ½åŠ›**ï¼ˆéŸ³é¢‘/è§†è§‰ï¼‰ã€‚",
    'compare.verdict.gemma.bullet3': "**èµ„æºæ•ˆç‡**å’Œä½RAMå ç”¨è‡³å…³é‡è¦ã€‚",
    'compare.verdict.gemma.bullet4': "ä½ éœ€è¦ä¸€ä¸ªç”¨äºé€šç”¨ä»»åŠ¡çš„ã€å‡è¡¡çš„å…¨é¢æ¨¡å‹ã€‚",
    'compare.verdict.llama.title': "é€‰æ‹© Llama 3 å¦‚æœ...",
    'compare.verdict.llama.bullet1': "ä½ çš„ä¸»è¦ç”¨ä¾‹æ˜¯**å¤æ‚çš„ç¼–ç¨‹æˆ–æ¨ç†**ã€‚",
    'compare.verdict.llama.bullet2': "ä½ æ‹¥æœ‰**å¼ºå¤§çš„GPU**ã€‚",
    'compare.verdict.llama.bullet3': "ä½ éœ€è¦åœ¨**çº¯æ–‡æœ¬ä»»åŠ¡**ä¸Šè·å¾—ç»å¯¹æœ€ä½³æ€§èƒ½ã€‚",
    'compare.verdict.llama.bullet4': "ä½ æƒ³åˆ©ç”¨åºå¤§çš„ç¤¾åŒºå¾®è°ƒæ¨¡å‹åº“ã€‚",
    'compare.cta.title': "å‡†å¤‡å¥½æ·±å…¥æ¢ç´¢äº†å—ï¼Ÿ",
    'compare.cta.subtitle': "æµè§ˆæˆ‘ä»¬çš„å®æˆ˜æ•™ç¨‹ï¼ŒæŒæ¡è¿™ä¸¤æ¬¾æ¨¡å‹ã€‚",
    'compare.cta.button1': "æµè§ˆå…¨éƒ¨æ•™ç¨‹",
    'compare.cta.button2': "è·å–å·¥å…·ç®±",

    // Leaderboard Page
    'leaderboard.title': "AIæ¨¡å‹æ’è¡Œæ¦œï¼šæœ€ä½³å¼€æºæ¨¡å‹å¯¹æ¯”",
    'leaderboard.description': "ä¸€ä¸ªæ•°æ®é©±åŠ¨ã€å¯æ’åºçš„æ’è¡Œæ¦œï¼Œæ¯”è¾ƒGemma 3nã€Llama 3ã€Phi-3å’ŒQwen 2ç­‰é¡¶çº§å¼€æºAIæ¨¡å‹ã€‚å¯æŒ‰MMLUã€GSM8Kå’ŒHumanEvalç­‰åŸºå‡†è¿›è¡Œç­›é€‰ã€‚",
    'leaderboard.h1': "å¼€æºæ¨¡å‹æ’è¡Œæ¦œ",
    'leaderboard.subheading': "å½“ä»Šé¡¶çº§å¼€æºAIæ¨¡å‹çš„æƒå¨æ•°æ®é©±åŠ¨æ’åã€‚æ’åºã€æ¯”è¾ƒï¼Œæ‰¾åˆ°æœ€é€‚åˆæ‚¨éœ€æ±‚çš„æ¨¡å‹ã€‚",
    'leaderboard.badge': "ç¤¾åŒºåŸºå‡†æµ‹è¯•",
    'leaderboard.table.rank': "æ’å",
    'leaderboard.table.model': "æ¨¡å‹",
    'leaderboard.table.params': "å‚æ•°é‡ (B)",
    'leaderboard.table.mmlu': "MMLU",
    'leaderboard.table.gsm8k': "GSM8K",
    'leaderboard.table.humaneval': "HumanEval",
    'leaderboard.table.tags': "æ ‡ç­¾",
    'leaderboard.notes.definitions': "* MMLU: Massive Multitask Language Understanding. GSM8K: Grade School Math. HumanEval: Code Generation.",
    'leaderboard.notes.disclaimer': "* æ€§èƒ½æ•°æ®åŸºäºå…¬å¼€ä¿¡æ¯ï¼Œå¯èƒ½å› é‡åŒ–å’Œå®ç°æ–¹å¼è€Œå¼‚ã€‚",
    'leaderboard.tags.reasoning': "æ¨ç†èƒ½åŠ›å¼º",
    'leaderboard.tags.efficiency': "æ•ˆç‡ä¹‹ç‹",
    'leaderboard.tags.multimodal': "å¤šæ¨¡æ€",
    'leaderboard.tags.coder': "ç¼–ç¨‹é«˜æ‰‹",
    'leaderboard.tags.on_device': "ç«¯ä¾§è®¾å¤‡",
    'leaderboard.tags.fast': "é€Ÿåº¦å¿«",

    // éšç§ä¸æ¡æ¬¾
    'privacy.title': "éšç§æ”¿ç­–",
    'privacy.h1': "Gemma-3n.net éšç§æ”¿ç­–",
    'privacy.effective_date': "ç”Ÿæ•ˆæ—¥æœŸï¼š2025å¹´7æœˆ1æ—¥",
    'privacy.p1': "æ¬¢è¿è®¿é—® Gemma-3n.netã€‚æˆ‘ä»¬è‡´åŠ›äºä¿æŠ¤æ‚¨çš„éšç§ã€‚æœ¬éšç§æ”¿ç­–è§£é‡Šäº†å½“æ‚¨è®¿é—®æˆ‘ä»¬çš„ç½‘ç«™æ—¶ï¼Œæˆ‘ä»¬å¦‚ä½•æ”¶é›†ã€ä½¿ç”¨ã€æŠ«éœ²å’Œä¿æŠ¤æ‚¨çš„ä¿¡æ¯ã€‚è¯·ä»”ç»†é˜…è¯»æœ¬éšç§æ”¿ç­–ã€‚å¦‚æœæ‚¨ä¸åŒæ„æœ¬éšç§æ”¿ç­–çš„æ¡æ¬¾ï¼Œè¯·ä¸è¦è®¿é—®æœ¬ç½‘ç«™ã€‚",
    'privacy.h2_info': "æ‚¨çš„ä¿¡æ¯æ”¶é›†",
    'privacy.p2': "æˆ‘ä»¬å¯èƒ½ä»¥å¤šç§æ–¹å¼æ”¶é›†æœ‰å…³æ‚¨çš„ä¿¡æ¯ã€‚æˆ‘ä»¬å¯èƒ½åœ¨ç½‘ç«™ä¸Šæ”¶é›†çš„ä¿¡æ¯åŒ…æ‹¬ï¼š",
    'privacy.h3_personal': "ä¸ªäººæ•°æ®",
    'privacy.p3': "æ‚¨åœ¨è®¢é˜…æˆ‘ä»¬çš„æ–°é—»é€šè®¯æ—¶è‡ªæ„¿æä¾›ç»™æˆ‘ä»¬çš„ä¸ªäººèº«ä»½ä¿¡æ¯ï¼Œä¾‹å¦‚æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€ã€‚",
    'privacy.h3_analytics': "è¡ç”Ÿæ•°æ®",
    'privacy.p4': "å½“æ‚¨è®¿é—®æœ¬ç½‘ç«™æ—¶ï¼Œæˆ‘ä»¬çš„æœåŠ¡å™¨ä¼šè‡ªåŠ¨æ”¶é›†çš„ä¿¡æ¯ï¼Œä¾‹å¦‚æ‚¨çš„IPåœ°å€ã€æµè§ˆå™¨ç±»å‹ã€æ“ä½œç³»ç»Ÿã€è®¿é—®æ—¶é—´ä»¥åŠæ‚¨åœ¨è®¿é—®æœ¬ç½‘ç«™å‰åç›´æ¥æŸ¥çœ‹çš„é¡µé¢ã€‚æˆ‘ä»¬ä½¿ç”¨æ³¨é‡éšç§çš„åˆ†ææœåŠ¡ï¼Œä¸ä½¿ç”¨è°·æ­Œåˆ†æã€‚",
    'privacy.h2_use': "æ‚¨çš„ä¿¡æ¯ä½¿ç”¨",
    'privacy.p5': "æ‹¥æœ‰å…³äºæ‚¨çš„å‡†ç¡®ä¿¡æ¯ä½¿æˆ‘ä»¬èƒ½å¤Ÿä¸ºæ‚¨æä¾›æµç•…ã€é«˜æ•ˆå’Œå®šåˆ¶åŒ–çš„ä½“éªŒã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¯èƒ½ä½¿ç”¨é€šè¿‡æœ¬ç½‘ç«™æ”¶é›†çš„å…³äºæ‚¨çš„ä¿¡æ¯æ¥ï¼šå°±æ‚¨çš„å¸æˆ·æˆ–è®¢å•å‘æ‚¨å‘é€ç”µå­é‚®ä»¶ï¼Œå›å¤å®¢æˆ·æœåŠ¡è¯·æ±‚ï¼Œä»¥åŠå‘æ‚¨å‘é€æ–°é—»é€šè®¯ã€‚",
    'privacy.h2_security': "æ‚¨çš„ä¿¡æ¯å®‰å…¨",
    'privacy.p6': "æˆ‘ä»¬ä½¿ç”¨è¡Œæ”¿ã€æŠ€æœ¯å’Œç‰©ç†å®‰å…¨æªæ–½æ¥å¸®åŠ©ä¿æŠ¤æ‚¨çš„ä¸ªäººä¿¡æ¯ã€‚è™½ç„¶æˆ‘ä»¬å·²é‡‡å–åˆç†æªæ–½æ¥ä¿æŠ¤æ‚¨æä¾›ç»™æˆ‘ä»¬çš„ä¸ªäººä¿¡æ¯ï¼Œä½†è¯·æ³¨æ„ï¼Œå°½ç®¡æˆ‘ä»¬åšå‡ºäº†åŠªåŠ›ï¼Œä½†æ²¡æœ‰ä»»ä½•å®‰å…¨æªæ–½æ˜¯å®Œç¾æˆ–ä¸å¯é€¾è¶Šçš„ï¼Œä¹Ÿæ²¡æœ‰ä»»ä½•æ•°æ®ä¼ è¾“æ–¹æ³•å¯ä»¥ä¿è¯ä¸ä¼šè¢«æ‹¦æˆªæˆ–é­åˆ°å…¶ä»–ç±»å‹çš„æ»¥ç”¨ã€‚",
    'privacy.h2_contact': "è”ç³»æˆ‘ä»¬",
    'privacy.p7': "å¦‚æœæ‚¨å¯¹æœ¬éšç§æ”¿ç­–æœ‰ä»»ä½•é—®é¢˜æˆ–æ„è§ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸æˆ‘ä»¬è”ç³»ï¼šlegal@gemma-3n.net",

    'terms.title': "æœåŠ¡æ¡æ¬¾",
    'terms.h1': "Gemma-3n.net æœåŠ¡æ¡æ¬¾",
    'terms.effective_date': "ç”Ÿæ•ˆæ—¥æœŸï¼š2025å¹´7æœˆ1æ—¥",
    'terms.p1': "ä½¿ç”¨ä½äº Gemma-3n.net çš„ç½‘ç«™ï¼ˆâ€œæœ¬ç½‘ç«™â€ï¼‰ï¼Œå³è¡¨ç¤ºæ‚¨åŒæ„å—æœ¬æœåŠ¡æ¡æ¬¾ï¼ˆâ€œæœ¬åè®®â€ï¼‰çš„çº¦æŸï¼Œæ— è®ºæ‚¨æ˜¯å¦æ³¨å†Œä¸ºä¼šå‘˜ã€‚å¦‚æœæ‚¨ä¸åŒæ„è¿™äº›æ¡æ¬¾ï¼Œåˆ™ä¸åº”ä½¿ç”¨æœ¬ç½‘ç«™ã€‚",
    'terms.h2_use': "ç½‘ç«™ä½¿ç”¨",
    'terms.p2': "æ‚¨åªèƒ½å°†æœ¬ç½‘ç«™ç”¨äºä¸ªäººéå•†ä¸šç”¨é€”ã€‚æ‚¨åŒæ„ä¸ä¸ºä»»ä½•éæ³•æˆ–æœ¬åè®®ç¦æ­¢çš„ç›®çš„ä½¿ç”¨æœ¬ç½‘ç«™ã€‚æ‚¨ä¸å¾—ä»¥ä»»ä½•å¯èƒ½æŸåã€ç¦ç”¨ã€è¶…è½½æˆ–æŸå®³æœ¬ç½‘ç«™çš„æ–¹å¼ä½¿ç”¨æœ¬ç½‘ç«™ã€‚",
    'terms.h2_disclaimer': "å…è´£å£°æ˜",
    'terms.p3': "æœ¬ç½‘ç«™ä¸Šæä¾›çš„ä¿¡æ¯ä»…ä¾›ä¸€èˆ¬å‚è€ƒä¹‹ç”¨ã€‚æœ¬ç½‘ç«™ä¸Šçš„æ‰€æœ‰ä¿¡æ¯å‡å‡ºäºå–„æ„æä¾›ï¼Œä½†æˆ‘ä»¬ä¸å¯¹æœ¬ç½‘ç«™ä¸Šä»»ä½•ä¿¡æ¯çš„å‡†ç¡®æ€§ã€å……åˆ†æ€§ã€æœ‰æ•ˆæ€§ã€å¯é æ€§ã€å¯ç”¨æ€§æˆ–å®Œæ•´æ€§ä½œå‡ºä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„é™ˆè¿°æˆ–ä¿è¯ã€‚",
    'terms.h2_liability': "è´£ä»»é™åˆ¶",
    'terms.p4': "åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æˆ–æˆ‘ä»¬çš„è‘£äº‹ã€å‘˜å·¥æˆ–ä»£ç†äººå‡ä¸å¯¹æ‚¨æˆ–ä»»ä½•ç¬¬ä¸‰æ–¹å› æ‚¨ä½¿ç”¨æœ¬ç½‘ç«™è€Œå¼•èµ·çš„ä»»ä½•ç›´æ¥ã€é—´æ¥ã€åæœæ€§ã€æƒ©æˆ’æ€§ã€é™„å¸¦æ€§ã€ç‰¹æ®Šæ€§æˆ–æƒ©ç½šæ€§æŸå®³è´Ÿè´£ï¼ŒåŒ…æ‹¬åˆ©æ¶¦æŸå¤±ã€æ”¶å…¥æŸå¤±ã€æ•°æ®ä¸¢å¤±æˆ–å…¶ä»–æŸå®³ï¼Œå³ä½¿æˆ‘ä»¬å·²è¢«å‘ŠçŸ¥å¯èƒ½å‘ç”Ÿæ­¤ç±»æŸå®³ã€‚",
    'terms.h2_governing': "ç®¡è¾–æ³•å¾‹",
    'terms.p5': "æœ¬åè®®åº”å—åŠ åˆ©ç¦å°¼äºšå·æ³•å¾‹ç®¡è¾–å¹¶æ ¹æ®å…¶è§£é‡Šï¼Œä¸è€ƒè™‘å…¶æ³•å¾‹å†²çªåŸåˆ™ã€‚",
    'terms.h2_contact': "è”ç³»æˆ‘ä»¬",
    'terms.p6': "å¦‚æœæ‚¨å¯¹æœ¬æœåŠ¡æ¡æ¬¾æœ‰ä»»ä½•é—®é¢˜æˆ–æ„è§ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸æˆ‘ä»¬è”ç³»ï¼šlegal@gemma-3n.net",
  }
} as const;

// è·å–ç¿»è¯‘æ–‡æœ¬çš„å‡½æ•°
export function useTranslations(lang: Language) {
  return function t(key: keyof typeof ui[typeof defaultLang]): string {
    return ui[lang]?.[key] || ui[defaultLang][key] || key;
  }
}

// ä»URLè·¯å¾„è·å–è¯­è¨€
export function getLangFromUrl(url: URL): Language {
  const [, lang] = url.pathname.split('/');
  if (lang in languages) return lang as Language;
  return defaultLang;
}

// è·å–æœ¬åœ°åŒ–è·¯å¾„
export function getLocalizedPath(path: string, lang: Language): string {
  if (lang === defaultLang) {
    return path;
  }
  return `/${lang}${path}`;
}

// è·å–æ›¿ä»£è¯­è¨€è·¯å¾„
export function getAlternateLanguagePaths(currentPath: string, currentLang: Language) {
  const paths: Record<Language, string> = {} as Record<Language, string>;
  
  // ç§»é™¤å½“å‰è¯­è¨€å‰ç¼€
  let basePath = currentPath;
  if (currentLang !== defaultLang) {
    basePath = currentPath.replace(`/${currentLang}`, '') || '/';
  }
  
  // ä¸ºæ¯ç§è¯­è¨€ç”Ÿæˆè·¯å¾„
  Object.keys(languages).forEach(lang => {
    const language = lang as Language;
    paths[language] = getLocalizedPath(basePath, language);
  });
  
  return paths;
} 