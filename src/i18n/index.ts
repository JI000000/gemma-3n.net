// ÊîØÊåÅÁöÑËØ≠Ë®Ä
export const languages = {
  en: 'English',
  zh: '‰∏≠Êñá'
} as const;

export type Language = keyof typeof languages;

// ÈªòËÆ§ËØ≠Ë®Ä
export const defaultLang: Language = 'en';

// ËØ≠Ë®ÄÈÖçÁΩÆ
export const langConfig = {
  en: {
    name: 'English',
    dir: 'ltr',
    locale: 'en-US'
  },
  zh: {
    name: '‰∏≠Êñá',
    dir: 'ltr', 
    locale: 'zh-CN'
  }
} as const;

// UIÊñáÊú¨ËµÑÊ∫ê
export const ui = {
  en: {
    // Nav
    'nav.home': 'Home',
    'nav.about': 'About',
    'nav.benchmarks': 'Benchmarks',
    'nav.blog': 'Blog',
    'nav.toolkit': 'Toolkit',
    'nav.resources': 'Resources',
    'nav.faq': 'FAQ',
    'nav.demo': 'Demo',
    'nav.compare': 'Compare',
    'nav.leaderboard': 'Leaderboard',
    
    // Home
    'hero.title': 'Gemma-3n.net: The Ultimate Developer Guide',
    'hero.subtitle': 'Master Google\'s Gemma 3n AI models with comprehensive tutorials, benchmarks, and tools.',
    'hero.cta.primary': 'Get Started',
    'hero.cta.secondary': 'View Demos',
    
    // SEO
    'seo.home.title': 'Gemma-3n.net: The Ultimate Developer Guide for Google‚Äôs Gemma 3n',
    'seo.home.description': 'Master Google‚Äôs Gemma 3n AI model with comprehensive tutorials, benchmarks, and tools. Your essential resource for local and cloud deployment.',
    'seo.about.title': 'About Gemma-3n.net | Our Mission and Methodology',
    'seo.about.description': 'Learn about the mission of Gemma-3n.net: to provide the most accurate, independent, and up-to-date resources for the Gemma 3n developer community.',
    'seo.blog.title': 'Gemma 3n Blog | Tutorials, News, and In-Depth Analysis',
    'seo.blog.description': 'The official blog for Gemma-3n.net. Find the latest news, expert tutorials, and deep-dive articles on fine-tuning, deploying, and optimizing the Gemma 3n model.',
    'seo.toolkit.title': 'Gemma 3n Toolkit | Downloads, Guides, and Official Resources',
    'seo.toolkit.description': 'The complete developer toolkit for Gemma 3n. Access official model downloads, setup guides for Ollama and Hugging Face, iOS deployment docs, and more.',
    'seo.compare.title': 'Gemma 3n vs. Llama 3: In-Depth AI Model Comparison',
    'seo.compare.description': 'A head-to-head, data-driven comparison of Google\'s Gemma 3n and Meta\'s Llama 3. Analyze performance benchmarks, architecture, and real-world use cases.',
    'seo.leaderboard.title': 'AI Model Leaderboard | Compare Gemma 3n, Llama 3, and More',
    'seo.leaderboard.description': 'Live AI model leaderboard comparing the latest open-source and proprietary models on key industry benchmarks. See how Gemma 3n stacks up against the competition.',

    // Demo
    'demo.title': 'üöÄ Gemma 3n Interactive Demo',
    'demo.subtitle': 'Experience in-browser AI inference - fully local, no server required',
    'demo.loading.initializing': 'Initializing lightweight AI model...',
    'demo.loading.engine': 'Downloading lightweight inference engine...',
    'demo.loading.wasm': 'Initializing WebAssembly module...',
    'demo.loading.vocab': 'Loading vocabulary and configuration...',
    'demo.loading.weights': 'Optimizing model weights...',
    'demo.loading.ready': 'Model ready!',
    'demo.status.ready': '‚úÖ Gemma 3n Lite is ready (Online Demo Version)',
    'demo.scenarios.label': 'Select a demo scenario',
    'demo.scenarios.code.title': 'Code Completion',
    'demo.scenarios.code.description': 'Intelligent code suggestions',
    'demo.scenarios.translate.title': 'Language Translation',
    'demo.scenarios.translate.description': 'Translate between languages',
    'demo.scenarios.chat.title': 'Assistant Chat',
    'demo.scenarios.chat.description': 'Conversational assistant',
    'demo.input.label': 'Input Text',
    'demo.input.placeholder': 'Enter your text...',
    'demo.parameters.label': 'Temperature (Creativity)',
    'demo.parameters.conservative': 'Conservative',
    'demo.parameters.creative': 'Creative',
    'demo.button.loading': 'Model loading...',
    'demo.button.generate': 'Generate AI Response',
    'demo.button.generating': 'Generating...',
    'demo.output.label': 'AI Output',
    'demo.output.placeholder': 'AI-generated content will appear here...',
    'demo.output.thinking': 'ü§ñ AI is thinking...',
    'demo.output.error': '‚ùå Generation failed:',
    'demo.alert.no_input': 'Please enter some text',
    'demo.metrics.tokensPerSecond': 'Tokens/sec',
    'demo.metrics.inferenceTime': 'Inference Time (ms)',
    'demo.metrics.memoryUsage': 'Memory Usage (MB)',
    'demo.metrics.modelSize': 'Model Size',
    'demo.placeholders.code': `function fibonacci(n) {
  // Calculate fibonacci sequence
  if (n <= 1) return n;
  return`,
    'demo.placeholders.translate': `Please translate the following text to English:
Artificial intelligence is changing our world.`,
    'demo.placeholders.chat': `Hello, I would like to know the features and advantages of the Gemma 3n model.`,
    'demo.simulations.code_response': ` fibonacci(n - 1) + fibonacci(n - 2);
}

// Optimized version: using dynamic programming
function fibonacciDP(n) {
  const dp = [0, 1];
  for (let i = 2; i <= n; i++) {
    dp[i] = dp[i-1] + dp[i-2];
  }
  return dp[n];
}`,
    'demo.simulations.translation_response': `**Translation Result:**
Artificial Intelligence is transforming our world.

*Detected Language: Chinese ‚Üí English*`,
    'demo.simulations.chat_response_1': `Hello! I'm happy to introduce Gemma 3n. It is the latest multimodal AI model released by Google, with the following features:

üéØ **On-device Optimization**: Designed for devices like mobile phones and laptops
‚ö° **Efficient Architecture**: "Nested" MatFormer Transformer structure
üé® **Multimodal Capability**: Supports text, image, and audio processing
üîß **Developer Friendly**: Compatible with the mainstream AI tool ecosystem

Which aspect would you like to know more about?`,
    'demo.simulations.chat_response_2': `The advantages of Gemma 3n compared to other models are:

1. **Smaller Memory Footprint**: The E2B version requires only 4GB of memory
2. **Faster Inference Speed**: Optimized for mobile devices
3. **Better Accuracy**: Achieves 79.8% on the MMLU benchmark
4. **Stronger Multimodality**: Natively supports vision and audio

This makes it particularly suitable for building privacy-first on-device AI applications.`,
    'demo.simulations.chat_response_3': `Regarding the technical implementation of Gemma 3n, I recommend that you:

üìö **Learning Path**: Start with our introductory tutorials
üíª **Practical Projects**: Try the iOS deployment or Ollama integration
üîß **Advanced Skills**: Learn LoRA fine-tuning techniques
üåê **Community Involvement**: Follow the latest model updates and optimizations

Would you like me to recommend a specific tutorial?`,
    
    // Controls
    'controls.temperature': 'Temperature',
    'controls.temperature.desc': 'Controls randomness in output',
    'controls.maxTokens': 'Max Tokens',
    'controls.maxTokens.desc': 'Maximum length of generated text',
    'controls.topK': 'Top-K',
    'controls.topK.desc': 'Limits vocabulary for more focused output',
    
    // Metrics
    'metrics.inference': 'Inference Time',
    'metrics.memory': 'Memory Usage',
    'metrics.tokens': 'Tokens/sec',
    'metrics.local': 'Local Processing',
    'metrics.api': 'API Call',
    
    // Scenarios
    'scenarios.code': 'Code Generation',
    'scenarios.code.desc': 'Generate and complete code',
    'scenarios.text': 'Text Generation', 
    'scenarios.text.desc': 'Creative writing and content',
    'scenarios.chat': 'Q&A Chat',
    'scenarios.chat.desc': 'Interactive conversations',
    
    // Benchmarks
    'benchmarks.title': 'Performance Benchmarks',
    'benchmarks.subtitle': 'How does Gemma 3n compare to competitors? Here are the benchmarks.',
    'benchmarks.source': 'Data sourced from official Google AI publications and independent benchmarks.',
    'benchmarks.heading': 'Performance Benchmarks',
    'benchmarks.efficiency_champion_title': 'Efficiency Champion',
    'benchmarks.efficiency_champion': 'Gemma 3n E4B achieves 79.8% MMLU with only 4B parameters, outperforming Llama 3.1 8B (66.7%) while using half the memory.',
    'benchmarks.mobile_first_design_title': 'Mobile-First Design',
    'benchmarks.mobile_first_design': 'MatFormer architecture enables dynamic scaling, allowing the same model to run efficiently from smartphones to workstations.',
    'benchmarks.mmlu.title': 'MMLU',
    'benchmarks.mmlu.desc': 'Massive Multitask Language Understanding',
    'benchmarks.mmlu.note': 'Outperforms leading models in its class on this key knowledge and reasoning benchmark.',
    'benchmarks.lmarena.title': 'LMArena Score',
    'benchmarks.lmarena.desc': 'Human preference chatbot benchmark',
    'benchmarks.lmarena.max': 'of max observed',
    'benchmarks.lmarena.note': 'The first model under 10B parameters to break the 1300 barrier, showcasing strong conversational ability.',
    'benchmarks.vision.title': 'Vision Encoder Speed',
    'benchmarks.vision.desc': 'On-device performance (Pixel Edge TPU)',
    'benchmarks.vision.faster': 'Faster',
    'benchmarks.vision.compare': 'MobileNet-V5 vs SoViT',
    'benchmarks.vision.note': 'A massive speedup in vision processing with higher accuracy and a smaller memory footprint.',
    'benchmarks.table.title': 'Gemma 3n vs. Competition',
    'benchmarks.table.model': 'Model',
    'benchmarks.table.params': 'Parameters',
    'benchmarks.table.mmlu': 'MMLU',
    'benchmarks.table.gsm8k': 'GSM8K',
    'benchmarks.table.humaneval': 'HumanEval',
    'benchmarks.table.memory': 'Memory (GB)',
    'benchmarks.gemma_e4b': 'Gemma 3n E4B',
    'benchmarks.gemma_e2b': 'Gemma 3n E2B',
    'benchmarks.llama_3_8b': 'Llama 3.1 8B',
    'benchmarks.llama_3_3b': 'Llama 3.2 3B',
    'benchmarks.score': 'Score',
    'benchmarks.tag.superior': 'Superior performance',
    'benchmarks.tag.below': 'Below Gemma 3n E4B',
    'benchmarks.memory.note': 'Memory requirements are for full precision models.',

    // Toolkit
    'toolkit.title': 'Gemma 3n Toolkit - Complete Developer Resources',
    'toolkit.description': 'Comprehensive toolkit for Gemma 3n development. Includes Ollama setup, Hugging Face integration, iOS deployment guides, and model comparison tools.',
    'toolkit.h1': 'Gemma 3n Toolkit',
    'toolkit.subheading': 'Everything you need to get started with Gemma 3n development. From quick setup to advanced deployment strategies.',
    'toolkit.tag1': 'Ollama Ready',
    'toolkit.tag2': 'Hugging Face Compatible',
    'toolkit.tag3': 'iOS Optimized',
    'toolkit.resources.title': 'Official Resources',
    'toolkit.resources.description': 'Access the latest official documentation, research papers, and community discussions directly from Google and the open source community.',
    'toolkit.resources.google.title': 'Google Official',
    'toolkit.resources.google.deepmind_page': 'DeepMind Official Page',
    'toolkit.resources.google.deepmind_desc': 'Official model overview, architecture details, and performance benchmarks.',
    'toolkit.resources.google.ai_dev': 'AI for Developers',
    'toolkit.resources.google.ai_dev_desc': 'Technical documentation, API references, and integration guides.',
    'toolkit.resources.google.announcement': 'Official Announcement',
    'toolkit.resources.google.announcement_desc': 'Launch announcement, key features, and architectural innovations.',
    'toolkit.downloads.title': 'Download Models',
    'toolkit.downloads.huggingface': 'Hugging Face Hub',
    'toolkit.downloads.huggingface_desc': 'Official model repositories with multiple format options.',
    'toolkit.downloads.ollama': 'Ollama Library',
    'toolkit.downloads.ollama_desc': 'Easy one-command installation for local development.',
    'toolkit.downloads.ollama_link': 'View on Ollama',
    'toolkit.community.title': 'Community & Research',
    'toolkit.community.reddit': 'r/LocalLLaMA',
    'toolkit.community.reddit_desc': 'Active community discussions, benchmarks, and user experiences.',
    'toolkit.community.hackernews': 'Hacker News',
    'toolkit.community.hackernews_desc': 'Technical discussions and community feedback on Gemma 3n.',
    'toolkit.community.research': 'Research Projects',
    'toolkit.community.research_desc': 'Reverse engineering efforts and architectural analysis.',
    'toolkit.learning.title': 'Learning Resources',
    'toolkit.learning.unsloth': 'Unsloth Blog',
    'toolkit.learning.unsloth_desc': 'Fine-tuning guides and performance optimization techniques.',
    'toolkit.learning.hf_blog': 'Hugging Face Blog',
    'toolkit.learning.hf_blog_desc': 'Technical deep-dives and integration tutorials.',
    'cta.title': 'Ready to Build with Gemma 3n?',
    'cta.subtitle': 'Join thousands of developers already using Gemma 3n in production.',
    'cta.button1': 'Browse Tutorials',
    'cta.button2': 'Download Models',
    
    // Common
    'common.loading': 'Loading...',
    'common.error': 'Error',
    'common.retry': 'Try Again',
    'common.close': 'Close',
    'common.save': 'Save',
    'common.cancel': 'Cancel',
    'common.continue': 'Continue',
    'common.learn.more': 'Learn More',
    'common.get.started': 'Get Started',
    'common.view.all': 'View All',
    
    // PWA
    'pwa.install': 'Install App',
    'pwa.install.desc': 'Install Gemma-3n.net for offline access',
    'pwa.update': 'Update Available',
    'pwa.update.desc': 'A new version is available. Refresh to update.',
    'pwa.offline': 'You\'re offline',
    'pwa.offline.desc': 'Some features may be limited without internet connection.',
    
    // ËØ≠Ë®ÄÂàáÊç¢
    'lang.switch': 'Switch Language',
    'lang.current': 'English',

    // resources
    'resources.heading': 'Resources',
    'resources.subtitle': 'Essential links to get you started and building with Gemma 3n.',
    'resources.category.download': 'Download Models',
    'resources.category.api': 'Official APIs & Guides',
    'resources.download.hf.title': 'Hugging Face',
    'resources.download.hf.desc': 'Access all Gemma 3n models, GGUF versions, and community-tuned variants.',
    'resources.download.ollama.title': 'Ollama',
    'resources.download.ollama.desc': 'Pull and run Gemma 3n models with a single command on your local machine.',
    'resources.download.lmstudio.title': 'LM Studio',
    'resources.download.lmstudio.desc': 'Discover and run Gemma 3n through a user-friendly desktop application.',
    'resources.api.studio.title': 'Google AI Studio',
    'resources.api.studio.desc': 'Experiment with Gemma 3n models directly in your browser with Google\'s free tool.',
    'resources.api.keras.title': 'Keras',
    'resources.api.keras.desc': 'Utilize Gemma 3n with Keras, Google\'s high-level API for building and training models.',
    'resources.api.paper.title': 'Technical Report',
    'resources.api.paper.desc': 'Read the official paper from Google for a deep dive into Gemma 3n\'s architecture.',

    // Demo È°µÈù¢‰∏ªÁªìÊûÑ
    'demo.page.title': 'AI Demo | Interactive Experience',
    'demo.page.description': 'Experience the power of Gemma 3n - run AI models directly in your browser, no installation required.',
    'demo.hero.title': 'Gemma 3n Interactive Experience',
    'demo.hero.subtitle': 'Experience powerful AI features directly in your browser. Code completion ‚Ä¢ Language translation ‚Ä¢ Intelligent Q&A',
    'demo.hero.feature1.title': 'Ultra-fast Response',
    'demo.hero.feature1.desc': 'Millisecond-level AI inference, real-time interaction',
    'demo.hero.feature2.title': 'Privacy First',
    'demo.hero.feature2.desc': 'All data processed locally, never uploaded to the cloud',
    'demo.hero.feature3.title': 'Multi-scenario Support',
    'demo.hero.feature3.desc': 'Coding, translation, chat ‚Äî one model for all',
    'demo.hero.cta': 'Try Now ‚Üí',
    'demo.section.title': 'Interactive AI Demo',
    'demo.section.desc': 'This is a simulated version showing how Gemma 3n works in real-world scenarios. For production, use ONNX.js or WebAssembly to run the real model.',
    'demo.info.title': 'About this Demo',
    'demo.info.current.title': 'Current Features',
    'demo.info.current.feature1': 'Simulates Gemma 3n inference process and response style',
    'demo.info.current.feature2': 'Realistic UI and interaction flow',
    'demo.info.current.feature3': 'Performance metrics based on real hardware data',
    'demo.info.current.feature4': 'Supports three core application scenarios',
    'demo.info.prod.title': 'Production Version',
    'demo.info.prod.feature1': 'Load real Gemma 3n model with ONNX.js',
    'demo.info.prod.feature2': 'Accelerated inference with WebAssembly',
    'demo.info.prod.feature3': 'Full tokenizer and post-processing pipeline',
    'demo.info.prod.feature4': 'Supports model quantization and optimization',
    'demo.tech.title': 'Technical Implementation Path',
    'demo.tech.desc': 'Upgrade the demo to a full-fledged AI application tech stack',
    'demo.tech.frontend.title': 'Frontend Architecture',
    'demo.tech.frontend.engine': 'Lightweight Inference Engine',
    'demo.tech.frontend.engine.code': "// ONNX.js integration\nimport * as ort from 'onnxruntime-web';\n\n// Load model\nconst session = await ort.InferenceSession\n  .create('/models/gemma-3n-e2b.onnx');\n\n// Inference\nconst results = await session.run(feeds);",
    'demo.tech.frontend.wasm': 'WebAssembly Optimization',
    'demo.tech.frontend.wasm.code': "// WebAssembly tokenizer\nimport init, { tokenize } from './pkg/tokenizer.js';\n\n// Initialize WASM module\nawait init();\n\n// High-performance tokenization\nconst tokens = tokenize(inputText);",
    'demo.tech.deploy.title': 'Model Deployment',
    'demo.tech.deploy.convert': 'Model Conversion',
    'demo.tech.deploy.convert1': 'Hugging Face ‚Üí ONNX',
    'demo.tech.deploy.convert2': 'Dynamic quantization (INT8)',
    'demo.tech.deploy.convert3': 'Graph optimization and constant folding',
    'demo.tech.deploy.convert4': 'WebGL backend adaptation',
    'demo.tech.deploy.cdn': 'CDN Distribution',
    'demo.tech.deploy.cdn1': 'Global acceleration with Cloudflare',
    'demo.tech.deploy.cdn2': 'Chunked download strategy',
    'demo.tech.deploy.cdn3': 'Browser cache optimization',
    'demo.tech.deploy.cdn4': 'Progressive loading',
    'demo.tech.deploy.optimize': 'Performance Optimization',
    'demo.tech.deploy.optimize1': 'Web Workers multithreading',
    'demo.tech.deploy.optimize2': 'SharedArrayBuffer',
    'demo.tech.deploy.optimize3': 'WebGPU acceleration (future)',
    'demo.tech.deploy.optimize4': 'Memory pool management',
    'demo.tech.cost.title': 'Zero-cost Solution Advantages',
    'demo.tech.cost.cloud': 'Traditional Cloud AI Cost',
    'demo.tech.cost.cloud1': 'üî¥ OpenAI API: $0.002/1K tokens',
    'demo.tech.cost.cloud2': 'üî¥ Azure OpenAI: $0.0015/1K tokens',
    'demo.tech.cost.cloud3': 'üî¥ Google Cloud AI: $0.001/1K tokens',
    'demo.tech.cost.cloud4': 'üî¥ Monthly: $200-2000 (medium traffic)',
    'demo.tech.cost.device': 'Gemma 3n On-device Solution',
    'demo.tech.cost.device1': '‚úÖ Inference cost: $0',
    'demo.tech.cost.device2': '‚úÖ CDN: $0 (Cloudflare free tier)',
    'demo.tech.cost.device3': '‚úÖ Storage: $0 (static hosting)',
    'demo.tech.cost.device4': '‚úÖ Monthly: $0 + $12/year domain',
    'demo.cta.title': 'Ready to build your AI app?',
    'demo.cta.desc': 'Start with tutorials and master the power of Gemma 3n step by step.',
    'demo.cta.learn': 'Start Learning',
    'demo.cta.toolkit': 'Toolkit',
    'demo.cta.download': 'Download Model',

    // FAQÂå∫Âùó
    'faq.heading': 'Frequently Asked Questions',
    'faq.subtitle': "Got questions? We've got answers. Here are some of the most common things developers ask about Gemma 3n.",
    'faq.q1': 'Is Gemma 3n free to use?',
    'faq.a1': 'Yes, Gemma 3n models are released under a license that permits free access for commercial and research use. Always check the official license terms for details.',
    'faq.q2': "What does 'multimodal' actually mean for Gemma 3n?",
    'faq.a2': 'It means the model can natively understand and process more than just text. It can analyze images and listen to audio, making it suitable for a wider range of applications like describing photos or transcribing speech.',
    'faq.q3': 'How is Gemma 3n different from the regular Gemma 2 or Gemma family?',
    'faq.a3': 'Gemma 3n is specifically optimized for on-device performance. It uses the novel MatFormer architecture to be more efficient in terms of memory and computation, making it ideal for running on phones and laptops.',
    'faq.q4': 'Can I fine-tune Gemma 3n on my own data?',
    'faq.a4': 'Absolutely. The models are designed to be fine-tuned. Google provides recipes and support through frameworks like Keras, PyTorch, and JAX to facilitate this process.',
    'faq.q5': 'How do I run Gemma 3n with Ollama?',
    'faq.a5': "Running Gemma 3n with Ollama is straightforward. Simply install Ollama and run 'ollama run gemma-3n:e4b' for the 4B model or 'ollama run gemma-3n:e2b' for the 2B model. The model will be downloaded automatically.",
    'faq.q6': "What's the difference between Gemma 3n E2B and E4B models?",
    'faq.a6': 'E2B (2B parameters) is smaller and faster, ideal for mobile devices and quick inference. E4B (4B parameters) offers better performance and accuracy but requires more computational resources. Both use the same MatFormer architecture.',
    'faq.q7': 'Can I use Gemma 3n models from Hugging Face?',
    'faq.a7': 'Yes, all Gemma 3n models are available on Hugging Face Hub. You can use them with the transformers library: from transformers import AutoModelForCausalLM, AutoTokenizer. Both 16-bit and quantized versions are available.',
    'faq.q8': 'Is Gemma 3n better than Llama 3 for local AI setups?',
    'faq.a8': "Gemma 3n E4B often outperforms Llama 3 8B in many benchmarks while being smaller and more efficient. For on-device applications, Gemma 3n's MatFormer architecture provides better memory efficiency and faster inference.",
    'faq.q9': 'Can I run Gemma 3n on iOS devices?',
    'faq.a9': 'Yes, Gemma 3n models can run on iOS devices. The E2B model is particularly well-suited for mobile deployment. You can use frameworks like CoreML or run quantized versions for optimal performance on Apple devices.',
    'faq.q10': 'What hardware requirements does Gemma 3n have?',
    'faq.a10': 'Gemma 3n E2B can run on devices with as little as 4GB RAM. E4B typically requires 8GB+ RAM for comfortable operation. Both models can run on CPU-only setups, though GPU acceleration significantly improves inference speed.',
    
    // newsletter
    'newsletter.heading': 'Stay Updated',
    'newsletter.desc': 'Get the latest tutorials and news about Gemma 3n delivered to your inbox. No spam, ever.',
    'newsletter.placeholder': 'Enter your email',
    'newsletter.subscribe': 'Subscribe',

    'footer.independent': 'An independent, community-driven guide to Google‚Äôs Gemma 3n.',
    'footer.rights': 'All rights reserved.',
    'footer.stay_updated': 'Stay Updated',
    'footer.subscribe_desc': 'Get the latest Gemma 3n news, tutorials, and benchmarks delivered to your inbox.',
    'footer.subscribe_button': 'Subscribe',
    'footer.privacy': 'Privacy Policy',
    'footer.terms': 'Terms of Service',

    // Blog
    'blog.title': 'Gemma 3n Developer Blog',
    'blog.description': 'News, tutorials, and in-depth articles on the Gemma 3n AI model.',
    'blog.read_more': 'Read More',
    'blog.giscus.comments': 'Comments',
    'blog.table_of_contents': 'Table of Contents',
    'blog.last_updated': 'Last Updated',
    'blog.share': 'Share This Post',
    'blog.share.twitter': 'Share on Twitter',
    'blog.share.linkedin': 'Share on LinkedIn',
    'blog.share.facebook': 'Share on Facebook',
    'blog.share.copy': 'Copy Link',
    'blog.share.copied': 'Copied!',

    // ÂØπÊØîÈ°µÈù¢
    'compare.title': "Gemma 3n vs. Llama 3: ÁªàÊûÅÂØπÂÜ≥",
    'compare.description': "Ê∑±Â∫¶Êï∞ÊçÆÈ©±Âä®ÂØπÊØî Google Gemma 3n ‰∏é Meta Llama 3„ÄÇÊàë‰ª¨ÂàÜÊûêÂü∫ÂáÜÊµãËØï„ÄÅÁ°¨‰ª∂ÈúÄÊ±ÇÂíå‰ΩøÁî®Âú∫ÊôØÔºåÂä©‰Ω†ÈÄâÊã©ÊúÄÈÄÇÂêà‰Ω†È°πÁõÆÁöÑÊ®°Âûã„ÄÇ",
    'compare.h1': "Gemma 3n <span class='text-blue-600'>ÂØπÂÜ≥</span> Llama 3",
    'compare.subheading': "ÊïàÁéá‰∏éÊÄßËÉΩÁöÑÁ¢∞Êíû„ÄÇÊàë‰ª¨Ê∑±ÂÖ•ÂâñÊûê‰∏§Â§ßÈ¢ÜÂÖàÂºÄÊ∫êÊ®°ÂûãÔºåÂä©‰Ω†Ê†πÊçÆÂÖ∑‰ΩìÈúÄÊ±ÇÂÅöÂá∫ÊúÄÁªàÂÜ≥Á≠ñ„ÄÇ",
    'compare.showdown_badge': "Ê®°ÂûãÂØπÂÜ≥",
    'compare.glance.title': "ÈÄüËßàÔºöÊ†∏ÂøÉÂ∑ÆÂºÇ",
    'compare.glance.feature': "ÁâπÊÄß",
    'compare.glance.gemma': "Gemma 3n (E4B)",
    'compare.glance.llama': "Llama 3 (8B)",
    'compare.glance.architecture': "Êû∂ÊûÑ",
    'compare.glance.architecture.gemma': "MatFormer (Âä®ÊÄÅÁº©Êîæ)",
    'compare.glance.architecture.llama': "Ê†áÂáÜ Transformer",
    'compare.glance.params': "ÊúâÊïàÂèÇÊï∞",
    'compare.glance.params.gemma': "~40‰∫ø",
    'compare.glance.params.llama': "80‰∫ø",
    'compare.glance.strength': "Ê†∏ÂøÉ‰ºòÂäø",
    'compare.glance.strength.gemma': "Á´Ø‰æßÊÄßËÉΩ, È´òÊïàÁéá",
    'compare.glance.strength.llama': "ÂéüÂßãÊé®ÁêÜ & ÁºñÁ®ãËÉΩÂäõ",
    'compare.glance.hardware': "Á°¨‰ª∂ÈúÄÊ±Ç",
    'compare.glance.hardware.gemma': "<span class='font-semibold text-green-600 dark:text-green-400'>‰Ωé</span> (Áé∞‰ª£Á¨îËÆ∞Êú¨)",
    'compare.glance.hardware.llama': "<span class='font-semibold text-orange-500'>‰∏≠</span> (ÈúÄË¶ÅËâØÂ•ΩGPU)",
    'compare.glance.multimodality': "Â§öÊ®°ÊÄÅËÉΩÂäõ",
    'compare.glance.multimodality.gemma': "ÂéüÁîüÊîØÊåÅÊñáÊú¨„ÄÅÈü≥È¢ë„ÄÅÂõæÂÉè",
    'compare.glance.multimodality.llama': "‰ªÖÊñáÊú¨",
    'compare.benchmarks.title': "ÊÄßËÉΩÂü∫ÂáÜÊµãËØï",
    'compare.benchmarks.note': "*Âü∫ÂáÜÂàÜÊï∞ÊòØÂü∫‰∫éÂÖ¨ÂºÄËÅöÂêàÊï∞ÊçÆÁöÑËØ¥ÊòéÊÄßÂ±ïÁ§∫„ÄÇ",
    'compare.deepdive.title': "Ê∑±Â∫¶ÂàÜÊûê",
    'compare.deepdive.gemma.title': "üèÜ Gemma 3n ÁöÑËÉúÂá∫‰πãÂ§Ñ",
    'compare.deepdive.gemma.1.title': "ÊïàÁéá‰∏éÂèØÂèäÊÄß",
    'compare.deepdive.gemma.1.desc': "Âú®Ê∂àË¥πÁ∫ßÁ°¨‰ª∂ÔºàÁ¨îËÆ∞Êú¨„ÄÅÊâãÊú∫Ôºâ‰∏äÊµÅÁïÖËøêË°åÔºåRAMÂç†Áî®ÊòæËëóÂáèÂ∞ëÔºåÊòØÁ´Ø‰æßÂ∫îÁî®ÁöÑÂÆåÁæéÈÄâÊã©„ÄÇ",
    'compare.deepdive.gemma.2.title': "ÂéüÁîüÂ§öÊ®°ÊÄÅ",
    'compare.deepdive.gemma.2.desc': "‰ªéÂ∫ïÂ±ÇËÆæËÆ°Â∞±ÊîØÊåÅÂú®Âçï‰∏ÄÊ®°Âûã‰∏≠ÁêÜËß£ÊñáÊú¨„ÄÅÈü≥È¢ëÂíåÂõæÂÉèÔºåËß£ÈîÅ‰∫ÜLlamaÊó†Ê≥ïÂçïÁã¨Â§ÑÁêÜÁöÑÊñ∞ÂûãÂ∫îÁî®„ÄÇ",
    'compare.deepdive.gemma.3.title': "Âä®ÊÄÅÊû∂ÊûÑ",
    'compare.deepdive.gemma.3.desc': "MatFormerÊû∂ÊûÑ‰ΩøÂÖ∂ËÉΩÂä®ÊÄÅË∞ÉÊï¥ËÆ°ÁÆóÈáèÔºåÊó†ÈúÄÂ∑®Â§ßÁöÑÈùôÊÄÅÂèÇÊï∞Âç≥ÂèØÊèê‰æõÂùáË°°ÁöÑÊÄßËÉΩ„ÄÇ",
    'compare.deepdive.llama.title': "üèÜ Llama 3 ÁöÑËÉúÂá∫‰πãÂ§Ñ",
    'compare.deepdive.llama.1.title': "ÂéüÂßãÊé®ÁêÜ‰∏éÁºñÁ®ãËÉΩÂäõ",
    'compare.deepdive.llama.1.desc': "Âá≠ÂÄüÊõ¥Â§ö‰∏ìÁî®ÂèÇÊï∞ÔºåLlama 3Âú®Â§çÊùÇÈÄªËæëÊé®ÁêÜ„ÄÅÊï∞Â≠¶ÈóÆÈ¢òÂíå‰ª£Á†ÅÁîüÊàêÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåÁ∫ØÊñáÊú¨Âü∫ÂáÜÊµãËØïÈÄöÂ∏∏‰ºò‰∫éGemma„ÄÇ",
    'compare.deepdive.llama.2.title': "ÊàêÁÜüÁöÑÂæÆË∞ÉÁîüÊÄÅ",
    'compare.deepdive.llama.2.desc': "‰Ωú‰∏∫‰∏Ä‰∏™Êõ¥ÊàêÁÜüÁöÑÊû∂ÊûÑÔºåÁ§æÂå∫‰∏∫Llama 3Ë¥°ÁåÆ‰∫ÜÂ§ßÈáèÈíàÂØπÁâπÂÆö‰ªªÂä°ÁöÑÂæÆË∞ÉÁâàÊú¨„ÄÇ",
    'compare.deepdive.llama.3.title': "ÂèØÈ¢ÑÊµãÁöÑÊÄßËÉΩ",
    'compare.deepdive.llama.3.desc': "ÂÖ∂Ê†áÂáÜTransformerÊû∂ÊûÑÊÑèÂë≥ÁùÄÊÄßËÉΩÈùûÂ∏∏ÂèØÈ¢ÑÊµãÔºåÂπ∂‰∏îËÉΩÈöèÊõ¥Âº∫Â§ßÁöÑÁ°¨‰ª∂ÂæàÂ•ΩÂú∞Êâ©Â±ï„ÄÇ",
    'compare.verdict.title': "ÊúÄÁªàË£ÅÂÜ≥ÔºöÂì™Ê¨æÈÄÇÂêà‰Ω†Ôºü",
    'compare.verdict.subtitle': "‰Ω†ÁöÑÈÄâÊã©ÂÆåÂÖ®ÂèñÂÜ≥‰∫éÈ°πÁõÆÁöÑÊ†∏ÂøÉÁõÆÊ†á„ÄÇ",
    'compare.verdict.gemma.title': "ÈÄâÊã© Gemma 3n Â¶ÇÊûú...",
    'compare.verdict.gemma.bullet1': "‰Ω†Ê≠£Âú®‰∏∫**ÁßªÂä®ÊàñËæπÁºòËÆæÂ§á**ÊûÑÂª∫Â∫îÁî®„ÄÇ",
    'compare.verdict.gemma.bullet2': "‰Ω†ÁöÑÂ∫îÁî®ÈúÄË¶Å**Â§öÊ®°ÊÄÅËÉΩÂäõ**ÔºàÈü≥È¢ë/ËßÜËßâÔºâ„ÄÇ",
    'compare.verdict.gemma.bullet3': "**ËµÑÊ∫êÊïàÁéá**Âíå‰ΩéRAMÂç†Áî®Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ",
    'compare.verdict.gemma.bullet4': "‰Ω†ÈúÄË¶Å‰∏Ä‰∏™Áî®‰∫éÈÄöÁî®‰ªªÂä°ÁöÑ„ÄÅÂùáË°°ÁöÑÂÖ®Èù¢Ê®°Âûã„ÄÇ",
    'compare.verdict.llama.title': "ÈÄâÊã© Llama 3 Â¶ÇÊûú...",
    'compare.verdict.llama.bullet1': "‰Ω†ÁöÑ‰∏ªË¶ÅÁî®‰æãÊòØ**Â§çÊùÇÁöÑÁºñÁ®ãÊàñÊé®ÁêÜ**„ÄÇ",
    'compare.verdict.llama.bullet2': "‰Ω†Êã•Êúâ**Âº∫Â§ßÁöÑGPU**„ÄÇ",
    'compare.verdict.llama.bullet3': "‰Ω†ÈúÄË¶ÅÂú®**Á∫ØÊñáÊú¨‰ªªÂä°**‰∏äËé∑ÂæóÁªùÂØπÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇ",
    'compare.verdict.llama.bullet4': "‰Ω†ÊÉ≥Âà©Áî®Â∫ûÂ§ßÁöÑÁ§æÂå∫ÂæÆË∞ÉÊ®°ÂûãÂ∫ì„ÄÇ",
    'compare.cta.title': "ÂáÜÂ§áÂ•ΩÊ∑±ÂÖ•Êé¢Á¥¢‰∫ÜÂêóÔºü",
    'compare.cta.subtitle': "ÊµèËßàÊàë‰ª¨ÁöÑÂÆûÊàòÊïôÁ®ãÔºåÊéåÊè°Ëøô‰∏§Ê¨æÊ®°Âûã„ÄÇ",
    'compare.cta.button1': "ÊµèËßàÂÖ®ÈÉ®ÊïôÁ®ã",
    'compare.cta.button2': "Ëé∑ÂèñÂ∑•ÂÖ∑ÁÆ±",

    // Leaderboard Page
    'leaderboard.title': "AI Model Leaderboard: The Best Open Source Models",
    'leaderboard.description': "A data-driven, sortable leaderboard comparing the top open-source AI models like Gemma 3n, Llama 3, Phi-3, and Qwen 2. Filter by benchmarks like MMLU, GSM8K, and HumanEval.",
    'leaderboard.h1': "Open Model Leaderboard",
    'leaderboard.subheading': "The definitive, data-driven ranking of today's top open-source AI models. Sort, compare, and find the best model for your needs.",
    'leaderboard.badge': "Community Benchmark",
    'leaderboard.table.rank': "Rank",
    'leaderboard.table.model': "Model",
    'leaderboard.table.params': "Params (B)",
    'leaderboard.table.mmlu': "MMLU",
    'leaderboard.table.gsm8k': "GSM8K",
    'leaderboard.table.humaneval': "HumanEval",
    'leaderboard.table.tags': "Tags",
    'leaderboard.notes.definitions': "* MMLU: Massive Multitask Language Understanding. GSM8K: Grade School Math. HumanEval: Code Generation.",
    'leaderboard.notes.disclaimer': "* Performance data is based on publicly available information and may vary based on quantization and implementation.",
    'leaderboard.tags.reasoning': "Reasoning Power",
    'leaderboard.tags.efficiency': "Efficiency King",
    'leaderboard.tags.multimodal': "Multimodal",
    'leaderboard.tags.coder': "Strong Coder",
    'leaderboard.tags.on_device': "On-Device",
    'leaderboard.tags.fast': "Fast",

    // Privacy and Terms
    'privacy.title': "Privacy Policy",
    'privacy.h1': "Privacy Policy for Gemma-3n.net",
    'privacy.effective_date': "Effective Date: July 1, 2025",
    'privacy.p1': "Welcome to Gemma-3n.net. We are committed to protecting your privacy. This Privacy Policy explains how we collect, use, disclose, and safeguard your information when you visit our website. Please read this privacy policy carefully. If you do not agree with the terms of this privacy policy, please do not access the site.",
    'privacy.h2_info': "Collection of Your Information",
    'privacy.p2': "We may collect information about you in a variety of ways. The information we may collect on the Site includes:",
    'privacy.h3_personal': "Personal Data",
    'privacy.p3': "Personally identifiable information, such as your email address, that you voluntarily give to us when you subscribe to our newsletter.",
    'privacy.h3_analytics': "Derivative Data",
    'privacy.p4': "Information our servers automatically collect when you access the Site, such as your IP address, your browser type, your operating system, your access times, and the pages you have viewed directly before and after accessing the Site. We use a privacy-focused analytics service and do not use Google Analytics.",
    'privacy.h2_use': "Use of Your Information",
    'privacy.p5': "Having accurate information about you permits us to provide you with a smooth, efficient, and customized experience. Specifically, we may use information collected about you via the Site to: email you regarding your account or order, respond to customer service requests, and send you a newsletter.",
    'privacy.h2_security': "Security of Your Information",
    'privacy.p6': "We use administrative, technical, and physical security measures to help protect your personal information. While we have taken reasonable steps to secure the personal information you provide to us, please be aware that despite our efforts, no security measures are perfect or impenetrable, and no method of data transmission can be guaranteed against any interception or other type of misuse.",
    'privacy.h2_contact': "Contact Us",
    'privacy.p7': "If you have questions or comments about this Privacy Policy, please contact us at: legal@gemma-3n.net",

    'terms.title': "Terms of Service",
    'terms.h1': "Terms of Service for Gemma-3n.net",
    'terms.effective_date': "Effective Date: July 1, 2025",
    'terms.p1': "By using the website located at Gemma-3n.net (the \"Site\"), you agree to be bound by these Terms of Service (this \"Agreement\"), whether or not you register as a member. If you do not agree with these terms, you should not use the Site.",
    'terms.h2_use': "Use of the Site",
    'terms.p2': "You may use the Site for your personal, non-commercial use only. You agree not to use the Site for any purpose that is unlawful or prohibited by this Agreement. You may not use the Site in any manner that could damage, disable, overburden, or impair the Site.",
    'terms.h2_disclaimer': "Disclaimer",
    'terms.p3': "The information provided on the Site is for general informational purposes only. All information on the Site is provided in good faith, however we make no representation or warranty of any kind, express or implied, regarding the accuracy, adequacy, validity, reliability, availability or completeness of any information on the Site.",
    'terms.h2_liability': "Limitation of Liability",
    'terms.p4': "IN NO EVENT WILL WE OR OUR DIRECTORS, EMPLOYEES, OR AGENTS BE LIABLE TO YOU OR ANY THIRD PARTY FOR ANY DIRECT, INDIRECT, CONSEQUENTIAL, EXEMPLARY, INCIDENTAL, SPECIAL, OR PUNITIVE DAMAGES, INCLUDING LOST PROFIT, LOST REVENUE, LOSS OF DATA, OR OTHER DAMAGES ARISING FROM YOUR USE OF THE SITE, EVEN IF WE HAVE BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.",
    'terms.h2_governing': "Governing Law",
    'terms.p5': "This Agreement shall be governed by and construed in accordance with the laws of the State of California, without regard to its conflict of law principles.",
    'terms.h2_contact': "Contact Us",
    'terms.p6': "If you have questions or comments about these Terms of Service, please contact us at: legal@gemma-3n.net",
  },
  zh: {
    // ÂØºËà™
    'nav.home': 'È¶ñÈ°µ',
    'nav.about': 'ÂÖ≥‰∫é',
    'nav.benchmarks': 'ÊÄßËÉΩÊµãËØï',
    'nav.blog': 'ÂçöÂÆ¢',
    'nav.toolkit': 'Â∑•ÂÖ∑ÁÆ±',
    'nav.resources': 'ËµÑÊ∫ê',
    'nav.faq': 'Â∏∏ËßÅÈóÆÈ¢ò',
    'nav.demo': 'ÊºîÁ§∫',
    'nav.compare': 'ÂØπÊØî',
    'nav.leaderboard': 'ÊéíË°åÊ¶ú',
    
    // È¶ñÈ°µ
    'hero.title': 'Gemma-3n.net: ÁªàÊûÅÂºÄÂèëËÄÖÊåáÂçó',
    'hero.subtitle': 'ÈÄöËøáÂÖ®Èù¢ÁöÑÊïôÁ®ã„ÄÅÂü∫ÂáÜÊµãËØïÂíåÂ∑•ÂÖ∑ÔºåÊéåÊè°GoogleÁöÑGemma 3n AIÊ®°Âûã„ÄÇ',
    'hero.cta.primary': 'ÂºÄÂßã‰ΩøÁî®',
    'hero.cta.secondary': 'Êü•ÁúãÊºîÁ§∫',
    
    // SEO
    'seo.home.title': 'Gemma-3n.net: Google Gemma 3n ÁªàÊûÅÂºÄÂèëËÄÖÊåáÂçó',
    'seo.home.description': 'ÈÄöËøáÂÖ®Èù¢ÁöÑÊïôÁ®ã„ÄÅÂü∫ÂáÜÊµãËØïÂíåÂ∑•ÂÖ∑ÔºåÊéåÊè°GoogleÁöÑGemma 3n AIÊ®°Âûã„ÄÇÊÇ®ËøõË°åÊú¨Âú∞Âíå‰∫ëÁ´ØÈÉ®ÁΩ≤ÁöÑÈáçË¶ÅËµÑÊ∫ê„ÄÇ',
    'seo.about.title': 'ÂÖ≥‰∫é Gemma-3n.net | Êàë‰ª¨ÁöÑ‰ΩøÂëΩ‰∏éÊñπÊ≥ïËÆ∫',
    'seo.about.description': '‰∫ÜËß£ Gemma-3n.net ÁöÑ‰ΩøÂëΩÔºö‰∏∫Gemma 3nÂºÄÂèëËÄÖÁ§æÂå∫Êèê‰æõÊúÄÂáÜÁ°Æ„ÄÅÁã¨Á´ãÂíåÊúÄÊñ∞ÁöÑËµÑÊ∫ê„ÄÇ',
    'seo.blog.title': 'Gemma 3n ÂçöÂÆ¢ | ÊïôÁ®ã„ÄÅÊñ∞Èóª‰∏éÊ∑±Â∫¶ÂàÜÊûê',
    'seo.blog.description': 'Gemma-3n.net ÁöÑÂÆòÊñπÂçöÂÆ¢„ÄÇÊü•ÊâæÂÖ≥‰∫éÂæÆË∞É„ÄÅÈÉ®ÁΩ≤Âíå‰ºòÂåñGemma 3nÊ®°ÂûãÁöÑÊúÄÊñ∞Ê∂àÊÅØ„ÄÅ‰∏ìÂÆ∂ÊïôÁ®ãÂíåÊ∑±Â∫¶ÊñáÁ´†„ÄÇ',
    'seo.toolkit.title': 'Gemma 3n Â∑•ÂÖ∑ÁÆ± | ‰∏ãËΩΩ„ÄÅÊåáÂçóÂíåÂÆòÊñπËµÑÊ∫ê',
    'seo.toolkit.description': 'Gemma 3n ÁöÑÂÆåÊï¥ÂºÄÂèëËÄÖÂ∑•ÂÖ∑ÁÆ±„ÄÇËé∑ÂèñÂÆòÊñπÊ®°Âûã‰∏ãËΩΩ„ÄÅOllamaÂíåHugging FaceÁöÑËÆæÁΩÆÊåáÂçó„ÄÅiOSÈÉ®ÁΩ≤ÊñáÊ°£Á≠â„ÄÇ',
    'seo.compare.title': 'Gemma 3n vs. Llama 3: AIÊ®°ÂûãÊ∑±Â∫¶ÂØπÊØî',
    'seo.compare.description': 'GoogleÁöÑGemma 3n‰∏éMetaÁöÑLlama 3ÁöÑÊ≠£Èù¢Êï∞ÊçÆÈ©±Âä®ÂØπÊØî„ÄÇÂàÜÊûêÊÄßËÉΩÂü∫ÂáÜ„ÄÅÊû∂ÊûÑÂíåÁúüÂÆû‰∏ñÁïåÁî®‰æã„ÄÇ',
    'seo.leaderboard.title': 'AIÊ®°ÂûãÊéíË°åÊ¶ú | ÂØπÊØîGemma 3n„ÄÅLlama 3Á≠â',
    'seo.leaderboard.description': 'ÂÆûÊó∂ÁöÑAIÊ®°ÂûãÊéíË°åÊ¶úÔºåÊØîËæÉÊúÄÊñ∞ÁöÑÂºÄÊ∫êÂíå‰∏ìÊúâÊ®°ÂûãÂú®ÂÖ≥ÈîÆË°å‰∏öÂü∫ÂáÜ‰∏äÁöÑË°®Áé∞„ÄÇÊü•ÁúãGemma 3n‰∏éÁ´û‰∫âÂØπÊâãÁöÑËæÉÈáè„ÄÇ',

    // Demo
    'demo.title': 'üöÄ Gemma 3n ‰∫§‰∫íÂºèDemo',
    'demo.subtitle': '‰ΩìÈ™åÊµèËßàÂô®ÂÜÖAIÊé®ÁêÜ - ÂÆåÂÖ®Êú¨Âú∞ÂåñÔºåÊó†ÈúÄÊúçÂä°Âô®',
    'demo.loading.initializing': 'Ê≠£Âú®ÂàùÂßãÂåñËΩªÈáèÁ∫ßAIÊ®°Âûã...',
    'demo.loading.engine': '‰∏ãËΩΩËΩªÈáèÁ∫ßÊé®ÁêÜÂºïÊìé...',
    'demo.loading.wasm': 'ÂàùÂßãÂåñWebAssemblyÊ®°Âùó...',
    'demo.loading.vocab': 'Âä†ËΩΩËØçÊ±áË°®ÂíåÈÖçÁΩÆ...',
    'demo.loading.weights': '‰ºòÂåñÊ®°ÂûãÊùÉÈáç...',
    'demo.loading.ready': 'Ê®°ÂûãÂ∞±Áª™ÔºÅ',
    'demo.status.ready': '‚úÖ Gemma 3n Lite Â∑≤Â∞±Áª™ (Âú®Á∫øDemoÁâàÊú¨)',
    'demo.scenarios.label': 'ÈÄâÊã©ÊºîÁ§∫Âú∫ÊôØ',
    'demo.scenarios.code.title': '‰ª£Á†ÅË°•ÂÖ®',
    'demo.scenarios.code.description': 'Êô∫ËÉΩ‰ª£Á†ÅÂª∫ËÆÆ',
    'demo.scenarios.translate.title': 'ËØ≠Ë®ÄÁøªËØë',
    'demo.scenarios.translate.description': 'Â§öËØ≠Ë®Ä‰∫íËØë',
    'demo.scenarios.chat.title': 'Êô∫ËÉΩÈóÆÁ≠î',
    'demo.scenarios.chat.description': 'ÂØπËØùÂä©Êâã',
    'demo.input.label': 'ËæìÂÖ•ÊñáÊú¨',
    'demo.input.placeholder': 'ËæìÂÖ•ÊÇ®ÁöÑÊñáÊú¨...',
    'demo.parameters.label': 'Ê∏©Â∫¶ËÆæÁΩÆ (ÂàõÈÄ†ÊÄß)',
    'demo.parameters.conservative': '‰øùÂÆà',
    'demo.parameters.creative': 'ÂàõÊñ∞',
    'demo.button.loading': 'Ê®°ÂûãÂä†ËΩΩ‰∏≠...',
    'demo.button.generate': 'ÁîüÊàêAIÂõûÂ§ç',
    'demo.button.generating': 'ÁîüÊàê‰∏≠...',
    'demo.output.label': 'AIËæìÂá∫ÁªìÊûú',
    'demo.output.placeholder': 'AIÁîüÊàêÁöÑÂÜÖÂÆπÂ∞ÜÂú®ËøôÈáåÊòæÁ§∫...',
    'demo.output.thinking': 'ü§ñ AIÊ≠£Âú®ÊÄùËÄÉ...',
    'demo.output.error': '‚ùå ÁîüÊàêÂ§±Ë¥•:',
    'demo.alert.no_input': 'ËØ∑ËæìÂÖ•‰∏Ä‰∫õÊñáÊú¨',
    'demo.metrics.tokensPerSecond': 'Tokens/Áßí',
    'demo.metrics.inferenceTime': 'Êé®ÁêÜÊó∂Èó¥(ms)',
    'demo.metrics.memoryUsage': 'ÂÜÖÂ≠ò‰ΩøÁî®(MB)',
    'demo.metrics.modelSize': 'Ê®°ÂûãÂ§ßÂ∞è',
    'demo.placeholders.code': `function fibonacci(n) {
  // ËÆ°ÁÆóÊñêÊ≥¢ÈÇ£Â•ëÊï∞Âàó
  if (n <= 1) return n;
  return`,
    'demo.placeholders.translate': `ËØ∑Â∞Ü‰ª•‰∏ãÊñáÊú¨ÁøªËØëÊàêËã±ÊñáÔºö
‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊîπÂèòÊàë‰ª¨ÁöÑ‰∏ñÁïå„ÄÇ`,
    'demo.placeholders.chat': `‰Ω†Â•ΩÔºåÊàëÊÉ≥‰∫ÜËß£Gemma 3nÊ®°ÂûãÁöÑÁâπÁÇπÂíå‰ºòÂäø„ÄÇ`,
    'demo.simulations.code_response': ` fibonacci(n - 1) + fibonacci(n - 2);
}

// ‰ºòÂåñÁâàÊú¨Ôºö‰ΩøÁî®Âä®ÊÄÅËßÑÂàí
function fibonacciDP(n) {
  const dp = [0, 1];
  for (let i = 2; i <= n; i++) {
    dp[i] = dp[i-1] + dp[i-2];
  }
  return dp[n];
}`,
    'demo.simulations.translation_response': `**ÁøªËØëÁªìÊûú:**
‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊîπÂèòÊàë‰ª¨ÁöÑ‰∏ñÁïå„ÄÇ

*Ê£ÄÊµãÂà∞ÁöÑËØ≠Ë®Ä: ‰∏≠Êñá ‚Üí Ëã±Êñá*`,
    'demo.simulations.chat_response_1': `ÊÇ®Â•ΩÔºÅÊàëÂæàÈ´òÂÖ¥‰∏∫ÊÇ®‰ªãÁªçGemma 3n„ÄÇËøôÊòØGoogleÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÂ§öÊ®°ÊÄÅAIÊ®°ÂûãÔºåÂÖ∑Êúâ‰ª•‰∏ãÁâπÁÇπÔºö

üéØ **ËÆæÂ§áÁ´Ø‰ºòÂåñ**: ‰∏ì‰∏∫ÊâãÊú∫„ÄÅÁ¨îËÆ∞Êú¨Á≠âËÆæÂ§áËÆæËÆ°
‚ö° **È´òÊïàÊû∂ÊûÑ**: MatFormer"ÂµåÂ•ó"TransformerÁªìÊûÑ
üé® **Â§öÊ®°ÊÄÅËÉΩÂäõ**: ÊîØÊåÅÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÈü≥È¢ëÂ§ÑÁêÜ
üîß **ÂºÄÂèëËÄÖÂèãÂ•Ω**: ‰∏é‰∏ªÊµÅAIÂ∑•ÂÖ∑ÁîüÊÄÅÂÖºÂÆπ

ÊÇ®ËøòÊÉ≥‰∫ÜËß£Âì™‰∏™ÊñπÈù¢ÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºü`,
    'demo.simulations.chat_response_2': `Gemma 3nÁõ∏ÊØîÂÖ∂‰ªñÊ®°ÂûãÁöÑ‰ºòÂäøÂú®‰∫éÔºö

1. **Êõ¥Â∞èÁöÑÂÜÖÂ≠òÂç†Áî®**: E2BÁâàÊú¨‰ªÖÈúÄ4GBÂÜÖÂ≠ò
2. **Êõ¥Âø´ÁöÑÊé®ÁêÜÈÄüÂ∫¶**: ÈíàÂØπÁßªÂä®ËÆæÂ§á‰ºòÂåñ
3. **Êõ¥Â•ΩÁöÑÂáÜÁ°ÆÊÄß**: MMLUÂü∫ÂáÜÊµãËØïËææÂà∞79.8%
4. **Êõ¥Âº∫ÁöÑÂ§öÊ®°ÊÄÅ**: ÂéüÁîüÊîØÊåÅËßÜËßâÂíåÈü≥È¢ë

Ëøô‰ΩøÂæóÂÆÉÁâπÂà´ÈÄÇÂêàÊûÑÂª∫ÈöêÁßÅ‰ºòÂÖàÁöÑËÆæÂ§áÁ´ØAIÂ∫îÁî®„ÄÇ`,
    'demo.simulations.chat_response_3': `ÂÖ≥‰∫éGemma 3nÁöÑÊäÄÊúØÂÆûÁé∞ÔºåÊàëÂª∫ËÆÆÊÇ®Ôºö

üìö **Â≠¶‰π†Ë∑ØÂæÑ**: ‰ªéÊàë‰ª¨ÁöÑÂÖ•Èó®ÊïôÁ®ãÂºÄÂßã
üíª **ÂÆûË∑µÈ°πÁõÆ**: Â∞ùËØïiOSÈÉ®ÁΩ≤ÊàñOllamaÈõÜÊàê
üîß **ËøõÈò∂ÊäÄËÉΩ**: Â≠¶‰π†LoRAÂæÆË∞ÉÊäÄÊúØ
üåê **Á§æÂå∫ÂèÇ‰∏é**: ÂÖ≥Ê≥®ÊúÄÊñ∞ÁöÑÊ®°ÂûãÊõ¥Êñ∞Âíå‰ºòÂåñ

ÈúÄË¶ÅÊàë‰∏∫ÊÇ®Êé®ËçêÂÖ∑‰ΩìÁöÑÊïôÁ®ãÂêóÔºü`,
    
    // ÂèÇÊï∞ÊéßÂà∂
    'controls.temperature': 'Ê∏©Â∫¶ÂÄº',
    'controls.temperature.desc': 'ÊéßÂà∂ËæìÂá∫ÁöÑÈöèÊú∫ÊÄß',
    'controls.maxTokens': 'ÊúÄÂ§ßÈïøÂ∫¶',
    'controls.maxTokens.desc': 'ÁîüÊàêÊñáÊú¨ÁöÑÊúÄÂ§ßÈïøÂ∫¶',
    'controls.topK': 'Top-K',
    'controls.topK.desc': 'ÈôêÂà∂ËØçÊ±áË°®‰ª•Ëé∑ÂæóÊõ¥ÈõÜ‰∏≠ÁöÑËæìÂá∫',
    
    // ÊÄßËÉΩÁõëÊéß
    'metrics.inference': 'Êé®ÁêÜÊó∂Èó¥',
    'metrics.memory': 'ÂÜÖÂ≠ò‰ΩøÁî®',
    'metrics.tokens': '‰ª§Áâå/Áßí',
    'metrics.local': 'Êú¨Âú∞Â§ÑÁêÜ',
    'metrics.api': 'APIË∞ÉÁî®',
    
    // È¢ÑËÆæÂú∫ÊôØ
    'scenarios.code': '‰ª£Á†ÅÁîüÊàê',
    'scenarios.code.desc': 'ÁîüÊàêÂíåË°•ÂÖ®‰ª£Á†Å',
    'scenarios.text': 'ÊñáÊú¨ÁîüÊàê',
    'scenarios.text.desc': 'ÂàõÊÑèÂÜô‰ΩúÂíåÂÜÖÂÆπÂàõ‰Ωú',
    'scenarios.chat': 'ÈóÆÁ≠îÂØπËØù',
    'scenarios.chat.desc': '‰∫§‰∫íÂºèÂØπËØù',
    
    // Â∑•ÂÖ∑ÁÆ±
    'toolkit.title': 'Gemma 3n Â∑•ÂÖ∑ÁÆ± - ÂÆåÊï¥ÁöÑÂºÄÂèëËÄÖËµÑÊ∫ê',
    'toolkit.description': 'Gemma 3n ÂºÄÂèëÁöÑÁªºÂêàÂ∑•ÂÖ∑ÁÆ±„ÄÇÂåÖÊã¨ Ollama ËÆæÁΩÆ„ÄÅHugging Face ÈõÜÊàê„ÄÅiOS ÈÉ®ÁΩ≤ÊåáÂçóÂíåÊ®°ÂûãÊØîËæÉÂ∑•ÂÖ∑„ÄÇ',
    'toolkit.h1': 'Gemma 3n Toolkit',
    'toolkit.subheading': 'ÊÇ®ÂºÄÂßã Gemma 3n ÂºÄÂèëÊâÄÈúÄÁöÑ‰∏ÄÂàá„ÄÇ‰ªéÂø´ÈÄüËÆæÁΩÆÂà∞È´òÁ∫ßÈÉ®ÁΩ≤Á≠ñÁï•„ÄÇ',
    'toolkit.tag1': 'Ollama Â∞±Áª™',
    'toolkit.tag2': 'Hugging Face ÂÖºÂÆπ',
    'toolkit.tag3': 'iOS ‰ºòÂåñ',
    'toolkit.resources.title': 'ÂÆòÊñπËµÑÊ∫ê',
    'toolkit.resources.description': 'Áõ¥Êé•‰ªéË∞∑Ê≠åÂíåÂºÄÊ∫êÁ§æÂå∫ËÆøÈóÆÊúÄÊñ∞ÁöÑÂÆòÊñπÊñáÊ°£„ÄÅÁ†îÁ©∂ËÆ∫ÊñáÂíåÁ§æÂå∫ËÆ®ËÆ∫„ÄÇ',
    'toolkit.resources.google.title': 'Google Official',
    'toolkit.resources.google.deepmind_page': 'DeepMind Official Page',
    'toolkit.resources.google.deepmind_desc': 'Official model overview, architecture details, and performance benchmarks.',
    'toolkit.resources.google.ai_dev': 'AI for Developers',
    'toolkit.resources.google.ai_dev_desc': 'Technical documentation, API references, and integration guides.',
    'toolkit.resources.google.announcement': 'Official Announcement',
    'toolkit.resources.google.announcement_desc': 'Launch announcement, key features, and architectural innovations.',
    'toolkit.downloads.title': 'Download Models',
    'toolkit.downloads.huggingface': 'Hugging Face Hub',
    'toolkit.downloads.huggingface_desc': 'Official model repositories with multiple format options.',
    'toolkit.downloads.ollama': 'Ollama Library',
    'toolkit.downloads.ollama_desc': 'Easy one-command installation for local development.',
    'toolkit.downloads.ollama_link': 'View on Ollama',
    'toolkit.community.title': 'Community & Research',
    'toolkit.community.reddit': 'r/LocalLLaMA',
    'toolkit.community.reddit_desc': 'Active community discussions, benchmarks, and user experiences.',
    'toolkit.community.hackernews': 'Hacker News',
    'toolkit.community.hackernews_desc': 'Technical discussions and community feedback on Gemma 3n.',
    'toolkit.community.research': 'Research Projects',
    'toolkit.community.research_desc': 'Reverse engineering efforts and architectural analysis.',
    'toolkit.learning.title': 'Learning Resources',
    'toolkit.learning.unsloth': 'Unsloth Blog',
    'toolkit.learning.unsloth_desc': 'Fine-tuning guides and performance optimization techniques.',
    'toolkit.learning.hf_blog': 'Hugging Face Blog',
    'toolkit.learning.hf_blog_desc': 'Technical deep-dives and integration tutorials.',
    'cta.title': 'Ready to Build with Gemma 3n?',
    'cta.subtitle': 'Join thousands of developers already using Gemma 3n in production.',
    'cta.button1': 'Browse Tutorials',
    'cta.button2': 'Download Models',
    
    // ÈÄöÁî®
    'common.loading': 'Âä†ËΩΩ‰∏≠...',
    'common.error': 'ÈîôËØØ',
    'common.retry': 'ÈáçËØï',
    'common.close': 'ÂÖ≥Èó≠',
    'common.save': '‰øùÂ≠ò',
    'common.cancel': 'ÂèñÊ∂à',
    'common.continue': 'ÁªßÁª≠',
    'common.learn.more': '‰∫ÜËß£Êõ¥Â§ö',
    'common.get.started': 'ÂºÄÂßã‰ΩøÁî®',
    'common.view.all': 'Êü•ÁúãÂÖ®ÈÉ®',
    
    // PWA
    'pwa.install': 'ÂÆâË£ÖÂ∫îÁî®',
    'pwa.install.desc': 'ÂÆâË£Ö Gemma-3n.net ‰ª•‰æøÁ¶ªÁ∫øËÆøÈóÆ',
    'pwa.update': 'ÊúâÂèØÁî®Êõ¥Êñ∞',
    'pwa.update.desc': 'Êñ∞ÁâàÊú¨ÂèØÁî®ÔºåÂà∑Êñ∞È°µÈù¢‰ª•Êõ¥Êñ∞„ÄÇ',
    'pwa.offline': 'ÊÇ®ÂΩìÂâçÁ¶ªÁ∫ø',
    'pwa.offline.desc': 'Ê≤°ÊúâÁΩëÁªúËøûÊé•Êó∂Êüê‰∫õÂäüËÉΩÂèØËÉΩÂèóÈôê„ÄÇ',

    // ËØ≠Ë®ÄÂàáÊç¢
    'lang.switch': 'ÂàáÊç¢ËØ≠Ë®Ä',
    'lang.current': '‰∏≠Êñá',

    // Âü∫ÂáÜÊµãËØï
    'benchmarks.title': 'ÊÄßËÉΩÂü∫ÂáÜ',
    'benchmarks.subtitle': 'Gemma 3n ‰∏éÁ´û‰∫âÂØπÊâãÁõ∏ÊØîË°®Áé∞Â¶Ç‰ΩïÔºüËøôÈáåÊòØÊï∞ÊçÆÂØπÊØî„ÄÇ',
    'benchmarks.source': 'Êï∞ÊçÆÊù•Ê∫ê‰∫éGoogle AIÂÆòÊñπÂèëÂ∏ÉÂíåÁã¨Á´ãÂü∫ÂáÜÊµãËØï„ÄÇ',
    'benchmarks.heading': 'ÊÄßËÉΩÂü∫ÂáÜ',
    'benchmarks.mmlu.title': 'MMLU',
    'benchmarks.mmlu.desc': 'Â§ö‰ªªÂä°ËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõ',
    'benchmarks.mmlu.note': 'Âú®ËØ•ÂÖ≥ÈîÆÁü•ËØÜ‰∏éÊé®ÁêÜÂü∫ÂáÜ‰∏äË∂ÖË∂äÂêåÁ∫ß‰∏ªÊµÅÊ®°Âûã',
    'benchmarks.lmarena.title': 'LMArena ÂæóÂàÜ',
    'benchmarks.lmarena.desc': '‰∫∫Á±ªÂÅèÂ•ΩÂØπËØùÂü∫ÂáÜ',
    'benchmarks.lmarena.max': 'ÊúÄÂ§ßÂàÜÊï∞Âç†ÊØî',
    'benchmarks.lmarena.note': 'È¶ñ‰∏™Á™ÅÁ†¥1300ÂàÜÁöÑ10B‰ª•‰∏ãÊ®°ÂûãÔºåÂ±ïÁé∞Âº∫Â§ßÂØπËØùËÉΩÂäõ',
    'benchmarks.vision.title': 'ËßÜËßâÁºñÁ†ÅÈÄüÂ∫¶',
    'benchmarks.vision.desc': 'ËÆæÂ§áÁ´ØËßÜËßâÊé®ÁêÜÊÄßËÉΩÔºàPixel Edge TPUÔºâ',
    'benchmarks.vision.faster': 'Âä†ÈÄü',
    'benchmarks.vision.compare': 'MobileNet-V5 vs SoViT',
    'benchmarks.vision.note': 'ËßÜËßâÂ§ÑÁêÜÈÄüÂ∫¶Â§ßÂπÖÊèêÂçáÔºåÁ≤æÂ∫¶Êõ¥È´òÔºåÂÜÖÂ≠òÂç†Áî®Êõ¥‰Ωé',
    'benchmarks.table.title': 'Gemma 3n ‰∏éÁ´ûÂìÅÂØπÊØî',
    'benchmarks.table.model': 'Ê®°Âûã',
    'benchmarks.table.params': 'ÂèÇÊï∞Èáè',
    'benchmarks.table.mmlu': 'MMLU',
    'benchmarks.table.gsm8k': 'GSM8K',
    'benchmarks.table.humaneval': 'HumanEval',
    'benchmarks.table.memory': 'ÂÜÖÂ≠ò(GB)',
    'benchmarks.gemma_e4b': 'Gemma 3n E4B',
    'benchmarks.gemma_e2b': 'Gemma 3n E2B',
    'benchmarks.llama_3_8b': 'Llama 3.1 8B',
    'benchmarks.llama_3_3b': 'Llama 3.2 3B',
    'benchmarks.score': 'ÂàÜÊï∞',
    'benchmarks.tag.superior': 'ÊÄßËÉΩÈ¢ÜÂÖà',
    'benchmarks.tag.below': '‰Ωé‰∫é Gemma 3n E4B',
    'benchmarks.memory.note': 'ÂÜÖÂ≠òÈúÄÊ±Ç‰∏∫ÂÖ®Á≤æÂ∫¶Ê®°ÂûãÈÖçÁΩÆ„ÄÇ',
    'benchmarks.efficiency_champion_title': 'ÊïàÁéá‰πãÁéã',
    'benchmarks.efficiency_champion': 'Gemma 3n E4B ‰ªÖÁî® 4B ÂèÇÊï∞Âç≥Ëææ 79.8% MMLUÔºåÊÄßËÉΩË∂ÖË∂ä Llama 3.1 8BÔºà66.7%ÔºâÔºåÂÜÖÂ≠òÂç†Áî®‰ªÖ‰∏∫ÂÖ∂‰∏ÄÂçä„ÄÇ',
    'benchmarks.mobile_first_design_title': 'ÁßªÂä®‰ºòÂÖàËÆæËÆ°',
    'benchmarks.mobile_first_design': 'MatFormer Êû∂ÊûÑÊîØÊåÅÂä®ÊÄÅÊâ©Â±ïÔºåÂêå‰∏ÄÊ®°ÂûãÂèØÈ´òÊïàËøêË°å‰∫éÊâãÊú∫Âà∞Â∑•‰ΩúÁ´ôÁ≠âÂ§öÁßçËÆæÂ§á„ÄÇ',

    // ËµÑÊ∫êÂå∫Âùó
    'resources.heading': 'ËµÑÊ∫ê',
    'resources.subtitle': 'ÂºÄÂßã‰ΩøÁî® Gemma 3n ÁöÑÈáçË¶ÅÈìæÊé•„ÄÇ',
    'resources.category.download': '‰∏ãËΩΩÊ®°Âûã',
    'resources.category.api': 'ÂÆòÊñπAPI‰∏éÊåáÂçó',
    'resources.download.hf.title': 'Hugging Face',
    'resources.download.hf.desc': 'Ëé∑ÂèñÂÖ®ÈÉ® Gemma 3n Ê®°Âûã„ÄÅGGUF ÁâàÊú¨ÂèäÁ§æÂå∫ÂæÆË∞ÉÊ®°Âûã„ÄÇ',
    'resources.download.ollama.title': 'Ollama',
    'resources.download.ollama.desc': '‰∏ÄË°åÂëΩ‰ª§Êú¨Âú∞ÊãâÂèñÂπ∂ËøêË°å Gemma 3n Ê®°Âûã„ÄÇ',
    'resources.download.lmstudio.title': 'LM Studio',
    'resources.download.lmstudio.desc': 'Ê°åÈù¢Á´ØÂèØËßÜÂåñÂ∫îÁî®ÔºåËΩªÊùæ‰ΩìÈ™åÂíåËøêË°å Gemma 3n„ÄÇ',
    'resources.api.studio.title': 'Google AI Studio',
    'resources.api.studio.desc': 'Êó†ÈúÄÂÆâË£ÖÔºåÁõ¥Êé•Âú®ÊµèËßàÂô®‰ΩìÈ™å Gemma 3n„ÄÇ',
    'resources.api.keras.title': 'Keras',
    'resources.api.keras.desc': 'Áî® Keras È´òÊïàÊûÑÂª∫ÂíåËÆ≠ÁªÉ Gemma 3n Ê®°Âûã„ÄÇ',
    'resources.api.paper.title': 'ÊäÄÊúØÊä•Âëä',
    'resources.api.paper.desc': 'ÈòÖËØª Google ÂÆòÊñπËÆ∫ÊñáÔºåÊ∑±ÂÖ•‰∫ÜËß£ Gemma 3n Êû∂ÊûÑ„ÄÇ',

    // Demo È°µÈù¢‰∏ªÁªìÊûÑ
    'demo.page.title': 'AI Demo | Interactive Experience',
    'demo.page.description': 'Experience the power of Gemma 3n - run AI models directly in your browser, no installation required.',
    'demo.hero.title': 'Gemma 3n Interactive Experience',
    'demo.hero.subtitle': 'Experience powerful AI features directly in your browser. Code completion ‚Ä¢ Language translation ‚Ä¢ Intelligent Q&A',
    'demo.hero.feature1.title': 'Ultra-fast Response',
    'demo.hero.feature1.desc': 'Millisecond-level AI inference, real-time interaction',
    'demo.hero.feature2.title': 'Privacy First',
    'demo.hero.feature2.desc': 'All data processed locally, never uploaded to the cloud',
    'demo.hero.feature3.title': 'Multi-scenario Support',
    'demo.hero.feature3.desc': 'Coding, translation, chat ‚Äî one model for all',
    'demo.hero.cta': 'Try Now ‚Üí',
    'demo.section.title': 'Interactive AI Demo',
    'demo.section.desc': 'This is a simulated version showing how Gemma 3n works in real-world scenarios. For production, use ONNX.js or WebAssembly to run the real model.',
    'demo.info.title': 'About this Demo',
    'demo.info.current.title': 'Current Features',
    'demo.info.current.feature1': 'Simulates Gemma 3n inference process and response style',
    'demo.info.current.feature2': 'Realistic UI and interaction flow',
    'demo.info.current.feature3': 'Performance metrics based on real hardware data',
    'demo.info.current.feature4': 'Supports three core application scenarios',
    'demo.info.prod.title': 'Production Version',
    'demo.info.prod.feature1': 'Load real Gemma 3n model with ONNX.js',
    'demo.info.prod.feature2': 'Accelerated inference with WebAssembly',
    'demo.info.prod.feature3': 'Full tokenizer and post-processing pipeline',
    'demo.info.prod.feature4': 'Supports model quantization and optimization',
    'demo.tech.title': 'Technical Implementation Path',
    'demo.tech.desc': 'Upgrade the demo to a full-fledged AI application tech stack',
    'demo.tech.frontend.title': 'Frontend Architecture',
    'demo.tech.frontend.engine': 'Lightweight Inference Engine',
    'demo.tech.frontend.engine.code': "// ONNX.js integration\nimport * as ort from 'onnxruntime-web';\n\n// Load model\nconst session = await ort.InferenceSession\n  .create('/models/gemma-3n-e2b.onnx');\n\n// Inference\nconst results = await session.run(feeds);",
    'demo.tech.frontend.wasm': 'WebAssembly Optimization',
    'demo.tech.frontend.wasm.code': "// WebAssembly tokenizer\nimport init, { tokenize } from './pkg/tokenizer.js';\n\n// Initialize WASM module\nawait init();\n\n// High-performance tokenization\nconst tokens = tokenize(inputText);",
    'demo.tech.deploy.title': 'Model Deployment',
    'demo.tech.deploy.convert': 'Model Conversion',
    'demo.tech.deploy.convert1': 'Hugging Face ‚Üí ONNX',
    'demo.tech.deploy.convert2': 'Dynamic quantization (INT8)',
    'demo.tech.deploy.convert3': 'Graph optimization and constant folding',
    'demo.tech.deploy.convert4': 'WebGL backend adaptation',
    'demo.tech.deploy.cdn': 'CDN Distribution',
    'demo.tech.deploy.cdn1': 'Global acceleration with Cloudflare',
    'demo.tech.deploy.cdn2': 'Chunked download strategy',
    'demo.tech.deploy.cdn3': 'Browser cache optimization',
    'demo.tech.deploy.cdn4': 'Progressive loading',
    'demo.tech.deploy.optimize': 'Performance Optimization',
    'demo.tech.deploy.optimize1': 'Web Workers multithreading',
    'demo.tech.deploy.optimize2': 'SharedArrayBuffer',
    'demo.tech.deploy.optimize3': 'WebGPU acceleration (future)',
    'demo.tech.deploy.optimize4': 'Memory pool management',
    'demo.tech.cost.title': 'Zero-cost Solution Advantages',
    'demo.tech.cost.cloud': 'Traditional Cloud AI Cost',
    'demo.tech.cost.cloud1': 'üî¥ OpenAI API: $0.002/1K tokens',
    'demo.tech.cost.cloud2': 'üî¥ Azure OpenAI: $0.0015/1K tokens',
    'demo.tech.cost.cloud3': 'üî¥ Google Cloud AI: $0.001/1K tokens',
    'demo.tech.cost.cloud4': 'üî¥ Monthly: $200-2000 (medium traffic)',
    'demo.tech.cost.device': 'Gemma 3n On-device Solution',
    'demo.tech.cost.device1': '‚úÖ Inference cost: $0',
    'demo.tech.cost.device2': '‚úÖ CDN: $0 (Cloudflare free tier)',
    'demo.tech.cost.device3': '‚úÖ Storage: $0 (static hosting)',
    'demo.tech.cost.device4': '‚úÖ Monthly: $0 + $12/year domain',
    'demo.cta.title': 'Ready to build your AI app?',
    'demo.cta.desc': 'Start with tutorials and master the power of Gemma 3n step by step.',
    'demo.cta.learn': 'Start Learning',
    'demo.cta.toolkit': 'Toolkit',
    'demo.cta.download': 'Download Model',

    // FAQÂå∫Âùó
    'faq.heading': 'Â∏∏ËßÅÈóÆÈ¢ò',
    'faq.subtitle': 'ÊúâÁñëÈóÆÔºüÊàë‰ª¨Êù•Ëß£Á≠î„ÄÇ‰ª•‰∏ãÊòØÂºÄÂèëËÄÖÊúÄÂ∏∏ÈóÆÁöÑ‰∏Ä‰∫õÈóÆÈ¢ò„ÄÇ',
    'faq.q1': 'Gemma 3n ÂèØ‰ª•ÂÖçË¥πÂïÜÁî®ÂêóÔºü',
    'faq.a1': 'ÂèØ‰ª•„ÄÇGemma 3n Ê®°ÂûãÈááÁî®ÂÆΩÊùæËÆ∏ÂèØÂçèËÆÆÔºåÂÖÅËÆ∏ÂÖçË¥πÂïÜÁî®ÂíåÁßëÁ†î‰ΩøÁî®„ÄÇËØ∑Âä°ÂøÖÊü•ÈòÖÂÆòÊñπËÆ∏ÂèØÊù°Ê¨æ„ÄÇ',
    'faq.q2': 'Gemma 3n ÁöÑ"Â§öÊ®°ÊÄÅ"ÂÖ∑‰ΩìÊåá‰ªÄ‰πàÔºü',
    'faq.a2': 'Â§öÊ®°ÊÄÅÊÑèÂë≥ÁùÄÊ®°Âûã‰∏ç‰ªÖËÉΩÁêÜËß£ÊñáÊú¨ÔºåËøòËÉΩÂàÜÊûêÂõæÁâáÂíåÈü≥È¢ëÔºåÈÄÇÁî®‰∫éÊèèËø∞ÁÖßÁâá„ÄÅËØ≠Èü≥ËΩ¨ÂΩïÁ≠âÂ§öÂú∫ÊôØ„ÄÇ',
    'faq.q3': 'Gemma 3n Âíå Gemma 2 Êúâ‰ªÄ‰πàÂå∫Âà´Ôºü',
    'faq.a3': 'Gemma 3n ÈíàÂØπËÆæÂ§áÁ´Ø‰ºòÂåñÔºåÈááÁî® MatFormer Êû∂ÊûÑÔºåÂÜÖÂ≠òÂíåÁÆóÂäõÊïàÁéáÊõ¥È´òÔºåÈùûÂ∏∏ÈÄÇÂêàÊâãÊú∫„ÄÅÁ¨îËÆ∞Êú¨Á≠âÊú¨Âú∞ÈÉ®ÁΩ≤„ÄÇ',
    'faq.q4': 'ÂèØ‰ª•Áî®Ëá™Â∑±ÁöÑÊï∞ÊçÆÂæÆË∞É Gemma 3n ÂêóÔºü',
    'faq.a4': 'ÂΩìÁÑ∂ÂèØ‰ª•„ÄÇGoogle Êèê‰æõ‰∫Ü Keras„ÄÅPyTorch„ÄÅJAX Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂæÆË∞ÉÊñπÊ°àÂíåÂ∑•ÂÖ∑„ÄÇ',
    'faq.q5': 'Â¶Ç‰ΩïÁî® Ollama ËøêË°å Gemma 3nÔºü',
    'faq.a5': 'ÂÆâË£Ö Ollama ÂêéÔºåËøêË°å "ollama run gemma-3n:e4b" Êàñ "ollama run gemma-3n:e2b" Âç≥ÂèØËá™Âä®‰∏ãËΩΩÂπ∂ËøêË°åÂØπÂ∫îÊ®°Âûã„ÄÇ',
    'faq.q6': 'E2B Âíå E4B Êúâ‰ªÄ‰πàÂå∫Âà´Ôºü',
    'faq.a6': 'E2BÔºà2BÂèÇÊï∞ÔºâÊõ¥Â∞èÊõ¥Âø´ÔºåÈÄÇÂêàÁßªÂä®Á´ØÂíåÂø´ÈÄüÊé®ÁêÜÔºõE4BÔºà4BÂèÇÊï∞ÔºâÁ≤æÂ∫¶Êõ¥È´ò‰ΩÜËµÑÊ∫êÈúÄÊ±ÇÊõ¥Â§ß„ÄÇ‰∏§ËÄÖÂùáÈááÁî® MatFormer Êû∂ÊûÑ„ÄÇ',
    'faq.q7': 'ÂèØ‰ª•Âú® Hugging Face ‰∏äÁî® Gemma 3n ÂêóÔºü',
    'faq.a7': 'ÂèØ‰ª•ÔºåÊâÄÊúâ Gemma 3n Ê®°ÂûãÂùáÂ∑≤‰∏äÊû∂ Hugging Face HubÔºåÊîØÊåÅ transformers Â∫ìÁõ¥Êé•Ë∞ÉÁî®„ÄÇ',
    'faq.q8': 'Gemma 3n ÊØî Llama 3 Êõ¥ÈÄÇÂêàÊú¨Âú∞ÈÉ®ÁΩ≤ÂêóÔºü',
    'faq.a8': 'Gemma 3n E4B Âú®Â§öÈ°πÂü∫ÂáÜÊµãËØï‰∏≠‰ºò‰∫é Llama 3 8BÔºå‰∏î‰ΩìÁßØÊõ¥Â∞è„ÄÅÊé®ÁêÜÊõ¥Âø´ÔºåÈùûÂ∏∏ÈÄÇÂêàÊú¨Âú∞ÂíåÈöêÁßÅÂú∫ÊôØ„ÄÇ',
    'faq.q9': 'Gemma 3n ËÉΩÂú® iOS ËÆæÂ§á‰∏äËøêË°åÂêóÔºü',
    'faq.a9': 'ÂèØ‰ª•ÔºåE2B ÁâàÊú¨ÁâπÂà´ÈÄÇÂêàÁßªÂä®Á´Ø„ÄÇÂèØÁî® CoreML ÊàñÈáèÂåñÊ®°ÂûãÂú®ËãπÊûúËÆæÂ§áÈ´òÊïàËøêË°å„ÄÇ',
    'faq.q10': 'Gemma 3n ÂØπÁ°¨‰ª∂Êúâ‰ΩïË¶ÅÊ±ÇÔºü',
    'faq.a10': 'E2B Âè™ÈúÄ 4GB ÂÜÖÂ≠òÂç≥ÂèØËøêË°åÔºåE4B Êé®Ëçê 8GB ‰ª•‰∏ä„ÄÇCPU ‰πüÂèØËøêË°åÔºåËã•Êúâ GPU Êé®ÁêÜÈÄüÂ∫¶Êõ¥Âø´„ÄÇ',

    // newsletter
    'newsletter.heading': 'Ëé∑ÂèñÊúÄÊñ∞ËµÑËÆØ',
    'newsletter.desc': 'ËÆ¢ÈòÖÂêéÂèØÁ¨¨‰∏ÄÊó∂Èó¥Ëé∑Âèñ Gemma 3n ÁöÑÊúÄÊñ∞ÊïôÁ®ã‰∏éÊñ∞Èóª„ÄÇÁªùÊó†ÂûÉÂúæÈÇÆ‰ª∂„ÄÇ',
    'newsletter.placeholder': 'ËØ∑ËæìÂÖ•ÊÇ®ÁöÑÈÇÆÁÆ±',
    'newsletter.subscribe': 'ËÆ¢ÈòÖ',

    // È°µËÑö
    'footer.independent': '‰∏Ä‰∏™Áî±Á§æÂå∫È©±Âä®ÁöÑ„ÄÅÁã¨Á´ãÁöÑGemma 3nÂºÄÂèëËÄÖÊåáÂçó„ÄÇ',
    'footer.rights': 'ÁâàÊùÉÊâÄÊúâ„ÄÇ',
    'footer.stay_updated': '‰øùÊåÅÊõ¥Êñ∞',
    'footer.subscribe_desc': 'ËÆ¢ÈòÖÊàë‰ª¨ÁöÑÊñ∞ÈóªÈÄöËÆØÔºåËé∑ÂèñÊúÄÊñ∞ÁöÑGemma 3nÊñ∞Èóª„ÄÅÊïôÁ®ãÂíåÂü∫ÂáÜÊµãËØï„ÄÇ',
    'footer.subscribe_button': 'ËÆ¢ÈòÖ',
    'footer.privacy': 'ÈöêÁßÅÊîøÁ≠ñ',
    'footer.terms': 'ÊúçÂä°Êù°Ê¨æ',

    // ÂçöÂÆ¢
    'blog.title': 'Gemma 3n ÂºÄÂèëËÄÖÂçöÂÆ¢',
    'blog.description': 'ÂÖ≥‰∫éGemma 3n AIÊ®°ÂûãÁöÑÊñ∞Èóª„ÄÅÊïôÁ®ãÂíåÊ∑±Â∫¶ÊñáÁ´†„ÄÇ',
    'blog.read_more': 'ÈòÖËØªÊõ¥Â§ö',
    'blog.giscus.comments': 'ËØÑËÆ∫',
    'blog.table_of_contents': 'ÁõÆÂΩï',
    'blog.last_updated': 'ÊúÄÂêéÊõ¥Êñ∞‰∫é',
    'blog.share': 'ÂàÜ‰∫´ËøôÁØáÊñáÁ´†',
    'blog.share.twitter': 'ÂàÜ‰∫´Âà∞Êé®Áâπ',
    'blog.share.linkedin': 'ÂàÜ‰∫´Âà∞È¢ÜËã±',
    'blog.share.facebook': 'ÂàÜ‰∫´Âà∞ËÑ∏‰π¶',
    'blog.share.copy': 'Â§çÂà∂ÈìæÊé•',
    'blog.share.copied': 'Â∑≤Â§çÂà∂ÔºÅ',

    // ÂØπÊØîÈ°µÈù¢
    'compare.title': "Gemma 3n vs. Llama 3: ÁªàÊûÅÂØπÂÜ≥",
    'compare.description': "Ê∑±Â∫¶Êï∞ÊçÆÈ©±Âä®ÂØπÊØî Google Gemma 3n ‰∏é Meta Llama 3„ÄÇÊàë‰ª¨ÂàÜÊûêÂü∫ÂáÜÊµãËØï„ÄÅÁ°¨‰ª∂ÈúÄÊ±ÇÂíå‰ΩøÁî®Âú∫ÊôØÔºåÂä©‰Ω†ÈÄâÊã©ÊúÄÈÄÇÂêà‰Ω†È°πÁõÆÁöÑÊ®°Âûã„ÄÇ",
    'compare.h1': "Gemma 3n <span class='text-blue-600'>ÂØπÂÜ≥</span> Llama 3",
    'compare.subheading': "ÊïàÁéá‰∏éÊÄßËÉΩÁöÑÁ¢∞Êíû„ÄÇÊàë‰ª¨Ê∑±ÂÖ•ÂâñÊûê‰∏§Â§ßÈ¢ÜÂÖàÂºÄÊ∫êÊ®°ÂûãÔºåÂä©‰Ω†Ê†πÊçÆÂÖ∑‰ΩìÈúÄÊ±ÇÂÅöÂá∫ÊúÄÁªàÂÜ≥Á≠ñ„ÄÇ",
    'compare.showdown_badge': "Ê®°ÂûãÂØπÂÜ≥",
    'compare.glance.title': "ÈÄüËßàÔºöÊ†∏ÂøÉÂ∑ÆÂºÇ",
    'compare.glance.feature': "ÁâπÊÄß",
    'compare.glance.gemma': "Gemma 3n (E4B)",
    'compare.glance.llama': "Llama 3 (8B)",
    'compare.glance.architecture': "Êû∂ÊûÑ",
    'compare.glance.architecture.gemma': "MatFormer (Âä®ÊÄÅÁº©Êîæ)",
    'compare.glance.architecture.llama': "Ê†áÂáÜ Transformer",
    'compare.glance.params': "ÊúâÊïàÂèÇÊï∞",
    'compare.glance.params.gemma': "~40‰∫ø",
    'compare.glance.params.llama': "80‰∫ø",
    'compare.glance.strength': "Ê†∏ÂøÉ‰ºòÂäø",
    'compare.glance.strength.gemma': "Á´Ø‰æßÊÄßËÉΩ, È´òÊïàÁéá",
    'compare.glance.strength.llama': "ÂéüÂßãÊé®ÁêÜ & ÁºñÁ®ãËÉΩÂäõ",
    'compare.glance.hardware': "Á°¨‰ª∂ÈúÄÊ±Ç",
    'compare.glance.hardware.gemma': "<span class='font-semibold text-green-600 dark:text-green-400'>‰Ωé</span> (Áé∞‰ª£Á¨îËÆ∞Êú¨)",
    'compare.glance.hardware.llama': "<span class='font-semibold text-orange-500'>‰∏≠</span> (ÈúÄË¶ÅËâØÂ•ΩGPU)",
    'compare.glance.multimodality': "Â§öÊ®°ÊÄÅËÉΩÂäõ",
    'compare.glance.multimodality.gemma': "ÂéüÁîüÊîØÊåÅÊñáÊú¨„ÄÅÈü≥È¢ë„ÄÅÂõæÂÉè",
    'compare.glance.multimodality.llama': "‰ªÖÊñáÊú¨",
    'compare.benchmarks.title': "ÊÄßËÉΩÂü∫ÂáÜÊµãËØï",
    'compare.benchmarks.note': "*Âü∫ÂáÜÂàÜÊï∞ÊòØÂü∫‰∫éÂÖ¨ÂºÄËÅöÂêàÊï∞ÊçÆÁöÑËØ¥ÊòéÊÄßÂ±ïÁ§∫„ÄÇ",
    'compare.deepdive.title': "Ê∑±Â∫¶ÂàÜÊûê",
    'compare.deepdive.gemma.title': "üèÜ Gemma 3n ÁöÑËÉúÂá∫‰πãÂ§Ñ",
    'compare.deepdive.gemma.1.title': "ÊïàÁéá‰∏éÂèØÂèäÊÄß",
    'compare.deepdive.gemma.1.desc': "Âú®Ê∂àË¥πÁ∫ßÁ°¨‰ª∂ÔºàÁ¨îËÆ∞Êú¨„ÄÅÊâãÊú∫Ôºâ‰∏äÊµÅÁïÖËøêË°åÔºåRAMÂç†Áî®ÊòæËëóÂáèÂ∞ëÔºåÊòØÁ´Ø‰æßÂ∫îÁî®ÁöÑÂÆåÁæéÈÄâÊã©„ÄÇ",
    'compare.deepdive.gemma.2.title': "ÂéüÁîüÂ§öÊ®°ÊÄÅ",
    'compare.deepdive.gemma.2.desc': "‰ªéÂ∫ïÂ±ÇËÆæËÆ°Â∞±ÊîØÊåÅÂú®Âçï‰∏ÄÊ®°Âûã‰∏≠ÁêÜËß£ÊñáÊú¨„ÄÅÈü≥È¢ëÂíåÂõæÂÉèÔºåËß£ÈîÅ‰∫ÜLlamaÊó†Ê≥ïÂçïÁã¨Â§ÑÁêÜÁöÑÊñ∞ÂûãÂ∫îÁî®„ÄÇ",
    'compare.deepdive.gemma.3.title': "Âä®ÊÄÅÊû∂ÊûÑ",
    'compare.deepdive.gemma.3.desc': "MatFormerÊû∂ÊûÑ‰ΩøÂÖ∂ËÉΩÂä®ÊÄÅË∞ÉÊï¥ËÆ°ÁÆóÈáèÔºåÊó†ÈúÄÂ∑®Â§ßÁöÑÈùôÊÄÅÂèÇÊï∞Âç≥ÂèØÊèê‰æõÂùáË°°ÁöÑÊÄßËÉΩ„ÄÇ",
    'compare.deepdive.llama.title': "üèÜ Llama 3 ÁöÑËÉúÂá∫‰πãÂ§Ñ",
    'compare.deepdive.llama.1.title': "ÂéüÂßãÊé®ÁêÜ‰∏éÁºñÁ®ãËÉΩÂäõ",
    'compare.deepdive.llama.1.desc': "Âá≠ÂÄüÊõ¥Â§ö‰∏ìÁî®ÂèÇÊï∞ÔºåLlama 3Âú®Â§çÊùÇÈÄªËæëÊé®ÁêÜ„ÄÅÊï∞Â≠¶ÈóÆÈ¢òÂíå‰ª£Á†ÅÁîüÊàêÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤ÔºåÁ∫ØÊñáÊú¨Âü∫ÂáÜÊµãËØïÈÄöÂ∏∏‰ºò‰∫éGemma„ÄÇ",
    'compare.deepdive.llama.2.title': "ÊàêÁÜüÁöÑÂæÆË∞ÉÁîüÊÄÅ",
    'compare.deepdive.llama.2.desc': "‰Ωú‰∏∫‰∏Ä‰∏™Êõ¥ÊàêÁÜüÁöÑÊû∂ÊûÑÔºåÁ§æÂå∫‰∏∫Llama 3Ë¥°ÁåÆ‰∫ÜÂ§ßÈáèÈíàÂØπÁâπÂÆö‰ªªÂä°ÁöÑÂæÆË∞ÉÁâàÊú¨„ÄÇ",
    'compare.deepdive.llama.3.title': "ÂèØÈ¢ÑÊµãÁöÑÊÄßËÉΩ",
    'compare.deepdive.llama.3.desc': "ÂÖ∂Ê†áÂáÜTransformerÊû∂ÊûÑÊÑèÂë≥ÁùÄÊÄßËÉΩÈùûÂ∏∏ÂèØÈ¢ÑÊµãÔºåÂπ∂‰∏îËÉΩÈöèÊõ¥Âº∫Â§ßÁöÑÁ°¨‰ª∂ÂæàÂ•ΩÂú∞Êâ©Â±ï„ÄÇ",
    'compare.verdict.title': "ÊúÄÁªàË£ÅÂÜ≥ÔºöÂì™Ê¨æÈÄÇÂêà‰Ω†Ôºü",
    'compare.verdict.subtitle': "‰Ω†ÁöÑÈÄâÊã©ÂÆåÂÖ®ÂèñÂÜ≥‰∫éÈ°πÁõÆÁöÑÊ†∏ÂøÉÁõÆÊ†á„ÄÇ",
    'compare.verdict.gemma.title': "ÈÄâÊã© Gemma 3n Â¶ÇÊûú...",
    'compare.verdict.gemma.bullet1': "‰Ω†Ê≠£Âú®‰∏∫**ÁßªÂä®ÊàñËæπÁºòËÆæÂ§á**ÊûÑÂª∫Â∫îÁî®„ÄÇ",
    'compare.verdict.gemma.bullet2': "‰Ω†ÁöÑÂ∫îÁî®ÈúÄË¶Å**Â§öÊ®°ÊÄÅËÉΩÂäõ**ÔºàÈü≥È¢ë/ËßÜËßâÔºâ„ÄÇ",
    'compare.verdict.gemma.bullet3': "**ËµÑÊ∫êÊïàÁéá**Âíå‰ΩéRAMÂç†Áî®Ëá≥ÂÖ≥ÈáçË¶Å„ÄÇ",
    'compare.verdict.gemma.bullet4': "‰Ω†ÈúÄË¶Å‰∏Ä‰∏™Áî®‰∫éÈÄöÁî®‰ªªÂä°ÁöÑ„ÄÅÂùáË°°ÁöÑÂÖ®Èù¢Ê®°Âûã„ÄÇ",
    'compare.verdict.llama.title': "ÈÄâÊã© Llama 3 Â¶ÇÊûú...",
    'compare.verdict.llama.bullet1': "‰Ω†ÁöÑ‰∏ªË¶ÅÁî®‰æãÊòØ**Â§çÊùÇÁöÑÁºñÁ®ãÊàñÊé®ÁêÜ**„ÄÇ",
    'compare.verdict.llama.bullet2': "‰Ω†Êã•Êúâ**Âº∫Â§ßÁöÑGPU**„ÄÇ",
    'compare.verdict.llama.bullet3': "‰Ω†ÈúÄË¶ÅÂú®**Á∫ØÊñáÊú¨‰ªªÂä°**‰∏äËé∑ÂæóÁªùÂØπÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇ",
    'compare.verdict.llama.bullet4': "‰Ω†ÊÉ≥Âà©Áî®Â∫ûÂ§ßÁöÑÁ§æÂå∫ÂæÆË∞ÉÊ®°ÂûãÂ∫ì„ÄÇ",
    'compare.cta.title': "ÂáÜÂ§áÂ•ΩÊ∑±ÂÖ•Êé¢Á¥¢‰∫ÜÂêóÔºü",
    'compare.cta.subtitle': "ÊµèËßàÊàë‰ª¨ÁöÑÂÆûÊàòÊïôÁ®ãÔºåÊéåÊè°Ëøô‰∏§Ê¨æÊ®°Âûã„ÄÇ",
    'compare.cta.button1': "ÊµèËßàÂÖ®ÈÉ®ÊïôÁ®ã",
    'compare.cta.button2': "Ëé∑ÂèñÂ∑•ÂÖ∑ÁÆ±",

    // Leaderboard Page
    'leaderboard.title': "AIÊ®°ÂûãÊéíË°åÊ¶úÔºöÊúÄ‰Ω≥ÂºÄÊ∫êÊ®°ÂûãÂØπÊØî",
    'leaderboard.description': "‰∏Ä‰∏™Êï∞ÊçÆÈ©±Âä®„ÄÅÂèØÊéíÂ∫èÁöÑÊéíË°åÊ¶úÔºåÊØîËæÉGemma 3n„ÄÅLlama 3„ÄÅPhi-3ÂíåQwen 2Á≠âÈ°∂Á∫ßÂºÄÊ∫êAIÊ®°Âûã„ÄÇÂèØÊåâMMLU„ÄÅGSM8KÂíåHumanEvalÁ≠âÂü∫ÂáÜËøõË°åÁ≠õÈÄâ„ÄÇ",
    'leaderboard.h1': "ÂºÄÊ∫êÊ®°ÂûãÊéíË°åÊ¶ú",
    'leaderboard.subheading': "ÂΩì‰ªäÈ°∂Á∫ßÂºÄÊ∫êAIÊ®°ÂûãÁöÑÊùÉÂ®ÅÊï∞ÊçÆÈ©±Âä®ÊéíÂêç„ÄÇÊéíÂ∫è„ÄÅÊØîËæÉÔºåÊâæÂà∞ÊúÄÈÄÇÂêàÊÇ®ÈúÄÊ±ÇÁöÑÊ®°Âûã„ÄÇ",
    'leaderboard.badge': "Á§æÂå∫Âü∫ÂáÜÊµãËØï",
    'leaderboard.table.rank': "ÊéíÂêç",
    'leaderboard.table.model': "Ê®°Âûã",
    'leaderboard.table.params': "ÂèÇÊï∞Èáè (B)",
    'leaderboard.table.mmlu': "MMLU",
    'leaderboard.table.gsm8k': "GSM8K",
    'leaderboard.table.humaneval': "HumanEval",
    'leaderboard.table.tags': "Ê†áÁ≠æ",
    'leaderboard.notes.definitions': "* MMLU: Massive Multitask Language Understanding. GSM8K: Grade School Math. HumanEval: Code Generation.",
    'leaderboard.notes.disclaimer': "* ÊÄßËÉΩÊï∞ÊçÆÂü∫‰∫éÂÖ¨ÂºÄ‰ø°ÊÅØÔºåÂèØËÉΩÂõ†ÈáèÂåñÂíåÂÆûÁé∞ÊñπÂºèËÄåÂºÇ„ÄÇ",
    'leaderboard.tags.reasoning': "Êé®ÁêÜËÉΩÂäõÂº∫",
    'leaderboard.tags.efficiency': "ÊïàÁéá‰πãÁéã",
    'leaderboard.tags.multimodal': "Â§öÊ®°ÊÄÅ",
    'leaderboard.tags.coder': "ÁºñÁ®ãÈ´òÊâã",
    'leaderboard.tags.on_device': "Á´Ø‰æßËÆæÂ§á",
    'leaderboard.tags.fast': "ÈÄüÂ∫¶Âø´",

    // ÈöêÁßÅ‰∏éÊù°Ê¨æ
    'privacy.title': "ÈöêÁßÅÊîøÁ≠ñ",
    'privacy.h1': "Gemma-3n.net ÈöêÁßÅÊîøÁ≠ñ",
    'privacy.effective_date': "ÁîüÊïàÊó•ÊúüÔºö2025Âπ¥7Êúà1Êó•",
    'privacy.p1': "Ê¨¢ËøéËÆøÈóÆ Gemma-3n.net„ÄÇÊàë‰ª¨Ëá¥Âäõ‰∫é‰øùÊä§ÊÇ®ÁöÑÈöêÁßÅ„ÄÇÊú¨ÈöêÁßÅÊîøÁ≠ñËß£Èáä‰∫ÜÂΩìÊÇ®ËÆøÈóÆÊàë‰ª¨ÁöÑÁΩëÁ´ôÊó∂ÔºåÊàë‰ª¨Â¶Ç‰ΩïÊî∂ÈõÜ„ÄÅ‰ΩøÁî®„ÄÅÊä´Èú≤Âíå‰øùÊä§ÊÇ®ÁöÑ‰ø°ÊÅØ„ÄÇËØ∑‰ªîÁªÜÈòÖËØªÊú¨ÈöêÁßÅÊîøÁ≠ñ„ÄÇÂ¶ÇÊûúÊÇ®‰∏çÂêåÊÑèÊú¨ÈöêÁßÅÊîøÁ≠ñÁöÑÊù°Ê¨æÔºåËØ∑‰∏çË¶ÅËÆøÈóÆÊú¨ÁΩëÁ´ô„ÄÇ",
    'privacy.h2_info': "ÊÇ®ÁöÑ‰ø°ÊÅØÊî∂ÈõÜ",
    'privacy.p2': "Êàë‰ª¨ÂèØËÉΩ‰ª•Â§öÁßçÊñπÂºèÊî∂ÈõÜÊúâÂÖ≥ÊÇ®ÁöÑ‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÂèØËÉΩÂú®ÁΩëÁ´ô‰∏äÊî∂ÈõÜÁöÑ‰ø°ÊÅØÂåÖÊã¨Ôºö",
    'privacy.h3_personal': "‰∏™‰∫∫Êï∞ÊçÆ",
    'privacy.p3': "ÊÇ®Âú®ËÆ¢ÈòÖÊàë‰ª¨ÁöÑÊñ∞ÈóªÈÄöËÆØÊó∂Ëá™ÊÑøÊèê‰æõÁªôÊàë‰ª¨ÁöÑ‰∏™‰∫∫Ë∫´‰ªΩ‰ø°ÊÅØÔºå‰æãÂ¶ÇÊÇ®ÁöÑÁîµÂ≠êÈÇÆ‰ª∂Âú∞ÂùÄ„ÄÇ",
    'privacy.h3_analytics': "Ë°çÁîüÊï∞ÊçÆ",
    'privacy.p4': "ÂΩìÊÇ®ËÆøÈóÆÊú¨ÁΩëÁ´ôÊó∂ÔºåÊàë‰ª¨ÁöÑÊúçÂä°Âô®‰ºöËá™Âä®Êî∂ÈõÜÁöÑ‰ø°ÊÅØÔºå‰æãÂ¶ÇÊÇ®ÁöÑIPÂú∞ÂùÄ„ÄÅÊµèËßàÂô®Á±ªÂûã„ÄÅÊìç‰ΩúÁ≥ªÁªü„ÄÅËÆøÈóÆÊó∂Èó¥‰ª•ÂèäÊÇ®Âú®ËÆøÈóÆÊú¨ÁΩëÁ´ôÂâçÂêéÁõ¥Êé•Êü•ÁúãÁöÑÈ°µÈù¢„ÄÇÊàë‰ª¨‰ΩøÁî®Ê≥®ÈáçÈöêÁßÅÁöÑÂàÜÊûêÊúçÂä°Ôºå‰∏ç‰ΩøÁî®Ë∞∑Ê≠åÂàÜÊûê„ÄÇ",
    'privacy.h2_use': "ÊÇ®ÁöÑ‰ø°ÊÅØ‰ΩøÁî®",
    'privacy.p5': "Êã•ÊúâÂÖ≥‰∫éÊÇ®ÁöÑÂáÜÁ°Æ‰ø°ÊÅØ‰ΩøÊàë‰ª¨ËÉΩÂ§ü‰∏∫ÊÇ®Êèê‰æõÊµÅÁïÖ„ÄÅÈ´òÊïàÂíåÂÆöÂà∂ÂåñÁöÑ‰ΩìÈ™å„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÊàë‰ª¨ÂèØËÉΩ‰ΩøÁî®ÈÄöËøáÊú¨ÁΩëÁ´ôÊî∂ÈõÜÁöÑÂÖ≥‰∫éÊÇ®ÁöÑ‰ø°ÊÅØÊù•ÔºöÂ∞±ÊÇ®ÁöÑÂ∏êÊà∑ÊàñËÆ¢ÂçïÂêëÊÇ®ÂèëÈÄÅÁîµÂ≠êÈÇÆ‰ª∂ÔºåÂõûÂ§çÂÆ¢Êà∑ÊúçÂä°ËØ∑Ê±ÇÔºå‰ª•ÂèäÂêëÊÇ®ÂèëÈÄÅÊñ∞ÈóªÈÄöËÆØ„ÄÇ",
    'privacy.h2_security': "ÊÇ®ÁöÑ‰ø°ÊÅØÂÆâÂÖ®",
    'privacy.p6': "Êàë‰ª¨‰ΩøÁî®Ë°åÊîø„ÄÅÊäÄÊúØÂíåÁâ©ÁêÜÂÆâÂÖ®Êé™ÊñΩÊù•Â∏ÆÂä©‰øùÊä§ÊÇ®ÁöÑ‰∏™‰∫∫‰ø°ÊÅØ„ÄÇËôΩÁÑ∂Êàë‰ª¨Â∑≤ÈááÂèñÂêàÁêÜÊé™ÊñΩÊù•‰øùÊä§ÊÇ®Êèê‰æõÁªôÊàë‰ª¨ÁöÑ‰∏™‰∫∫‰ø°ÊÅØÔºå‰ΩÜËØ∑Ê≥®ÊÑèÔºåÂ∞ΩÁÆ°Êàë‰ª¨ÂÅöÂá∫‰∫ÜÂä™ÂäõÔºå‰ΩÜÊ≤°Êúâ‰ªª‰ΩïÂÆâÂÖ®Êé™ÊñΩÊòØÂÆåÁæéÊàñ‰∏çÂèØÈÄæË∂äÁöÑÔºå‰πüÊ≤°Êúâ‰ªª‰ΩïÊï∞ÊçÆ‰º†ËæìÊñπÊ≥ïÂèØ‰ª•‰øùËØÅ‰∏ç‰ºöË¢´Êã¶Êà™ÊàñÈÅ≠Âà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑÊª•Áî®„ÄÇ",
    'privacy.h2_contact': "ËÅîÁ≥ªÊàë‰ª¨",
    'privacy.p7': "Â¶ÇÊûúÊÇ®ÂØπÊú¨ÈöêÁßÅÊîøÁ≠ñÊúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÊÑèËßÅÔºåËØ∑ÈÄöËøá‰ª•‰∏ãÊñπÂºè‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºölegal@gemma-3n.net",

    'terms.title': "ÊúçÂä°Êù°Ê¨æ",
    'terms.h1': "Gemma-3n.net ÊúçÂä°Êù°Ê¨æ",
    'terms.effective_date': "ÁîüÊïàÊó•ÊúüÔºö2025Âπ¥7Êúà1Êó•",
    'terms.p1': "‰ΩøÁî®‰Ωç‰∫é Gemma-3n.net ÁöÑÁΩëÁ´ôÔºà‚ÄúÊú¨ÁΩëÁ´ô‚ÄùÔºâÔºåÂç≥Ë°®Á§∫ÊÇ®ÂêåÊÑèÂèóÊú¨ÊúçÂä°Êù°Ê¨æÔºà‚ÄúÊú¨ÂçèËÆÆ‚ÄùÔºâÁöÑÁ∫¶ÊùüÔºåÊó†ËÆ∫ÊÇ®ÊòØÂê¶Ê≥®ÂÜå‰∏∫‰ºöÂëò„ÄÇÂ¶ÇÊûúÊÇ®‰∏çÂêåÊÑèËøô‰∫õÊù°Ê¨æÔºåÂàô‰∏çÂ∫î‰ΩøÁî®Êú¨ÁΩëÁ´ô„ÄÇ",
    'terms.h2_use': "ÁΩëÁ´ô‰ΩøÁî®",
    'terms.p2': "ÊÇ®Âè™ËÉΩÂ∞ÜÊú¨ÁΩëÁ´ôÁî®‰∫é‰∏™‰∫∫ÈùûÂïÜ‰∏öÁî®ÈÄî„ÄÇÊÇ®ÂêåÊÑè‰∏ç‰∏∫‰ªª‰ΩïÈùûÊ≥ïÊàñÊú¨ÂçèËÆÆÁ¶ÅÊ≠¢ÁöÑÁõÆÁöÑ‰ΩøÁî®Êú¨ÁΩëÁ´ô„ÄÇÊÇ®‰∏çÂæó‰ª•‰ªª‰ΩïÂèØËÉΩÊçüÂùè„ÄÅÁ¶ÅÁî®„ÄÅË∂ÖËΩΩÊàñÊçüÂÆ≥Êú¨ÁΩëÁ´ôÁöÑÊñπÂºè‰ΩøÁî®Êú¨ÁΩëÁ´ô„ÄÇ",
    'terms.h2_disclaimer': "ÂÖçË¥£Â£∞Êòé",
    'terms.p3': "Êú¨ÁΩëÁ´ô‰∏äÊèê‰æõÁöÑ‰ø°ÊÅØ‰ªÖ‰æõ‰∏ÄËà¨ÂèÇËÄÉ‰πãÁî®„ÄÇÊú¨ÁΩëÁ´ô‰∏äÁöÑÊâÄÊúâ‰ø°ÊÅØÂùáÂá∫‰∫éÂñÑÊÑèÊèê‰æõÔºå‰ΩÜÊàë‰ª¨‰∏çÂØπÊú¨ÁΩëÁ´ô‰∏ä‰ªª‰Ωï‰ø°ÊÅØÁöÑÂáÜÁ°ÆÊÄß„ÄÅÂÖÖÂàÜÊÄß„ÄÅÊúâÊïàÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅÂèØÁî®ÊÄßÊàñÂÆåÊï¥ÊÄß‰ΩúÂá∫‰ªª‰ΩïÊòéÁ§∫ÊàñÊöóÁ§∫ÁöÑÈôàËø∞Êàñ‰øùËØÅ„ÄÇ",
    'terms.h2_liability': "Ë¥£‰ªªÈôêÂà∂",
    'terms.p4': "Âú®‰ªª‰ΩïÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ÊàñÊàë‰ª¨ÁöÑËë£‰∫ã„ÄÅÂëòÂ∑•Êàñ‰ª£ÁêÜ‰∫∫Âùá‰∏çÂØπÊÇ®Êàñ‰ªª‰ΩïÁ¨¨‰∏âÊñπÂõ†ÊÇ®‰ΩøÁî®Êú¨ÁΩëÁ´ôËÄåÂºïËµ∑ÁöÑ‰ªª‰ΩïÁõ¥Êé•„ÄÅÈó¥Êé•„ÄÅÂêéÊûúÊÄß„ÄÅÊÉ©ÊàíÊÄß„ÄÅÈôÑÂ∏¶ÊÄß„ÄÅÁâπÊÆäÊÄßÊàñÊÉ©ÁΩöÊÄßÊçüÂÆ≥Ë¥üË¥£ÔºåÂåÖÊã¨Âà©Ê∂¶ÊçüÂ§±„ÄÅÊî∂ÂÖ•ÊçüÂ§±„ÄÅÊï∞ÊçÆ‰∏¢Â§±ÊàñÂÖ∂‰ªñÊçüÂÆ≥ÔºåÂç≥‰ΩøÊàë‰ª¨Â∑≤Ë¢´ÂëäÁü•ÂèØËÉΩÂèëÁîüÊ≠§Á±ªÊçüÂÆ≥„ÄÇ",
    'terms.h2_governing': "ÁÆ°ËæñÊ≥ïÂæã",
    'terms.p5': "Êú¨ÂçèËÆÆÂ∫îÂèóÂä†Âà©Á¶èÂ∞º‰∫öÂ∑ûÊ≥ïÂæãÁÆ°ËæñÂπ∂Ê†πÊçÆÂÖ∂Ëß£ÈáäÔºå‰∏çËÄÉËôëÂÖ∂Ê≥ïÂæãÂÜ≤Á™ÅÂéüÂàô„ÄÇ",
    'terms.h2_contact': "ËÅîÁ≥ªÊàë‰ª¨",
    'terms.p6': "Â¶ÇÊûúÊÇ®ÂØπÊú¨ÊúçÂä°Êù°Ê¨æÊúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÊÑèËßÅÔºåËØ∑ÈÄöËøá‰ª•‰∏ãÊñπÂºè‰∏éÊàë‰ª¨ËÅîÁ≥ªÔºölegal@gemma-3n.net",
  }
} as const;

// Ëé∑ÂèñÁøªËØëÊñáÊú¨ÁöÑÂáΩÊï∞
export function useTranslations(lang: Language) {
  return function t(key: keyof typeof ui[typeof defaultLang]): string {
    return ui[lang]?.[key] || ui[defaultLang][key] || key;
  }
}

// ‰ªéURLË∑ØÂæÑËé∑ÂèñËØ≠Ë®Ä
export function getLangFromUrl(url: URL): Language {
  const [, lang] = url.pathname.split('/');
  if (lang in languages) return lang as Language;
  return defaultLang;
}

// Ëé∑ÂèñÊú¨Âú∞ÂåñË∑ØÂæÑ
export function getLocalizedPath(path: string, lang: Language): string {
  if (lang === defaultLang) {
    return path;
  }
  return `/${lang}${path}`;
}

// Ëé∑ÂèñÊõø‰ª£ËØ≠Ë®ÄË∑ØÂæÑ
export function getAlternateLanguagePaths(currentPath: string, currentLang: Language) {
  const paths: Record<Language, string> = {} as Record<Language, string>;
  
  // ÁßªÈô§ÂΩìÂâçËØ≠Ë®ÄÂâçÁºÄ
  let basePath = currentPath;
  if (currentLang !== defaultLang) {
    basePath = currentPath.replace(`/${currentLang}`, '') || '/';
  }
  
  // ‰∏∫ÊØèÁßçËØ≠Ë®ÄÁîüÊàêË∑ØÂæÑ
  Object.keys(languages).forEach(lang => {
    const language = lang as Language;
    paths[language] = getLocalizedPath(basePath, language);
  });
  
  return paths;
} 