export const faq = {
  'faq.heading': '常见问题',
  'faq.subtitle': '有问题？我们有答案。以下是开发者关于Gemma 3n最常问的问题。',
  'faq.q1': 'Gemma 3n可以免费使用吗？',
  'faq.a1': '是的，Gemma 3n模型在允许商业和研究用途免费访问的许可证下发布。请始终查看官方许可证条款了解详情。',
  'faq.q2': 'Gemma 3n的"多模态"实际上意味着什么？',
  'faq.a2': '这意味着模型可以原生理解和处理不仅仅是文本。它可以分析图像和听取音频，使其适用于更广泛的应用，如描述照片或转录语音。',
  'faq.q3': 'Gemma 3n与普通的Gemma 2或Gemma系列有什么不同？',
  'faq.a3': 'Gemma 3n专门针对设备端性能进行了优化。它使用新颖的MatFormer架构，在内存和计算方面更加高效，使其非常适合在手机和笔记本电脑上运行。',
  'faq.q4': '我可以用自己的数据微调Gemma 3n吗？',
  'faq.a4': '当然可以。这些模型设计为可微调的。Google通过Keras、PyTorch和JAX等框架提供配方和支持来促进这个过程。',
  'faq.q5': '如何使用Ollama运行Gemma 3n？',
  'faq.a5': '使用Ollama运行Gemma 3n很简单。只需安装Ollama并运行"ollama run gemma-3n:e4b"获取4B模型，或"ollama run gemma-3n:e2b"获取2B模型。模型将自动下载。',
  'faq.q6': 'Gemma 3n E2B和E4B模型之间有什么区别？',
  'faq.a6': 'E2B（2B参数）更小更快，适合移动设备和快速推理。E4B（4B参数）提供更好的性能和准确性，但需要更多计算资源。两者都使用相同的MatFormer架构。',
  'faq.q7': '我可以从Hugging Face使用Gemma 3n模型吗？',
  'faq.a7': '是的，所有Gemma 3n模型都在Hugging Face Hub上可用。您可以使用transformers库：from transformers import AutoModelForCausalLM, AutoTokenizer。提供16位和量化版本。',
  'faq.q8': '对于本地AI设置，Gemma 3n比Llama 3更好吗？',
  'faq.a8': 'Gemma 3n E4B在许多基准测试中经常超越Llama 3 8B，同时更小更高效。对于设备端应用，Gemma 3n的MatFormer架构提供更好的内存效率和更快的推理。',
  'faq.q9': '我可以在iOS设备上运行Gemma 3n吗？',
  'faq.a9': '是的，Gemma 3n模型可以在iOS设备上运行。E2B模型特别适合移动部署。您可以使用CoreML等框架或运行量化版本以获得在Apple设备上的最佳性能。',
  'faq.q10': 'Gemma 3n有什么硬件要求？',
  'faq.a10': 'Gemma 3n E2B可以在只有4GB RAM的设备上运行。E4B通常需要8GB+ RAM才能舒适运行。两个模型都可以在仅CPU设置上运行，尽管GPU加速显著提高推理速度。',
} as const; 