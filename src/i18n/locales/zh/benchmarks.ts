export const benchmarks = {
  'benchmarks.title': 'Performance Benchmarks',
  'benchmarks.subtitle': 'How does Gemma 3n compare to competitors? Here are the benchmarks.',
  'benchmarks.source': 'Data sourced from official Google AI publications and independent benchmarks.',
  'benchmarks.heading': 'Performance Benchmarks',
  'benchmarks.efficiency_champion_title': 'Efficiency Champion',
  'benchmarks.efficiency_champion': 'Gemma 3n E4B achieves 79.8% MMLU with only 4B parameters, outperforming Llama 3.1 8B (66.7%) while using half the memory.',
  'benchmarks.mobile_first_design_title': 'Mobile-First Design',
  'benchmarks.mobile_first_design': 'MatFormer architecture enables dynamic scaling, allowing the same model to run efficiently from smartphones to workstations.',
  'benchmarks.mmlu.title': 'MMLU',
  'benchmarks.mmlu.desc': 'Massive Multitask Language Understanding',
  'benchmarks.mmlu.note': 'Outperforms leading models in its class on this key knowledge and reasoning benchmark.',
  'benchmarks.lmarena.title': 'LMArena Score',
  'benchmarks.lmarena.desc': 'Human preference chatbot benchmark',
  'benchmarks.lmarena.max': 'of max observed',
  'benchmarks.lmarena.note': 'The first model under 10B parameters to break the 1300 barrier, showcasing strong conversational ability.',
  'benchmarks.vision.title': 'Vision Encoder Speed',
  'benchmarks.vision.desc': 'On-device performance (Pixel Edge TPU)',
  'benchmarks.vision.faster': 'Faster',
  'benchmarks.vision.compare': 'MobileNet-V5 vs SoViT',
  'benchmarks.vision.note': 'A massive speedup in vision processing with higher accuracy and a smaller memory footprint.',
  'benchmarks.table.title': 'Gemma 3n vs. Competition',
  'benchmarks.table.model': 'Model',
  'benchmarks.table.params': 'Parameters',
  'benchmarks.table.mmlu': 'MMLU',
  'benchmarks.table.gsm8k': 'GSM8K',
  'benchmarks.table.humaneval': 'HumanEval',
  'benchmarks.table.memory': 'Memory (GB)',
  'benchmarks.gemma_e4b': 'Gemma 3n E4B',
  'benchmarks.gemma_e2b': 'Gemma 3n E2B',
  'benchmarks.llama_3_8b': 'Llama 3.1 8B',
  'benchmarks.llama_3_3b': 'Llama 3.2 3B',
  'benchmarks.score': 'Score',
  'benchmarks.tag.superior': 'Superior performance',
  'benchmarks.tag.below': 'Below Gemma 3n E4B',
  'benchmarks.memory.note': 'Memory requirements are for full precision models.',
} as const; 