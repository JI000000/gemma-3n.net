export const compare = {
  'compare.title': "Gemma 3n vs. Llama 3: The Ultimate Showdown",
  'compare.description': "A deep-dive, data-driven comparison of Google's Gemma 3n vs. Meta's Llama 3. We analyze benchmarks, hardware requirements, and use cases to help you choose the right model for your project.",
  'compare.h1': "Gemma 3n <span class='text-blue-600'>vs.</span> Llama 3",
  'compare.subheading': "Efficiency meets performance. We break down the two leading open-source models to help you make the right choice for your specific needs.",
  'compare.showdown_badge': "Model Showdown",
  'compare.glance.title': "At a Glance: Key Differences",
  'compare.glance.feature': "Feature",
  'compare.glance.gemma': "Gemma 3n (E4B)",
  'compare.glance.llama': "Llama 3 (8B)",
  'compare.glance.architecture': "Architecture",
  'compare.glance.architecture.gemma': "MatFormer (Dynamic Scaling)",
  'compare.glance.architecture.llama': "Standard Transformer",
  'compare.glance.params': "Effective Parameters",
  'compare.glance.params.gemma': "~4 Billion",
  'compare.glance.params.llama': "8 Billion",
  'compare.glance.strength': "Core Strength",
  'compare.glance.strength.gemma': "On-device performance, Efficiency",
  'compare.glance.strength.llama': "Raw reasoning & coding power",
  'compare.glance.hardware': "Hardware Requirements",
  'compare.glance.hardware.gemma': "<span class='font-semibold text-green-600 dark:text-green-400'>Low</span> (Modern laptop)",
  'compare.glance.hardware.llama': "<span class='font-semibold text-orange-500'>Medium</span> (Needs good GPU)",
  'compare.glance.multimodality': "Multimodal Capabilities",
  'compare.glance.multimodality.gemma': "Native text, audio, image support",
  'compare.glance.multimodality.llama': "Text only",
  'compare.benchmarks.title': "Performance Benchmarks",
  'compare.benchmarks.note': "*Benchmark scores are illustrative based on publicly aggregated data.",
  'compare.deepdive.title': "Deep Dive Analysis",
  'compare.deepdive.gemma.title': "üèÜ Where Gemma 3n Wins",
  'compare.deepdive.gemma.1.title': "Efficiency & Accessibility",
  'compare.deepdive.gemma.1.desc': "Runs smoothly on consumer hardware (laptops, phones) with significantly lower RAM usage, perfect for edge applications.",
  'compare.deepdive.gemma.2.title': "Native Multimodality",
  'compare.deepdive.gemma.2.desc': "Built from the ground up to understand text, audio, and images in a single model, unlocking new application types that Llama can't handle alone.",
  'compare.deepdive.gemma.3.title': "Dynamic Architecture",
  'compare.deepdive.gemma.3.desc': "MatFormer architecture allows it to dynamically scale compute, delivering balanced performance without massive static parameters.",
  'compare.deepdive.llama.title': "üèÜ Where Llama 3 Wins",
  'compare.deepdive.llama.1.title': "Raw Reasoning & Coding Power",
  'compare.deepdive.llama.1.desc': "With more dedicated parameters, Llama 3 excels at complex logical reasoning, math problems, and code generation, often outperforming Gemma on pure text benchmarks.",
  'compare.deepdive.llama.2.title': "Mature Fine-tuning Ecosystem",
  'compare.deepdive.llama.2.desc': "As a more established architecture, the community has contributed extensive task-specific fine-tuned versions of Llama 3.",
  'compare.deepdive.llama.3.title': "Predictable Performance",
  'compare.deepdive.llama.3.desc': "Its standard Transformer architecture means very predictable performance scaling and well-understood behavior with more powerful hardware.",
  'compare.verdict.title': "The Verdict: Which One Is Right for You?",
  'compare.verdict.subtitle': "Your choice depends entirely on your project's core goals.",
  'compare.verdict.gemma.title': "Choose Gemma 3n if...",
  'compare.verdict.gemma.bullet1': "You're building for **mobile or edge devices**.",
  'compare.verdict.gemma.bullet2': "Your application needs **multimodal capabilities** (audio/vision).",
  'compare.verdict.gemma.bullet3': "**Resource efficiency** and low RAM usage are critical.",
  'compare.verdict.gemma.bullet4': "You need a balanced, all-around model for general tasks.",
  'compare.verdict.llama.title': "Choose Llama 3 if...",
  'compare.verdict.llama.bullet1': "Your primary use case is **complex coding or reasoning**.",
  'compare.verdict.llama.bullet2': "You have **powerful GPU hardware**.",
  'compare.verdict.llama.bullet3': "You need absolute best performance on **pure text tasks**.",
  'compare.verdict.llama.bullet4': "You want to leverage the huge library of community fine-tuned models.",
  'compare.cta.title': "Ready to Dive Deeper?",
  'compare.cta.subtitle': "Explore our hands-on tutorials to master both models.",
  'compare.cta.button1': "Browse All Tutorials",
  'compare.cta.button2': "Get The Toolkit",
} as const; 