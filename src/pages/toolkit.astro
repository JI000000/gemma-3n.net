---
import MainLayout from '../layouts/MainLayout.astro';
import ToolkitCard from '../components/ToolkitCard.astro';

const tools = [
  {
    title: "Ollama",
    description: "An easy-to-use tool for running LLMs like Gemma 3n on your local machine. Great for getting started quickly from the command line.",
    logoSrc: "https://ollama.com/public/ollama.png",
    officialLink: "https://ollama.com/",
    tutorialLink: "/blog/how-to-run-gemma-3n-with-ollama"
  },
  {
    title: "LM Studio",
    description: "A beautiful and powerful desktop UI for discovering, managing, and running local LLMs. No command line required.",
    logoSrc: "https://avatars.githubusercontent.com/u/141323380?s=200&v=4",
    officialLink: "https://lmstudio.ai/",
    tutorialLink: "/blog/getting-started-with-gemma-3n-and-lm-studio"
  },
  {
    title: "Unsloth",
    description: "A library for extremely fast, memory-efficient fine-tuning of LLMs. Essential for training models on consumer hardware.",
    logoSrc: "https://avatars.githubusercontent.com/u/150191653?s=200&v=4",
    officialLink: "https://github.com/unslothai/unsloth",
    tutorialLink: "/blog/fine-tuning-gemma-3n-with-unsloth"
  },
  {
    title: "MLX",
    description: "Apple's framework for machine learning on Apple silicon. Perfect for high-performance, on-device multimodal applications.",
    logoSrc: "https://avatars.githubusercontent.com/u/151674099?s=200&v=4",
    officialLink: "https://github.com/ml-explore/mlx",
    tutorialLink: "/blog/image-analysis-with-gemma-3n"
  },
  {
    title: "Hugging Face",
    description: "The leading platform for the AI community. Find models, datasets, and tools to build with Gemma 3n.",
    logoSrc: "https://huggingface.co/front/assets/huggingface_logo-noborder.svg",
    officialLink: "https://huggingface.co/models?search=gemma+3n",
  },
  {
    title: "Kaggle",
    description: "The world's largest data science community. Access datasets, free notebook environments (GPUs), and competitions.",
    logoSrc: "https://www.kaggle.com/static/images/site-logo.svg",
    officialLink: "https://www.kaggle.com/",
  }
];
---

<MainLayout title="Gemma 3n Toolkit - Complete Developer Resources" description="Comprehensive toolkit for Gemma 3n development. Includes Ollama setup, Hugging Face integration, iOS deployment guides, and model comparison tools.">
  <main class="pt-20">
    <!-- Hero Section -->
    <section class="py-20 bg-gradient-to-br from-blue-50 to-indigo-100 dark:from-blue-900/20 dark:to-indigo-900/20">
      <div class="max-w-4xl mx-auto px-4 text-center">
        <h1 class="text-4xl md:text-6xl font-bold text-slate-900 dark:text-white mb-6">
          Gemma 3n Toolkit
        </h1>
        <p class="text-xl text-slate-600 dark:text-gray-400 mb-8">
          Everything you need to get started with Gemma 3n development. From quick setup to advanced deployment strategies.
        </p>
        <div class="flex flex-wrap justify-center gap-4">
          <span class="px-4 py-2 bg-blue-100 dark:bg-blue-900/50 text-blue-800 dark:text-blue-200 rounded-full text-sm font-medium">Ollama Ready</span>
          <span class="px-4 py-2 bg-green-100 dark:bg-green-900/50 text-green-800 dark:text-green-200 rounded-full text-sm font-medium">Hugging Face Compatible</span>
          <span class="px-4 py-2 bg-purple-100 dark:bg-purple-900/50 text-purple-800 dark:text-purple-200 rounded-full text-sm font-medium">iOS Optimized</span>
        </div>
      </div>
    </section>

    <!-- Quick Start Section -->
    <section class="py-20 bg-white dark:bg-slate-900">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="text-3xl font-bold text-center text-slate-900 dark:text-white mb-12">Quick Start Tools</h2>
        <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
          
          <!-- Ollama Integration -->
          <div class="p-6 bg-slate-50 dark:bg-gray-800 rounded-lg hover:shadow-lg transition-shadow">
            <div class="flex items-center mb-4">
              <div class="w-12 h-12 bg-blue-500 rounded-lg flex items-center justify-center text-white font-bold text-xl mr-4">
                O
              </div>
              <h3 class="text-xl font-bold text-slate-900 dark:text-white">Ollama Setup</h3>
            </div>
            <p class="text-slate-600 dark:text-gray-400 mb-4">Get Gemma 3n running locally with Ollama in under 5 minutes.</p>
            <div class="bg-gray-900 rounded-lg p-4 mb-4">
              <code class="text-green-400 text-sm">
                # Install Ollama first<br/>
                ollama run gemma-3n:e4b<br/>
                # Or for smaller model<br/>
                ollama run gemma-3n:e2b
              </code>
            </div>
            <a href="/blog/how-to-run-gemma-3n-with-ollama" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:underline">
              Complete Guide ‚Üí
            </a>
          </div>

          <!-- Hugging Face Integration -->
          <div class="p-6 bg-slate-50 dark:bg-gray-800 rounded-lg hover:shadow-lg transition-shadow">
            <div class="flex items-center mb-4">
              <div class="w-12 h-12 bg-yellow-500 rounded-lg flex items-center justify-center text-white font-bold text-xl mr-4">
                ü§ó
              </div>
              <h3 class="text-xl font-bold text-slate-900 dark:text-white">Hugging Face</h3>
            </div>
            <p class="text-slate-600 dark:text-gray-400 mb-4">Use Gemma 3n models directly from Hugging Face Hub.</p>
            <div class="bg-gray-900 rounded-lg p-4 mb-4">
              <code class="text-green-400 text-sm">
                from transformers import AutoTokenizer, AutoModelForCausalLM<br/>
                model_name = "google/gemma-3n-e4b-it"<br/>
                model = AutoModelForCausalLM.from_pretrained(model_name)
              </code>
            </div>
            <a href="https://huggingface.co/models?search=gemma%203n" target="_blank" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:underline">
              Browse Models ‚Üí
            </a>
          </div>

          <!-- Model Comparison -->
          <div class="p-6 bg-slate-50 dark:bg-gray-800 rounded-lg hover:shadow-lg transition-shadow">
            <div class="flex items-center mb-4">
              <div class="w-12 h-12 bg-green-500 rounded-lg flex items-center justify-center text-white font-bold text-xl mr-4">
                ‚öñÔ∏è
              </div>
              <h3 class="text-xl font-bold text-slate-900 dark:text-white">E2B vs E4B</h3>
            </div>
            <p class="text-slate-600 dark:text-gray-400 mb-4">Interactive tool to help you choose the right model size.</p>
            <div class="space-y-2 mb-4">
              <div class="flex justify-between text-sm">
                <span>E2B: Mobile-friendly</span>
                <span class="text-green-600 dark:text-green-400">4GB RAM</span>
              </div>
              <div class="flex justify-between text-sm">
                <span>E4B: Higher accuracy</span>
                <span class="text-blue-600 dark:text-blue-400">8GB RAM</span>
              </div>
            </div>
            <a href="/blog/gemma-3n-e2b-vs-e4b-which-one-should-you-choose" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:underline">
              Detailed Comparison ‚Üí
            </a>
          </div>

        </div>
      </div>
    </section>

    <!-- Platform Integrations -->
    <section class="py-20 bg-slate-50 dark:bg-slate-900/50">
      <div class="max-w-6xl mx-auto px-4">
        <h2 class="text-3xl font-bold text-center text-slate-900 dark:text-white mb-12">Platform Integrations</h2>
        
        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
          
          <!-- iOS Development -->
          <div class="p-8 bg-white dark:bg-gray-800 rounded-lg shadow-lg">
            <h3 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">üì± iOS Development</h3>
            <p class="text-slate-600 dark:text-gray-400 mb-6">Deploy Gemma 3n models on iOS devices with optimized performance.</p>
            
            <h4 class="font-semibold text-slate-900 dark:text-white mb-3">Recommended Setup:</h4>
            <ul class="space-y-2 mb-6">
              <li class="flex items-center text-slate-600 dark:text-gray-400">
                <span class="w-2 h-2 bg-green-500 rounded-full mr-3"></span>
                Gemma 3n E2B for iPhone (2GB model)
              </li>
              <li class="flex items-center text-slate-600 dark:text-gray-400">
                <span class="w-2 h-2 bg-blue-500 rounded-full mr-3"></span>
                CoreML conversion for optimal performance
              </li>
              <li class="flex items-center text-slate-600 dark:text-gray-400">
                <span class="w-2 h-2 bg-purple-500 rounded-full mr-3"></span>
                GGUF quantization for reduced size
              </li>
            </ul>
            
            <div class="bg-gray-900 rounded-lg p-4 mb-4">
              <code class="text-green-400 text-sm">
                # Convert to CoreML<br/>
                pip install coremltools<br/>
                # Follow our detailed iOS guide
              </code>
            </div>
            
            <a href="/tutorials/gemma-3n-ios-deployment" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:underline">
              iOS Deployment Guide ‚Üí
            </a>
          </div>

          <!-- Fine-tuning Tools -->
          <div class="p-8 bg-white dark:bg-gray-800 rounded-lg shadow-lg">
            <h3 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">üîß Fine-tuning Tools</h3>
            <p class="text-slate-600 dark:text-gray-400 mb-6">Customize Gemma 3n models for your specific use cases.</p>
            
            <h4 class="font-semibold text-slate-900 dark:text-white mb-3">Available Methods:</h4>
            <ul class="space-y-2 mb-6">
              <li class="flex items-center text-slate-600 dark:text-gray-400">
                <span class="w-2 h-2 bg-red-500 rounded-full mr-3"></span>
                LoRA (Low-Rank Adaptation)
              </li>
              <li class="flex items-center text-slate-600 dark:text-gray-400">
                <span class="w-2 h-2 bg-yellow-500 rounded-full mr-3"></span>
                Unsloth for 2x faster training
              </li>
              <li class="flex items-center text-slate-600 dark:text-gray-400">
                <span class="w-2 h-2 bg-indigo-500 rounded-full mr-3"></span>
                Google Colab notebooks ready
              </li>
            </ul>
            
            <div class="bg-gray-900 rounded-lg p-4 mb-4">
              <code class="text-green-400 text-sm">
                # Start with Unsloth<br/>
                pip install unsloth<br/>
                # Or try our LoRA tutorial
              </code>
            </div>
            
            <div class="flex space-x-4">
              <a href="/blog/fine-tuning-gemma-3n-with-lora" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:underline">
                LoRA Guide ‚Üí
              </a>
              <a href="/blog/fine-tuning-gemma-3n-with-unsloth" class="inline-flex items-center text-blue-600 dark:text-blue-400 hover:underline">
                Unsloth Guide ‚Üí
              </a>
            </div>
          </div>

        </div>
      </div>
    </section>

    <!-- Hardware Requirements -->
    <section class="py-20 bg-white dark:bg-slate-900">
      <div class="max-w-4xl mx-auto px-4">
        <h2 class="text-3xl font-bold text-center text-slate-900 dark:text-white mb-12">Hardware Requirements</h2>
        
        <div class="overflow-x-auto">
          <table class="w-full bg-slate-50 dark:bg-gray-800 rounded-lg shadow-lg">
            <thead class="bg-gray-100 dark:bg-gray-700">
              <tr>
                <th class="px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider">Model</th>
                <th class="px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider">RAM (FP16)</th>
                <th class="px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider">RAM (4-bit)</th>
                <th class="px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider">Best Use Case</th>
              </tr>
            </thead>
            <tbody class="divide-y divide-gray-200 dark:divide-gray-600">
              <tr>
                <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900 dark:text-white">Gemma 3n E2B</td>
                <td class="px-6 py-4 whitespace-nowrap text-sm text-green-600 dark:text-green-400">4GB</td>
                <td class="px-6 py-4 whitespace-nowrap text-sm text-green-600 dark:text-green-400">2GB</td>
                <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500 dark:text-gray-300">Mobile, Edge devices</td>
              </tr>
              <tr>
                <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900 dark:text-white">Gemma 3n E4B</td>
                <td class="px-6 py-4 whitespace-nowrap text-sm text-blue-600 dark:text-blue-400">8GB</td>
                <td class="px-6 py-4 whitespace-nowrap text-sm text-blue-600 dark:text-blue-400">4GB</td>
                <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500 dark:text-gray-300">Laptops, Workstations</td>
              </tr>
            </tbody>
          </table>
        </div>
        
        <div class="mt-8 grid grid-cols-1 md:grid-cols-3 gap-6">
          <div class="text-center p-6 bg-green-50 dark:bg-green-900/20 rounded-lg">
            <div class="text-2xl font-bold text-green-600 dark:text-green-400 mb-2">‚úÖ CPU Only</div>
            <p class="text-slate-600 dark:text-gray-400">Both models run efficiently on CPU-only setups</p>
          </div>
          <div class="text-center p-6 bg-blue-50 dark:bg-blue-900/20 rounded-lg">
            <div class="text-2xl font-bold text-blue-600 dark:text-blue-400 mb-2">üöÄ GPU Accelerated</div>
            <p class="text-slate-600 dark:text-gray-400">Significant speedup with CUDA/Metal support</p>
          </div>
          <div class="text-center p-6 bg-purple-50 dark:bg-purple-900/20 rounded-lg">
            <div class="text-2xl font-bold text-purple-600 dark:text-purple-400 mb-2">üì± Mobile Ready</div>
            <p class="text-slate-600 dark:text-gray-400">E2B optimized for iOS and Android deployment</p>
          </div>
        </div>
      </div>
    </section>

    <!-- Call to Action -->
    <section class="py-20 bg-gradient-to-r from-blue-600 to-indigo-600 text-white">
      <div class="max-w-4xl mx-auto px-4 text-center">
        <h2 class="text-3xl font-bold mb-4">Ready to Build with Gemma 3n?</h2>
        <p class="text-xl mb-8 opacity-90">Join thousands of developers already using Gemma 3n in production.</p>
        <div class="flex flex-wrap justify-center gap-4">
          <a href="/blog" class="px-8 py-3 bg-white text-blue-600 rounded-lg font-medium hover:bg-gray-100 transition-colors">
            Browse Tutorials
          </a>
          <a href="/#resources" class="px-8 py-3 border-2 border-white text-white rounded-lg font-medium hover:bg-white hover:text-blue-600 transition-colors">
            Download Models
          </a>
        </div>
      </div>
    </section>
  </main>
</MainLayout> 